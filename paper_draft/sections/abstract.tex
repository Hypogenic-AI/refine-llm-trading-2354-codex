\begin{abstract}
Large language model (LLM) trading agents are usually evaluated with frequent daily reallocation, but this setting can induce noise chasing and high turnover. Our main question is whether reducing decision cadence improves out-of-sample portfolio quality. We run a controlled experiment on U.S. equities with real \gptmodel API calls, using 15 tickers from 2010--2026 and a fixed test window from 2025-01-02 to 2026-01-30. We hold the model family, feature schema, and constraints constant, and vary only rebalance cadence (daily, weekly, monthly) plus a weekly position-awareness ablation. Weekly LLM control is the strongest LLM variant: Sortino 2.84 versus 2.17 for daily, lower drawdown (-0.1518 vs -0.1432, with monthly best at -0.1347), and much lower turnover (24.20 vs 59.49). Weekly outperforms daily on paired daily returns under Wilcoxon signed-rank testing ($p=0.0272$), while monthly shows practical gains but no significant daily-return difference ($p=0.4382$). Robustness checks across 0/5/10 bps transaction costs keep weekly and monthly above daily. A tuned non-LLM weekly momentum baseline remains best overall (Sortino 2.98), so we do not claim absolute dominance. The contribution is a cadence-controlled estimate showing that medium-horizon LLM allocation is more stable and more deployable than day-to-day LLM control in this setting.
\end{abstract}
