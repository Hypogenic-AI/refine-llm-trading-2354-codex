{"title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "authors": "Yanxu Chen, Zijun Yao, Yantao Liu, Jin Ye, Jianing Yu, Lei Hou, Juanzi Li", "url": "https://api.semanticscholar.org/CorpusId:281724665", "relevance": 3, "abstract": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making. While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making. Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading. To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments. Agents receive daily market signals -- including prices, fundamentals, and news -- and must make sequential buy, sell, or hold decisions. Performance is assessed using financial metrics such as cumulative return, maximum drawdown, and the Sortino ratio. Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively. These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies. We release StockBench as an open-source resource to support reproducibility and advance future research in this domain.", "citations": 7}
{"title": "FinPos: A Position-Aware Trading Agent System for Real Financial Markets", "year": 2025, "authors": "Bijia Liu, Ronghao Dang", "url": "https://api.semanticscholar.org/CorpusId:282719341", "relevance": 3, "abstract": "The exceptional potential of large language models (LLMs) in handling text information has garnered significant attention in the field of financial trading. However, most existing trading agents operate under intraday, independent unit-based trading tasks, where decisions are made as isolated directional actions, and thus lack awareness of continuous position management. Therefore, we propose a position-aware trading task designed to simulate a more realistic market. To address this task, we propose FinPos, a position-aware trading agent system designed to explicitly model and manage continuous positions. FinPos enhances position awareness through three key mechanisms: (1) professional-level interpretation of heterogeneous market information; (2) a dual-agent decision structure that separates directional reasoning from risk-aware position adjustment; and (3) multi-timescale reward signals, allowing the agent to internalize position awareness through experiential feedback rather than static instructions alone. Extensive experiments demonstrate that FinPos surpasses state-of-the-art trading agents in the position-aware trading task, which closely mirrors real market conditions. More importantly, our findings reveal that LLM-centered agent systems exhibit a vast, largely unexplored potential in long-term market decision-making.", "citations": 2}
{"title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "year": 2025, "authors": "Weixian Waylon Li, Hyeonjun Kim, Mihai Cucuringu, Tiejun Ma", "url": "https://api.semanticscholar.org/CorpusId:278501425", "relevance": 3, "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.", "citations": 8}
{"title": "Language Model Guided Reinforcement Learning in Quantitative Trading", "year": 2025, "authors": "Adam Darmanin, Vince Vella", "url": "https://api.semanticscholar.org/CorpusId:280421329", "relevance": 3, "abstract": "Algorithmic trading requires short-term tactical decisions consistent with long-term financial objectives. Reinforcement Learning (RL) has been applied to such problems, but adoption is limited by myopic behaviour and opaque policies. Large Language Models (LLMs) offer complementary strategic reasoning and multi-modal signal interpretation when guided by well-structured prompts. This paper proposes a hybrid framework in which LLMs generate high-level trading strategies to guide RL agents. We evaluate (i) the economic rationale of LLM-generated strategies through expert review, and (ii) the performance of LLM-guided agents against unguided RL baselines using Sharpe Ratio (SR) and Maximum Drawdown (MDD). Empirical results indicate that LLM guidance improves both return and risk metrics relative to standard RL.", "citations": 1}
{"title": "Hierarchical Organization Simulacra in the Investment Sector", "year": 2024, "authors": "Chung-Chi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao", "url": "https://api.semanticscholar.org/CorpusId:273022534", "relevance": 3, "abstract": "This paper explores designing artificial organizations with professional behavior in investments using a multi-agent simulation. The method mimics hierarchical decision-making in investment firms, using news articles to inform decisions. A large-scale study analyzing over 115,000 news articles of 300 companies across 15 years compared this approach against professional traders' decisions. Results show that hierarchical simulations align closely with professional choices, both in frequency and profitability. However, the study also reveals biases in decision-making, where changes in prompt wording and perceived agent seniority significantly influence outcomes. This highlights both the potential and limitations of large language models in replicating professional financial decision-making.", "citations": 1}
{"title": "AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading", "year": 2025, "authors": "Zheye Deng, Jiashu Wang", "url": "https://api.semanticscholar.org/CorpusId:282139067", "relevance": 3, "abstract": "While Large Language Model (LLM) agents show promise in automated trading, they still face critical limitations. Prominent multi-agent frameworks often suffer from inefficiency, produce inconsistent signals, and lack the end-to-end optimization required to learn a coherent strategy from market feedback. To address this, we introduce AlphaQuanter, a single-agent framework that uses reinforcement learning (RL) to learn a dynamic policy over a transparent, tool-augmented decision workflow, which empowers a single agent to autonomously orchestrate tools and proactively acquire information on demand, establishing a transparent and auditable reasoning process. Extensive experiments demonstrate that AlphaQuanter achieves state-of-the-art performance on key financial metrics. Moreover, its interpretable reasoning reveals sophisticated strategies, offering novel and valuable insights for human traders. Our code for data acquisition and agent training is publicly available at: https://github.com/AlphaQuanter/AlphaQuanter", "citations": 1}
{"title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://api.semanticscholar.org/CorpusId:281843943", "relevance": 3, "abstract": "In this paper, our objective is to develop a multi-agent financial system that incorporates simulated trading, a technique extensively utilized by financial professionals. While current LLM-based agent models demonstrate competitive performance, they still exhibit significant deviations from real-world fund companies. A critical distinction lies in the agents'reliance on ``post-reflection'', particularly in response to adverse outcomes, but lack a distinctly human capability: long-term prediction of future trends. Therefore, we introduce QuantAgents, a multi-agent system integrating simulated trading, to comprehensively evaluate various investment strategies and market scenarios without assuming actual risks. Specifically, QuantAgents comprises four agents: a simulated trading analyst, a risk control analyst, a market news analyst, and a manager, who collaborate through several meetings. Moreover, our system incentivizes agents to receive feedback on two fronts: performance in real-world markets and predictive accuracy in simulated trading. Extensive experiments demonstrate that our framework excels across all metrics, yielding an overall return of nearly 300% over the three years (https://quantagents.github.io/).", "citations": 4}
{"title": "GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents", "year": 2025, "authors": "Yejin Kim, Youngbin Lee, Juhyeon Kim, Yongjae Lee", "url": "https://api.semanticscholar.org/CorpusId:281724135", "relevance": 3, "abstract": "This study demonstrates that GuruAgents, prompt-guided AI agents, can systematically operationalize the strategies of legendary investment gurus. We develop five distinct GuruAgents, each designed to emulate an iconic investor, by encoding their distinct philosophies into LLM prompts that integrate financial tools and a deterministic reasoning pipeline. In a backtest on NASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit unique behaviors driven by their prompted personas. The Buffett GuruAgent achieves the highest performance, delivering a 42.2\\% CAGR that significantly outperforms benchmarks, while other agents show varied results. These findings confirm that prompt engineering can successfully translate the qualitative philosophies of investment gurus into reproducible, quantitative strategies, highlighting a novel direction for automated systematic investing. The source code and data are available at https://github.com/yejining99/GuruAgents.", "citations": 0}
{"title": "HedgeAgents: A Balanced-aware Multi-agent Financial Trading System", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://api.semanticscholar.org/CorpusId:276449781", "relevance": 3, "abstract": "As automated trading gains traction in the financial market, algorithmic investment strategies are increasingly prominent. While Large Language Models (LLMs) and Agent-based models exhibit promising potential in real-time market analysis and trading decisions, they still experience a significant -20% loss when confronted with rapid declines or frequent fluctuations, impeding their practical application. Hence, there is an imperative to explore a more robust and resilient framework. This paper introduces an innovative multi-agent system, HedgeAgents, aimed at bolstering system robustness via ''hedging'' strategies. In this well-balanced system, an array of hedging agents has been tailored, where HedgeAgents consist of a central fund manager and multiple hedging experts specializing in various financial asset classes. These agents leverage LLMs' cognitive capabilities to make decisions and coordinate through three types of conferences. Benefiting from the powerful understanding of LLMs, our HedgeAgents attained a 70% annualized return and a 400% total return over a period of 3 years. Moreover, we have observed with delight that HedgeAgents can even formulate investment experience comparable to those of human experts (https://hedgeagents.github.io/).", "citations": 23}
{"title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "year": 2026, "authors": "Mostapha Benhenda", "url": "https://api.semanticscholar.org/CorpusId:284911867", "relevance": 3, "abstract": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "citations": 0}
{"title": "Hierarchical AI Multi-Agent Fundamental Investing: Evidence from China's A-Share Market", "year": 2025, "authors": "Chujun He, Zhonghao Huang, Xiangguo Li, Ye Luo, Kewei Ma, Yuxuan Xiong, Xiaowei Zhang, Mingyang Zhao", "url": "https://api.semanticscholar.org/CorpusId:282384801", "relevance": 3, "abstract": "We present a multi-agent, AI-driven framework for fundamental investing that integrates macro indicators, industry-level and firm-specific information to construct optimized equity portfolios. The architecture comprises: (i) a Macro agent that dynamically screens and weights sectors based on evolving economic indicators and industry performance; (ii) four firm-level agents -- Fundamental, Technical, Report, and News -- that conduct in-depth analyses of individual firms to ensure both breadth and depth of coverage; (iii) a Portfolio agent that uses reinforcement learning to combine the agent outputs into a unified policy to generate the trading strategy; and (iv) a Risk Control agent that adjusts portfolio positions in response to market volatility. We evaluate the system on the constituents by the CSI 300 Index of China's A-share market and find that it consistently outperforms standard benchmarks and a state-of-the-art multi-agent trading system on risk-adjusted returns and drawdown control. Our core contribution is a hierarchical multi-agent design that links top-down macro screening with bottom-up fundamental analysis, offering a robust and extensible approach to factor-based portfolio construction.", "citations": 0}
{"title": "HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization", "year": 2025, "authors": "Benjamin Coriat, E. Benhamou", "url": "https://api.semanticscholar.org/CorpusId:280017786", "relevance": 3, "abstract": "This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.", "citations": 1}
{"title": "RAPTOR: Reasoned Agentic Portfolio Trading with Orchestrated Rebalancing", "year": null, "authors": "Blake Almon, Matthew Caliboso, Alex Kim, Rohan Dutta, Rohan Raman, Mithil Srungarapu, Vasu Sharma, Kevin Zhu, Sunishchal Dev", "url": "https://www.semanticscholar.org/paper/b2bf7b437f879e222f293046d09e234a8a22db1c", "relevance": 3, "abstract": "", "citations": 1}
{"title": "FinMem: A Performance-Enhanced LLM Trading Agent With Layered Memory and Character Design", "year": 2023, "authors": "Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Jordan W. Suchow, Denghui Zhang, K. Khashanah", "url": "https://api.semanticscholar.org/CorpusId:265445755", "relevance": 1, "abstract": "We introduce FinMem, a novel Large Language Models (LLM)-based agent framework for financial trading, designed to address the need for automated systems that can transform real-time data into executable decisions. FinMem comprises three core modules: Profile for customizing agent characteristics, Memory for hierarchical financial data assimilation, and Decision-making for converting insights into investment choices. The Memory module, which mimics human traders\u2019 cognitive structure, offers interpretability and real-time tuning while handling the critical timing of various information types. It employs a layered approach to process and prioritize data based on its timeliness and relevance, ensuring that the most recent and impactful information is given appropriate weight in decision-making. FinMem\u2019s adjustable cognitive span allows retention of critical information beyond human limits, enabling it to balance historical patterns with current market dynamics. This framework facilitates self-evolution of professional knowledge, agile reactions to investment cues, and continuous refinement of trading decisions in financial environments. When compared against advanced algorithmic agents using a large-scale real-world financial dataset, FinMem demonstrates superior performance across classic metrics like Cumulative Return and Sharpe ratio. Further tuning of the agent\u2019s perceptual span and character setting enhances its trading performance, positioning FinMem as a cutting-edge solution for automated trading.", "citations": 148}
{"title": "A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist", "year": 2024, "authors": "Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun Wang, Bo An", "url": "https://api.semanticscholar.org/CorpusId:268041696", "relevance": 1, "abstract": "Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 12 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.", "citations": 126}
{"title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making", "year": 2024, "authors": "Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, K. Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie", "url": "https://api.semanticscholar.org/CorpusId:271064881", "relevance": 1, "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.", "citations": 97}
{"title": "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges", "year": 2024, "authors": "Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Poor, Qingsong Wen, Stefan Zohren", "url": "https://api.semanticscholar.org/CorpusId:270562262", "relevance": 1, "abstract": "Recent advances in large language models (LLMs) have unlocked novel opportunities for machine learning applications in the financial domain. These models have demonstrated remarkable capabilities in understanding context, processing vast amounts of data, and generating human-preferred contents. In this survey, we explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. We provide a discussion of the progress and advantages of LLMs in financial contexts, analyzing their advanced technologies as well as prospective capabilities in contextual understanding, transfer learning flexibility, complex emotion detection, etc. We then highlight this survey for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, agent-based modeling, and other applications. For each application area, we delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, a comprehensive collection of datasets, model assets, and useful codes associated with mainstream applications are presented as resources for the researchers and practitioners. Finally, we outline the challenges and opportunities for future research, particularly emphasizing a number of distinctive aspects in this field. We hope our work can help facilitate the adoption and further development of LLMs in the financial sector.", "citations": 126}
{"title": "TradingAgents: Multi-Agents LLM Financial Trading Framework", "year": 2024, "authors": "Yijia Xiao, Edward Sun, Di Luo, Wei Wang", "url": "https://api.semanticscholar.org/CorpusId:275133732", "relevance": 1, "abstract": "Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, the multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TauricResearch/TradingAgents.", "citations": 92}
{"title": "TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance", "year": 2023, "authors": "Yang Li, Yangyang Yu, Haohang Li, Z. Chen, K. Khashanah", "url": "https://api.semanticscholar.org/CorpusId:261582775", "relevance": 1, "abstract": "Large Language Models (LLMs), prominently highlighted by the recent evolution in the Generative Pre-trained Transformers (GPT) series, have displayed significant prowess across various domains, such as aiding in healthcare diagnostics and curating analytical business reports. The efficacy of GPTs lies in their ability to decode human instructions, achieved through comprehensively processing historical inputs as an entirety within their memory system. Yet, the memory processing of GPTs does not precisely emulate the hierarchical nature of human memory. This can result in LLMs struggling to prioritize immediate and critical tasks efficiently. To bridge this gap, we introduce an innovative LLM multi-agent framework endowed with layered memories. We assert that this framework is well-suited for stock and fund trading, where the extraction of highly relevant insights from hierarchical financial data is imperative to inform trading decisions. Within this framework, one agent organizes memory into three distinct layers, each governed by a custom decay mechanism, aligning more closely with human cognitive processes. Agents can also engage in inter-agent debate. In financial trading contexts, LLMs serve as the decision core for trading agents, leveraging their layered memory system to integrate multi-source historical actions and market insights. This equips them to navigate financial changes, formulate strategies, and debate with peer agents about investment decisions. Another standout feature of our approach is to equip agents with individualized trading traits, enhancing memory diversity and decision robustness. These sophisticated designs boost the system's responsiveness to historical trades and real-time market signals, ensuring superior automated trading accuracy.", "citations": 86}
{"title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review", "year": 2025, "authors": "M. Ferrag, Norbert Tihanyi, M. Debbah", "url": "https://api.semanticscholar.org/CorpusId:278165282", "relevance": 1, "abstract": "Large language models and autonomous AI agents have evolved rapidly, resulting in a diverse array of evaluation benchmarks, frameworks, and collaboration protocols. However, the landscape remains fragmented and lacks a unified taxonomy or comprehensive survey. Therefore, we present a side-by-side comparison of benchmarks developed between 2019 and 2025 that evaluate these models and agents across multiple domains. In addition, we propose a taxonomy of approximately 60 benchmarks that cover general and academic knowledge reasoning, mathematical problem-solving, code generation and software engineering, factual grounding and retrieval, domain-specific evaluations, multimodal and embodied tasks, task orchestration, and interactive assessments. Furthermore, we review AI-agent frameworks introduced between 2023 and 2025 that integrate large language models with modular toolkits to enable autonomous decision-making and multi-step reasoning. Moreover, we present real-world applications of autonomous AI agents in materials science, biomedical research, academic ideation, software engineering, synthetic data generation, chemical reasoning, mathematical problem-solving, geographic information systems, multimedia, healthcare, and finance. We then survey key agent-to-agent collaboration protocols, namely the Agent Communication Protocol (ACP), the Model Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally, we discuss recommendations for future research, focusing on advanced reasoning strategies, failure modes in multi-agent LLM systems, automated scientific discovery, dynamic tool integration via reinforcement learning, integrated search capabilities, and security vulnerabilities in agent protocols.", "citations": 97}
{"title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "authors": "Han Ding, Yinheng Li, Junhao Wang, Hang Chen", "url": "https://api.semanticscholar.org/CorpusId:271860230", "relevance": 1, "abstract": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude. With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders. In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading. We summarize the common architecture used in the agent, the data inputs, and the performance of LLM trading agents in backtesting as well as the challenges presented in these research. This survey aims to provide insights into the current state of LLM-based financial trading agents and outline future research directions in this field.", "citations": 53}
{"title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "authors": "Junyu Luo, Weizhi Zhang, Ye Yuan, Yusheng Zhao, Junwei Yang, Yiyang Gu, Bohan Wu, Binqi Chen, Ziyue Qiao, Qingqing Long, Rongcheng Tu, Xiaoming Luo, Wei Ju, Zhiping Xiao, Yifan Wang, Mengxue Xiao, Chenwu Liu, Jingyang Yuan, Shichang Zhang, Yiqiao Jin, Fan Zhang, Xianhong Wu, Hanqing Zhao, Dacheng Tao, Philip S. Yu, Ming Zhang", "url": "https://api.semanticscholar.org/CorpusId:277350072", "relevance": 1, "abstract": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models. Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence. This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways. We unify fragmented research threads by revealing fundamental connections between agent design principles and their emergent behaviors in complex environments. Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains. By surveying the latest developments in this rapidly evolving field, we offer researchers a structured taxonomy for understanding LLM agents and identify promising directions for future research. The collection is available at https://github.com/luo-junyu/Awesome-Agent-Papers.", "citations": 112}
{"title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent", "year": 2024, "authors": "Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K. Subbalakshmi, Guojun Xiong, Jimin Huang, Lingfei Qian, Xueqing Peng, Qianqian Xie, Jordan W. Suchow", "url": "https://api.semanticscholar.org/CorpusId:274992211", "relevance": 1, "abstract": "Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and (2) the absence of standardized benchmarks and consistent datasets for assessing agent performance. To tackle these issues, we introduce \\textsc{InvestorBench}, the first benchmark specifically designed for evaluating LLM-based agents in diverse financial decision-making contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing a comprehensive suite of tasks applicable to different financial products, including single equities like stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we assess the reasoning and decision-making capabilities of our agent framework using thirteen different LLMs as backbone models, across various market environments and tasks. Furthermore, we have curated a diverse collection of open-source, multi-modal datasets and developed a comprehensive suite of environments for financial decision-making. This establishes a highly accessible platform for evaluating financial agents' performance across various scenarios.", "citations": 26}
{"title": "FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models", "year": 2024, "authors": "Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Chris Wang", "url": "https://api.semanticscholar.org/CorpusId:269983596", "relevance": 1, "abstract": "As financial institutions and professionals increasingly incorporate Large Language Models (LLMs) into their workflows, substantial barriers, including proprietary data and specialized knowledge, persist between the finance sector and the AI community. These challenges impede the AI community's ability to enhance financial tasks effectively. Acknowledging financial analysis's critical role, we aim to devise financial-specialized LLM-based toolchains and democratize access to them through open-source initiatives, promoting wider AI adoption in financial decision-making. In this paper, we introduce FinRobot, a novel open-source AI agent platform supporting multiple financially specialized AI agents, each powered by LLM. Specifically, the platform consists of four major layers: 1) the Financial AI Agents layer that formulates Financial Chain-of-Thought (CoT) by breaking sophisticated financial problems down into logical sequences; 2) the Financial LLM Algorithms layer dynamically configures appropriate model application strategies for specific tasks; 3) the LLMOps and DataOps layer produces accurate models by applying training/fine-tuning techniques and using task-relevant data; 4) the Multi-source LLM Foundation Models layer that integrates various LLMs and enables the above layers to access them directly. Finally, FinRobot provides hands-on for both professional-grade analysts and laypersons to utilize powerful AI techniques for advanced financial analysis. We open-source FinRobot at \\url{https://github.com/AI4Finance-Foundation/FinRobot}.", "citations": 34}
{"title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading", "year": 2025, "authors": "Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie", "url": "https://api.semanticscholar.org/CorpusId:276408244", "relevance": 1, "abstract": "Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose \\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.", "citations": 17}
{"title": "From Deep Learning to LLMs: A survey of AI in Quantitative Investment", "year": 2025, "authors": "Bokai Cao, Sai Wang, Xinyi Lin, Xiaojun Wu, Haohan Zhang, Lionel M. Ni, Jian Guo", "url": "https://api.semanticscholar.org/CorpusId:277349765", "relevance": 1, "abstract": "Quantitative investment (quant) is an emerging, technology-driven approach in asset management, increasingy shaped by advancements in artificial intelligence. Recent advances in deep learning and large language models (LLMs) for quant finance have improved predictive modeling and enabled agent-based automation, suggesting a potential paradigm shift in this field. In this survey, taking alpha strategy as a representative example, we explore how AI contributes to the quantitative investment pipeline. We first examine the early stage of quant research, centered on human-crafted features and traditional statistical models with an established alpha pipeline. We then discuss the rise of deep learning, which enabled scalable modeling across the entire pipeline from data processing to order execution. Building on this, we highlight the emerging role of LLMs in extending AI beyond prediction, empowering autonomous agents to process unstructured data, generate alphas, and support self-iterative workflows.", "citations": 12}
{"title": "FinVision: A Multi-Agent Framework for Stock Market Prediction", "year": 2024, "authors": "Sorouralsadat Fatemi, Yuheng Hu", "url": "https://api.semanticscholar.org/CorpusId:274023255", "relevance": 1, "abstract": "Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candlestick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework.", "citations": 19}
{"title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations", "year": 2025, "authors": "Alejandro Lopez-Lira", "url": "https://api.semanticscholar.org/CorpusId:277787336", "relevance": 1, "abstract": "This paper presents a realistic simulated stock market where large language models (LLMs) act as heterogeneous competing trading agents. The open-source framework incorporates a persistent order book with market and limit orders, partial fills, dividends, and equilibrium clearing alongside agents with varied strategies, information sets, and endowments. Agents submit standardized decisions using structured outputs and function calls while expressing their reasoning in natural language. Three findings emerge: First, LLMs demonstrate consistent strategy adherence and can function as value investors, momentum traders, or market makers per their instructions. Second, market dynamics exhibit features of real financial markets, including price discovery, bubbles, underreaction, and strategic liquidity provision. Third, the framework enables analysis of LLMs' responses to varying market conditions, similar to partial dependence plots in machine-learning interpretability. The framework allows simulating financial theories without closed-form solutions, creating experimental designs that would be costly with human participants, and establishing how prompts can generate correlated behaviors affecting market stability.", "citations": 9}
{"title": "When AI Meets Finance (StockAgent): Large Language Model-based Stock Trading in Simulated Real-world Environments", "year": 2024, "authors": "Chong Zhang, Xinyi Liu, Mingyu Jin, Zhongmou Zhang, Lingyao Li, Zhengting Wang, Wenyue Hua, Dong Shu, Suiyuan Zhu, Xiaobo Jin, Sujian Li, Mengnan Du, Yongfeng Zhang", "url": "https://api.semanticscholar.org/CorpusId:271533952", "relevance": 1, "abstract": "Can AI Agents simulate real-world trading environments to investigate the impact of external factors on stock trading activities (e.g., macroeconomics, policy changes, company fundamentals, and global events)? These factors, which frequently influence trading behaviors, are critical elements in the quest for maximizing investors' profits. Our work attempts to solve this problem through large language model based agents. We have developed a multi-agent AI system called StockAgent, driven by LLMs, designed to simulate investors' trading behaviors in response to the real stock market. The StockAgent allows users to evaluate the impact of different external factors on investor trading and to analyze trading behavior and profitability effects. Additionally, StockAgent avoids the test set leakage issue present in existing trading simulation systems based on AI Agents. Specifically, it prevents the model from leveraging prior knowledge it may have acquired related to the test data. We evaluate different LLMs under the framework of StockAgent in a stock trading environment that closely resembles real-world conditions. The experimental results demonstrate the impact of key external factors on stock market trading, including trading behavior and stock price fluctuation rules. This research explores the study of agents' free trading gaps in the context of no prior knowledge related to market data. The patterns identified through StockAgent simulations provide valuable insights for LLM-based investment advice and stock recommendation. The code is available at https://github.com/MingyuJ666/Stockagent.", "citations": 23}
{"title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "authors": "Shangheng Du, Jiabao Zhao, Jinxin Shi, Zhentao Xie, Xin Jiang, Yanhong Bai, Liang He", "url": "https://api.semanticscholar.org/CorpusId:277065966", "relevance": 1, "abstract": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness in complex agent-related environments. Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective remains lacking. In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods. We first focus on parameter-driven optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that optimize agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the evaluation for agents, review key applications of LLM-based agents, and discuss the major challenges and promising future directions. A curated collection of the surveyed works is provided at https://github.com/YoungDubbyDu/LLM-Agent-Optimization.", "citations": 21}
{"title": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents", "year": 2025, "authors": "Lingfei Qian, Xueqing Peng, Yan Wang, Vincent J. Zhang, Huan He, Hanley Smith, Yi Han, Yueru He, Haohang Li, Yupeng Cao, Yangyang Yu, Alejandro Lopez-Lira, Peng Lu, Jian-yun Nie, Guojun Xiong, Jimin Huang, Sophia Ananiadou", "url": "https://api.semanticscholar.org/CorpusId:282057127", "relevance": 1, "abstract": "Although Large Language Model (LLM)-based agents are increasingly used in financial trading, it remains unclear whether they can reason and adapt in live markets, as most studies test models instead of agents, cover limited periods and assets, and rely on unverified data. To address these gaps, we introduce Agent Market Arena (AMA), the first lifelong, real-time benchmark for evaluating LLM-based trading agents across multiple markets. AMA integrates verified trading data, expert-checked news, and diverse agent architectures within a unified trading framework, enabling fair and continuous comparison under real conditions. It implements four agents, including InvestorAgent as a single-agent baseline, TradeAgent and HedgeFundAgent with different risk styles, and DeepFundAgent with memory-based reasoning, and evaluates them across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets demonstrate that agent frameworks display markedly distinct behavioral patterns, spanning from aggressive risk-taking to conservative decision-making, whereas model backbones contribute less to outcome variation. AMA thus establishes a foundation for rigorous, reproducible, and continuously evolving evaluation of financial reasoning and trading intelligence in LLM-based agents.", "citations": 1}
{"title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "year": 2025, "authors": "Sedigheh Mahdavi, Jiating Chen, Pradeep Kumar Joshi, L. H. Guativa, Upmanyu Singh", "url": "https://api.semanticscholar.org/CorpusId:278900379", "relevance": 1, "abstract": "Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.", "citations": 5}
{"title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions", "year": 2025, "authors": "Dimitrios Emmanoulopoulos, Ollie Olby, Justin Lyon, Namid R Stillman", "url": "https://api.semanticscholar.org/CorpusId:280281425", "relevance": 1, "abstract": "Large language models (LLMs) are increasingly deployed in agentic frameworks, in which prompts trigger complex tool-based analysis in pursuit of a goal. While these frameworks have shown promise across multiple domains including in finance, they typically lack a principled model-building step, relying instead on sentiment- or trend-based analysis. We address this gap by developing an agentic system that uses LLMs to iteratively discover stochastic differential equations for financial time series. These models generate risk metrics which inform daily trading decisions. We evaluate our system in both traditional backtests and using a market simulator, which introduces synthetic but causally plausible price paths and news events. We find that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios across multiple equities. Our results show that combining LLMs with agentic model discovery enhances market risk estimation and enables more profitable trading decisions.", "citations": 2}
{"title": "Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews", "year": 2025, "authors": "Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan", "url": "https://api.semanticscholar.org/CorpusId:276250133", "relevance": 1, "abstract": "The advent of large language models has ushered in a new era of agentic systems, where artificial intelligence programs exhibit remarkable autonomous decision-making capabilities across diverse domains. This paper explores agentic system workflows in the financial services industry. In particular, we build agentic crews with human-in-the-loop module that can effectively collaborate to perform complex modeling and model risk management (MRM) tasks. The modeling crew consists of a judge agent and multiple agents who perform specific tasks such as exploratory data analysis, feature engineering, model selection/hyperparameter tuning, model training, model evaluation, and writing documentation. The MRM crew consists of a judge agent along with specialized agents who perform tasks such as checking compliance of modeling documentation, model replication, conceptual soundness, analysis of outcomes, and writing documentation. We demonstrate the effectiveness and robustness of modeling and MRM crews by presenting a series of numerical examples applied to credit card fraud detection, credit card approval, and portfolio credit risk modeling datasets.", "citations": 20}
{"title": "Shifting Power: Leveraging LLMs to Simulate Human Aversion in ABMs of Bilateral Financial Exchanges, A bond market study", "year": 2025, "authors": "Alicia Vidler, Toby Walsh", "url": "https://api.semanticscholar.org/CorpusId:276741474", "relevance": 1, "abstract": "Bilateral markets, such as those for government bonds, involve decentralized and opaque transactions between market makers (MMs) and clients, posing significant challenges for traditional modeling approaches. To address these complexities, we introduce TRIBE an agent-based model (ABM) augmented with a large language model (LLM) to simulate human-like decision-making in trading environments. TRIBE leverages publicly available data and stylized facts to capture realistic trading dynamics, integrating human biases like risk aversion and ambiguity sensitivity into the decision-making processes of agents. Our research yields three key contributions: first, we demonstrate that integrating LLMs into ABMs, to enhance client agency, is feasible and enriches the simulation of agent behaviors in complex markets; second, we find that even slight trade aversion encoded within the LLM leads to a complete cessation of trading activity, highlighting the sensitivity of market dynamics to agents' risk profiles; third, we show that incorporating human-like variability shifts power dynamics towards clients and can disproportionately affect the entire system, often resulting in systemic agent collapse across simulations. These findings underscore the emergent properties that arise when introducing stochastic, human-like decision processes, revealing new system behaviors that enhance the realism and complexity of artificial trading societies.", "citations": 1}
{"title": "An Adaptive Multi Agent Bitcoin Trading System", "year": 2025, "authors": "Aadi Singhi", "url": "https://api.semanticscholar.org/CorpusId:281950923", "relevance": 1, "abstract": "This paper presents a Multi Agent Bitcoin Trading system that utilizes Large Language Models (LLMs) for alpha generation and portfolio management in the cryptocurrencies market. Unlike equities, cryptocurrencies exhibit extreme volatility and are heavily influenced by rapidly shifting market sentiments and regulatory announcements, making them difficult to model using static regression models or neural networks trained solely on historical data. The proposed framework overcomes this by structuring LLMs into specialised agents for technical analysis, sentiment evaluation, decision-making, and performance reflection. The agents improve over time via a novel verbal feedback mechanism where a Reflect agent provides daily and weekly natural-language critiques of trading decisions. These textual evaluations are then injected into future prompts of the agents, allowing them to adjust allocation logic without weight updates or finetuning. Back-testing on Bitcoin price data from July 2024 to April 2025 shows consistent outperformance across market regimes: the Quantitative agent delivered over 30\\% higher returns in bullish phases and 15\\% overall gains versus buy-and-hold, while the sentiment-driven agent turned sideways markets from a small loss into a gain of over 100\\%. Adding weekly feedback further improved total performance by 31\\% and reduced bearish losses by 10\\%. The results demonstrate that verbal feedback represents a new, scalable, and low-cost approach of tuning LLMs for financial goals.", "citations": 0}
{"title": "FINRS: A Risk-Sensitive Trading Framework for Real Financial Markets", "year": 2025, "authors": "Bijia Liu, Ronghao Dang", "url": "https://api.semanticscholar.org/CorpusId:283072776", "relevance": 1, "abstract": "Large language models (LLMs) have shown strong reasoning capabilities and are increasingly explored for financial trading. Existing LLM-based trading agents, however, largely focus on single-step prediction and lack integrated mechanisms for risk management, which reduces their effectiveness in volatile markets. We introduce FinRS, a risk-sensitive trading framework that combines hierarchical market analysis, dual-decision agents, and multi-timescale reward reflection to align trading actions with both return objectives and downside risk constraints. Experiments on multiple stocks and market conditions show that FinRS achieves superior profitability and stability compared to state-of-the-art methods.", "citations": 0}
{"title": "Large Language Models in equity markets: applications, techniques, and insights", "year": 2025, "authors": "Aakanksha Jadhav, Vishal Mirza", "url": "https://api.semanticscholar.org/CorpusId:280955402", "relevance": 1, "abstract": "Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.", "citations": 10}
{"title": "TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis", "year": 2025, "authors": "Feng Tian, Flora D. Salim, Hao Xue", "url": "https://api.semanticscholar.org/CorpusId:280711571", "relevance": 1, "abstract": "Recent advancements in large language models (LLMs) have enabled powerful agent-based applications in finance, particularly for sentiment analysis, financial report comprehension, and stock forecasting. However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. These data are crucial for agents to understand the market dynamics, improve the quality of decision-making and promote effective coordination. We introduce TradingGroup, a multi-agent trading system designed to address these limitations through a self-reflective architecture and an end-to-end data-synthesis pipeline. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferences to produce buy, sell or hold decisions. Specifically, we design self-reflection mechanisms for the stock forecasting, style, and decision-making agents to distill past successes and failures for similar reasoning in analogous future scenarios and a dynamic risk-management model to offer configurable dynamic stop-loss and take-profit mechanisms. In addition, TradingGroup embeds an automated data-synthesis and annotation pipeline that generates high-quality post-training data for further improving the agent performance through post-training. Our backtesting experiments across five real-world stock datasets demonstrate TradingGroup's superior performance over rule-based, machine learning, reinforcement learning, and existing LLM-based trading strategies.", "citations": 3}
{"title": "The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents", "year": 2025, "authors": "Mohammad Rubyet Islam", "url": "https://api.semanticscholar.org/CorpusId:278782847", "relevance": 1, "abstract": "The pursuit of alpha returns that exceed market benchmarks has undergone a profound transformation, evolving from intuition-driven investing to autonomous, AI powered systems. This paper introduces a comprehensive five stage taxonomy that traces this progression across manual strategies, statistical models, classical machine learning, deep learning, and agentic architectures powered by large language models (LLMs). Unlike prior surveys focused narrowly on modeling techniques, this review adopts a system level lens, integrating advances in representation learning, multimodal data fusion, and tool augmented LLM agents. The strategic shift from static predictors to contextaware financial agents capable of real time reasoning, scenario simulation, and cross modal decision making is emphasized. Key challenges in interpretability, data fragility, governance, and regulatory compliance areas critical to production deployment are examined. The proposed taxonomy offers a unified framework for evaluating maturity, aligning infrastructure, and guiding the responsible development of next generation alpha systems.", "citations": 4}
{"title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking", "year": 2025, "authors": "Changlun Li, Yao Shi, Chen Wang, Qiqi Duan, Runke Ruan, Weijie Huang, Haonan Long, Lijun Huang, Yuyu Luo, Nan Tang", "url": "https://api.semanticscholar.org/CorpusId:278715123", "relevance": 1, "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across financial tasks, including financial report summarization, earnings call transcript analysis, and asset classification. However, their real-world effectiveness in managing complex fund investment remains inadequately assessed. A fundamental limitation of existing benchmarks for evaluating LLM-driven trading strategies is their reliance on historical back-testing, inadvertently enabling LLMs to\"time travel\"-leveraging future information embedded in their training corpora, thus resulting in possible information leakage and overly optimistic performance estimates. To address this issue, we introduce DeepFund, a live fund benchmark tool designed to rigorously evaluate LLM in real-time market conditions. Utilizing a multi-agent architecture, DeepFund connects directly with real-time stock market data-specifically data published after each model pretraining cutoff-to ensure fair and leakage-free evaluations. Empirical tests on nine flagship LLMs from leading global institutions across multiple investment dimensions-including ticker-level analysis, investment decision-making, portfolio management, and risk control-reveal significant practical challenges. Notably, even cutting-edge models such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses within DeepFund real-time evaluation environment, underscoring the present limitations of LLMs for active fund management. Our code is available at https://github.com/HKUSTDial/DeepFund.", "citations": 6}
{"title": "Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges", "year": 2025, "authors": "Liyuan Chen, Shuoling Liu, Jiangpeng Yan, Xiaoyu Wang, Henglin Liu, Chuang Li, Kechen Jiao, Jixuan Ying, Yang Liu, Qiang Yang, Xiu Li", "url": "https://api.semanticscholar.org/CorpusId:280017319", "relevance": 1, "abstract": "", "citations": 2}
{"title": "Bridging Language Models and Financial Analysis", "year": 2025, "authors": "Alejandro Lopez-Lira, Jihoon Kwon, Sangwoong Yoon, Jy-yong Sohn, Chanyeol Choi", "url": "https://api.semanticscholar.org/CorpusId:277451826", "relevance": 1, "abstract": "The rapid advancements in Large Language Models (LLMs) have unlocked transformative possibilities in natural language processing, particularly within the financial sector. Financial data is often embedded in intricate relationships across textual content, numerical tables, and visual charts, posing challenges that traditional methods struggle to address effectively. However, the emergence of LLMs offers new pathways for processing and analyzing this multifaceted data with increased efficiency and insight. Despite the fast pace of innovation in LLM research, there remains a significant gap in their practical adoption within the finance industry, where cautious integration and long-term validation are prioritized. This disparity has led to a slower implementation of emerging LLM techniques, despite their immense potential in financial applications. As a result, many of the latest advancements in LLM technology remain underexplored or not fully utilized in this domain. This survey seeks to bridge this gap by providing a comprehensive overview of recent developments in LLM research and examining their applicability to the financial sector. Building on previous survey literature, we highlight several novel LLM methodologies, exploring their distinctive capabilities and their potential relevance to financial data analysis. By synthesizing insights from a broad range of studies, this paper aims to serve as a valuable resource for researchers and practitioners, offering direction on promising research avenues and outlining future opportunities for advancing LLM applications in finance.", "citations": 5}
{"title": "Automate Strategy Finding with LLM in Quant investment", "year": 2024, "authors": "Zhizhuo Kou, Holam Yu, Jingshu Peng, Lei Chen", "url": "https://api.semanticscholar.org/CorpusId:272550540", "relevance": 1, "abstract": "We present a novel three-stage framework leveraging Large Language Models (LLMs) within a risk-aware multi-agent system for automate strategy finding in quantitative finance. Our approach addresses the brittleness of traditional deep learning models in financial applications by: employing prompt-engineered LLMs to generate executable alpha factor candidates across diverse financial data, implementing multimodal agent-based evaluation that filters factors based on market status, predictive quality while maintaining category balance, and deploying dynamic weight optimization that adapts to market conditions. Experimental results demonstrate the robust performance of the strategy in Chinese&US market regimes compared to established benchmarks. Our work extends LLMs capabilities to quantitative trading, providing a scalable architecture for financial signal extraction and portfolio construction. The overall framework significantly outperforms all benchmarks with 53.17% cumulative return on SSE50 (Jan 2023 to Jan 2024), demonstrating superior risk-adjusted performance and downside protection on the market.", "citations": 24}
{"title": "AI-Trader: Benchmarking Autonomous Agents in Real-Time Financial Markets", "year": 2025, "authors": "Tianyu Fan, Yuhao Yang, Ya Jiang, Yifei Zhang, Yuxuan Chen, Chao Huang", "url": "https://api.semanticscholar.org/CorpusId:283883436", "relevance": 1, "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential as autonomous agents, approaching human-expert performance through advanced reasoning and tool orchestration. However, decision-making in fully dynamic and live environments remains highly challenging, requiring real-time information integration and adaptive responses. While existing efforts have explored live evaluation mechanisms in structured tasks, a critical gap remains in systematic benchmarking for real-world applications, particularly in finance where stringent requirements exist for live strategic responsiveness. To address this gap, we introduce AI-Trader, the first fully-automated, live, and data-uncontaminated evaluation benchmark for LLM agents in financial decision-making. AI-Trader spans three major financial markets: U.S. stocks, A-shares, and cryptocurrencies, with multiple trading granularities to simulate live financial environments. Our benchmark implements a revolutionary fully autonomous minimal information paradigm where agents receive only essential context and must independently search, verify, and synthesize live market information without human intervention. We evaluate six mainstream LLMs across three markets and multiple trading frequencies. Our analysis reveals striking findings: general intelligence does not automatically translate to effective trading capability, with most agents exhibiting poor returns and weak risk management. We demonstrate that risk control capability determines cross-market robustness, and that AI trading strategies achieve excess returns more readily in highly liquid markets than policy-driven environments. These findings expose critical limitations in current autonomous agents and provide clear directions for future improvements. The code and evaluation data are open-sourced to foster community research: https://github.com/HKUDS/AI-Trader.", "citations": 2}
{"title": "Agent Trading Arena: A Study on Numerical Understanding in LLM-Based Agents", "year": 2025, "authors": "Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou", "url": "https://api.semanticscholar.org/CorpusId:276580341", "relevance": 1, "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language tasks, yet their performance in dynamic, real-world financial environments remains underexplored. Existing approaches are limited to historical backtesting, where trading actions cannot influence market prices and agents train only on static data. To address this limitation, we present the Agent Trading Arena, a virtual zero-sum stock market in which LLM-based agents engage in competitive multi-agent trading and directly impact price dynamics. By simulating realistic bid-ask interactions, our platform enables training in scenarios that closely mirror live markets, thereby narrowing the gap between training and evaluation. Experiments reveal that LLMs struggle with numerical reasoning when given plain-text data, often overfitting to local patterns and recent values. In contrast, chart-based visualizations significantly enhance both numerical reasoning and trading performance. Furthermore, incorporating a reflection module yields additional improvements, especially with visual inputs. Evaluations on NASDAQ and CSI datasets demonstrate the superiority of our method, particularly under high volatility. All code and data are available at https://github.com/wekjsdvnm/Agent-Trading-Arena.", "citations": 3}
{"title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models", "year": 2025, "authors": "Haofei Yu, Fenghai Li, Jiaxuan You", "url": "https://api.semanticscholar.org/CorpusId:282758249", "relevance": 1, "abstract": "Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty.", "citations": 3}
{"title": "Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading", "year": 2025, "authors": "Zifan Song, Kaitao Song, Guosheng Hu, Ding Qi, Junyao Gao, Xiaohua Wang, Dongsheng Li, Cairong Zhao", "url": "https://api.semanticscholar.org/CorpusId:281842508", "relevance": 1, "abstract": "Recent advancements in large language models (LLMs) and agentic systems have shown exceptional decision-making capabilities, revealing significant potential for autonomic finance. Current financial trading agents predominantly simulate anthropomorphic roles that inadvertently introduce emotional biases and rely on peripheral information, while being constrained by the necessity for continuous inference during deployment. In this paper, we pioneer the harmonization of strategic depth in agents with the mechanical rationality essential for quantitative trading. Consequently, we present TiMi (Trade in Minutes), a rationality-driven multi-agent system that architecturally decouples strategy development from minute-level deployment. TiMi leverages specialized LLM capabilities of semantic analysis, code programming, and mathematical reasoning within a comprehensive policy-optimization-deployment chain. Specifically, we propose a two-tier analytical paradigm from macro patterns to micro customization, layered programming design for trading bot implementation, and closed-loop optimization driven by mathematical reflection. Extensive evaluations across 200+ trading pairs in stock and cryptocurrency markets empirically validate the efficacy of TiMi in stable profitability, action efficiency, and risk control under volatile market dynamics.", "citations": 1}
{"title": "FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment", "year": 2025, "authors": "Wentao Zhang, Yilei Zhao, Chuqiao Zong, Xinrun Wang, Bo An", "url": "https://api.semanticscholar.org/CorpusId:280421572", "relevance": 1, "abstract": "Financial AI holds great promise for transforming modern finance, with the potential to support a wide range of tasks such as market forecasting, portfolio management, quantitative trading, and automated analysis. However, existing platforms remain limited in task coverage, lack robust multimodal data integration, and offer insufficient support for the training and deployment of large language models (LLMs). In response to these limitations, we present FinWorld, an all-in-one open-source platform that provides end-to-end support for the entire financial AI workflow, from data acquisition to experimentation and deployment. FinWorld distinguishes itself through native integration of heterogeneous financial data, unified support for diverse AI paradigms, and advanced agent automation, enabling seamless development and deployment. Leveraging data from 2 representative markets, 4 stock pools, and over 800 million financial data points, we conduct comprehensive experiments on 4 key financial AI tasks. These experiments systematically evaluate deep learning and reinforcement learning algorithms, with particular emphasis on RL-based finetuning for LLMs and LLM Agents. The empirical results demonstrate that FinWorld significantly enhances reproducibility, supports transparent benchmarking, and streamlines deployment, thereby providing a strong foundation for future research and real-world applications. Code is available at Github~\\footnote{https://github.com/DVampire/FinWorld}.", "citations": 2}
{"title": "FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making", "year": 2025, "authors": "Jiaxiang Chen, Mingxi Zou, Zhuo Wang, Qifan Wang, Dongning Sun, Chi Zhang, Zenglin Xu", "url": "https://api.semanticscholar.org/CorpusId:279305641", "relevance": 1, "abstract": "Financial decision-making presents unique challenges for language models, demanding temporal reasoning, adaptive risk assessment, and responsiveness to dynamic events. While large language models (LLMs) show strong general reasoning capabilities, they often fail to capture behavioral patterns central to human financial decisions-such as expert reliance under information asymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We propose FinHEAR, a multi-agent framework for Human Expertise and Adaptive Risk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to analyze historical trends, interpret current events, and retrieve expert-informed precedents within an event-centric pipeline. Grounded in behavioral economics, it incorporates expert-guided retrieval, confidence-adjusted position sizing, and outcome-based refinement to enhance interpretability and robustness. Empirical results on curated financial datasets show that FinHEAR consistently outperforms strong baselines across trend prediction and trading tasks, achieving higher accuracy and better risk-adjusted returns.", "citations": 0}
{"title": "Agent-Based Simulation of a Financial Market with Large Language Models", "year": 2025, "authors": "Ryuji Hashimoto, Takehiro Takayanagi, Masahiro Suzuki, Kiyoshi Izumi", "url": "https://api.semanticscholar.org/CorpusId:282064483", "relevance": 1, "abstract": "In real-world stock markets, certain chart patterns -- such as price declines near historical highs -- cannot be fully explained by fundamentals alone. These phenomena suggest the presence of path dependence in price formation, where investor decisions are influenced not only by current market conditions but also by the trajectory of prices leading up to the present. Path dependence has drawn attention in behavioral finance as a key mechanism behind such anomalies. One plausible driver of path dependence is human loss aversion, anchored to individual reference points like purchase prices or past peaks, which vary with personal context. However, capturing such subtle behavioral tendencies in traditional agent-based market simulations has remained a challenge. We propose the Fundamental-Chartist-LLM-Agent (FCLAgent), which uses large language models (LLMs) to emulate human-like trading decisions. In this framework, (1) buy/sell decisions are made by LLMs based on individual situations, while (2) order price and volume follow standard rule-based methods. Simulations show that FCLAgents reproduce path-dependent patterns that conventional agents fail to capture. Furthermore, an analysis of FCLAgents'behavior reveals that the reference points guiding loss aversion vary with market trajectories, highlighting the potential of LLM-based agents to model nuanced investor behavior.", "citations": 1}
{"title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "year": 2025, "authors": "Taian Guo, Haiyang Shen, Jinsheng Huang, Zhengyan Mao, Junyu Luo, Zhuorui Chen, Xuhui Liu, Bingyu Xia, Luchen Liu, Yun Ma, Ming Zhang", "url": "https://api.semanticscholar.org/CorpusId:278636281", "relevance": 1, "abstract": "The application of LLM-based agents in financial investment has shown significant promise, yet existing approaches often require intermediate steps like predicting individual stock movements or rely on predefined, static workflows. These limitations restrict their adaptability and effectiveness in constructing optimal portfolios. In this paper, we introduce the Multi-Agent Scaling Simulation (MASS), a novel framework that leverages multi-agent simulation for direct, end-to-end portfolio construction. At its core, MASS employs a backward optimization process to dynamically learn the optimal distribution of heterogeneous agents, enabling the system to adapt to evolving market regimes. A key finding enabled by our framework is the exploration of the scaling effect for portfolio construction: we demonstrate that as the number of agents increases exponentially (up to 512), the aggregated decisions yield progressively higher excess returns. Extensive experiments on a challenging, self-collected dataset from the 2023 Chinese A-share market show that MASS consistently outperforms seven state-of-the-art baselines. Further backtesting, stability analyses and the experiment on data leakage concerns validate its enhanced profitability and robustness. We have open-sourced our code, dataset, and training snapshots at https://github.com/gta0804/MASS/ to foster further research.", "citations": 8}
{"title": "A Survey of Financial AI: Architectures, Advances and Open Challenges", "year": 2024, "authors": "Junhua Liu", "url": "https://api.semanticscholar.org/CorpusId:274149777", "relevance": 1, "abstract": "Financial AI empowers sophisticated approaches to financial market forecasting, portfolio optimization, and automated trading. This survey provides a systematic analysis of these developments across three primary dimensions: predictive models that capture complex market dynamics, decision-making frameworks that optimize trading and investment strategies, and knowledge augmentation systems that leverage unstructured financial information. We examine significant innovations including foundation models for financial time series, graph-based architectures for market relationship modeling, and hierarchical frameworks for portfolio optimization. Analysis reveals crucial trade-offs between model sophistication and practical constraints, particularly in high-frequency trading applications. We identify critical gaps and open challenges between theoretical advances and industrial implementation, outlining open challenges and opportunities for improving both model performance and practical applicability.", "citations": 10}
{"title": "ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism", "year": 2025, "authors": "Li Zhao, Rui Sun, Zuoyou Jiang, Bo Yang, Yuxiao Bai, Mengting Chen, Xinyang Wang, Jing Li, Zuo Bai", "url": "https://api.semanticscholar.org/CorpusId:280416769", "relevance": 1, "abstract": "In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate management structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and condensing massive market data into diversified text factors, ensuring they fit the model's constrained context. (2) Research Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agent's performance undergoes continuous scoring and ranking, with only outputs from top-performing agents being adopted. The design enables the system to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers superior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at https://github.com/FinStep-AI/ContestTrade.", "citations": 3}
{"title": "Leveraging LLMS for Top-Down Sector Allocation In Automated Trading", "year": 2025, "authors": "Ryan Quek Wei Heng, Edoardo Vittori, Keane Ong, Rui Mao, Erik Cambria, G. Mengaldo", "url": "https://api.semanticscholar.org/CorpusId:276961799", "relevance": 1, "abstract": "This paper introduces a methodology leveraging Large Language Models (LLMs) for sector-level portfolio allocation through systematic analysis of macroeconomic conditions and market sentiment. Our framework emphasizes top-down sector allocation by processing multiple data streams simultaneously, including policy documents, economic indicators, and sentiment patterns. Empirical results demonstrate superior risk-adjusted returns compared to traditional cross momentum strategies, achieving a Sharpe ratio of 2.51 and portfolio return of 8.79% versus -0.61 and -1.39% respectively. These results suggest that LLM-based systematic macro analysis presents a viable approach for enhancing automated portfolio allocation decisions at the sector level.", "citations": 1}
{"title": "MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading", "year": 2025, "authors": "Siyi Wu, Zhaoyang Guan, Leyi Zhao, Xinyuan Song, Xinyu Ying, Hanlin Zhang, Michele Pak, Yangfan He, Yi Xin, Jianhui Wang, Tianyu Shi", "url": "https://api.semanticscholar.org/CorpusId:280322773", "relevance": 1, "abstract": "Cryptocurrency trading is a challenging task requiring the integration of heterogeneous data from multiple modalities. Traditional deep learning and reinforcement learning approaches typically demand large training datasets and encode diverse inputs into numerical representations, often at the cost of interpretability. Recent progress in large language model (LLM)-based agents has demonstrated the capacity to process multi-modal data and support complex investment decision-making. Building on these advances, we present \\textbf{MountainLion}, a multi-modal, multi-agent system for financial trading that coordinates specialized LLM-based agents to interpret financial data and generate investment strategies. MountainLion processes textual news, candlestick charts, and trading signal charts to produce high-quality financial reports, while also enabling modification of reports and investment recommendations through data-driven user interaction and question answering. A central reflection module analyzes historical trading signals and outcomes to continuously refine decision processes, and the system is capable of real-time report analysis, summarization, and dynamic adjustment of investment strategies. Empirical results confirm that MountainLion systematically enriches technical price triggers with contextual macroeconomic and capital flow signals, providing a more interpretable, robust, and actionable investment framework that improves returns and strengthens investor confidence.", "citations": 1}
{"title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?", "year": 2025, "authors": "Lewen Yan, Jilin Mei, Tianyi Zhou, Lige Huang, Jie Zhang, Dongrui Liu, Jing Shao", "url": "https://api.semanticscholar.org/CorpusId:283458569", "relevance": 1, "abstract": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.", "citations": 1}
{"title": "P1GPT: a multi-agent LLM workflow module for multi-modal financial information analysis", "year": 2025, "authors": "Chen-Che Lu, Yun-Cheng Chou, Teng-Ruei Chen", "url": "https://api.semanticscholar.org/CorpusId:282389311", "relevance": 1, "abstract": "Recent advances in large language models (LLMs) have enabled multi-agent reasoning systems capable of collaborative decision-making. However, in financial analysis, most frameworks remain narrowly focused on either isolated single-agent predictors or loosely connected analyst ensembles, and they lack a coherent reasoning workflow that unifies diverse data modalities. We introduce P1GPT, a layered multi-agent LLM framework for multi-modal financial information analysis and interpretable trading decision support. Unlike prior systems that emulate trading teams through role simulation, P1GPT implements a structured reasoning pipeline that systematically fuses technical, fundamental, and news-based insights through coordinated agent communication and integration-time synthesis. Backtesting on multi-modal datasets across major U.S. equities demonstrates that P1GPT achieves superior cumulative and risk-adjusted returns, maintains low drawdowns, and provides transparent causal rationales. These findings suggest that structured reasoning workflows, rather than agent role imitation, offer a scalable path toward explainable and trustworthy financial AI systems.", "citations": 0}
{"title": "MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial Trading", "year": 2025, "authors": "Yang Chen, Yueheng Jiang, Zhaozhao Ma, Yuchen Cao Jacky Keung, Kun Kuang, Leilei Gan, Yiquan Wu, Fei Wu", "url": "https://api.semanticscholar.org/CorpusId:281194722", "relevance": 1, "abstract": "The inherent non-stationarity of financial markets and the complexity of multi-modal information pose significant challenges to existing quantitative trading models. Traditional methods relying on fixed structures and unimodal data struggle to adapt to market regime shifts, while large language model (LLM)-driven solutions - despite their multi-modal comprehension - suffer from static strategies and homogeneous expert designs, lacking dynamic adjustment and fine-grained decision mechanisms. To address these limitations, we propose MM-DREX: a Multimodal-driven, Dynamically-Routed EXpert framework based on large language models. MM-DREX explicitly decouples market state perception from strategy execution to enable adaptive sequential decision-making in non-stationary environments. Specifically, it (1) introduces a vision-language model (VLM)-powered dynamic router that jointly analyzes candlestick chart patterns and long-term temporal features to allocate real-time expert weights; (2) designs four heterogeneous trading experts (trend, reversal, breakout, positioning) generating specialized fine-grained sub-strategies; and (3) proposes an SFT-RL hybrid training paradigm to synergistically optimize the router's market classification capability and experts'risk-adjusted decision-making. Extensive experiments on multi-modal datasets spanning stocks, futures, and cryptocurrencies demonstrate that MM-DREX significantly outperforms 15 baselines (including state-of-the-art financial LLMs and deep reinforcement learning models) across key metrics: total return, Sharpe ratio, and maximum drawdown, validating its robustness and generalization. Additionally, an interpretability module traces routing logic and expert behavior in real time, providing an audit trail for strategy transparency.", "citations": 1}
{"title": "StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets", "year": 2025, "authors": "Charidimos Papadakis, Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, G. Stamou", "url": "https://api.semanticscholar.org/CorpusId:280265856", "relevance": 1, "abstract": "We present StockSim, an open-source simulation platform for systematic evaluation of large language models (LLMs) in realistic financial decision-making scenarios. Unlike previous toolkits that offer limited scope, StockSim delivers a comprehensive system that fully models market dynamics and supports diverse simulation modes of varying granularity. It incorporates critical real-world factors, such as latency, slippage, and order-book microstructure, that were previously neglected, enabling more faithful and insightful assessment of LLM-based trading agents. An extensible, role-based agent framework supports heterogeneous trading strategies and multi-agent coordination, making StockSim a uniquely capable testbed for NLP research on reasoning under uncertainty and sequential decision-making. We open-source all our code at https: //github.com/harrypapa2002/StockSim.", "citations": 5}
{"title": "LLM-Powered AI Agent Systems and Their Applications in Industry", "year": 2025, "authors": "Guannan Liang, Qianqian Tong", "url": "https://api.semanticscholar.org/CorpusId:278789054", "relevance": 1, "abstract": "The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.", "citations": 18}
{"title": "Adaptive and Explainable Margin Trading via Large Language Models on Portfolio Management", "year": 2024, "authors": "Jingyi Gu, J. Ye, Guiling Wang, Wenpeng Yin", "url": "https://api.semanticscholar.org/CorpusId:274086023", "relevance": 1, "abstract": "Recent strategies for portfolio management often lack flexibility to adjust funds between long and short positions throughout trading periods. This prevents adapting portfolios to the market, which mitigates risks and seizes opportunities. To address these gaps, we propose an adaptive and explainable framework that integrates Large Language Models (LLMs) with Reinforcement Learning (RL) for dynamic long-short position adjustment in response to evolving market conditions. This approach leverages the recent advancements in LLMs for processing unstructured data and their capacity for explainable reasoning. The framework includes two stages: an Explainable Market Forecasting/Reasoning Pipeline, and a Position Reallocation stage. The Market Forecasting/Reasoning Pipeline allows various LLMs to learn market trends from diverse external data sources and determine optimal adjustment ratios with a clear reasoning path. The Portfolio Reallocation stage interacts with the sequential trading process from a pre-trained RL model to enhance decision-making and transparency. Our framework is flexible to accommodate various external data sources from microeconomics to macroeconomics data, diverse data types including time series and news text, along with multiple LLMs. Experiments demonstrate that our framework effectively achieves three times the return and doubles the Sharpe ratio compared to benchmarks. All the data and code are publicly available under NJIT FinTech Lab\u2019s GitHub1.", "citations": 8}
{"title": "AlphaAgents: Large Language Model based Multi-Agents for Equity Portfolio Constructions", "year": 2025, "authors": "Tianjiao Zhao, Jingrao Lyu, Stokes Jones, Harrison Garber, Stefano Pasquali, Dhagash Mehta", "url": "https://api.semanticscholar.org/CorpusId:280671159", "relevance": 1, "abstract": "The field of artificial intelligence (AI) agents is evolving rapidly, driven by the capabilities of Large Language Models (LLMs) to autonomously perform and refine tasks with human-like efficiency and adaptability. In this context, multi-agent collaboration has emerged as a promising approach, enabling multiple AI agents to work together to solve complex challenges. This study investigates the application of role-based multi-agent systems to support stock selection in equity research and portfolio management. We present a comprehensive analysis performed by a team of specialized agents and evaluate their stock-picking performance against established benchmarks under varying levels of risk tolerance. Furthermore, we examine the advantages and limitations of employing multi-agent frameworks in equity analysis, offering critical insights into their practical efficacy and implementation challenges.", "citations": 5}
{"title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "authors": "Anjana Sarkar, S. Sarkar", "url": "https://api.semanticscholar.org/CorpusId:279244795", "relevance": 1, "abstract": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP). It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition. The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks. To clarify these dynamics, the article provides conceptual schematics and formal models that map out communication pathways and optimize data flow. It further explores architectural variations suited to different degrees of agent autonomy and system complexity. Real-world applications in domains such as real-time financial processing and investment banking are discussed, illustrating how these patterns and MCP can meet specific operational demands. The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "citations": 11}
{"title": "Will LLMs be Professional at Fund Investment? DeepFund: A Live Arena Perspective", "year": 2025, "authors": "Changlun Li, Yao Shi, Yuyu Luo, Nan Tang", "url": "https://api.semanticscholar.org/CorpusId:277272186", "relevance": 1, "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, but their effectiveness in financial decision-making remains inadequately evaluated. Current benchmarks primarily assess LLMs'understanding on financial documents rather than the ability to manage assets or dig out trading opportunities in dynamic market conditions. Despite the release of new benchmarks for evaluating diversified tasks on the financial domain, we identified four major problems in these benchmarks, which are data leakage, navel-gazing, over-intervention, and maintenance-hard. To pave the research gap, we introduce DeepFund, a comprehensive arena platform for evaluating LLM-based trading strategies in a live environment. Our approach implements a multi-agent framework where they serve as multiple key roles that realize the real-world investment decision processes. Moreover, we provide a web interface that visualizes LLMs'performance with fund investment metrics across different market conditions, enabling detailed comparative analysis. Through DeepFund, we aim to provide a more realistic and fair assessment on LLM's capabilities in fund investment, offering diversified insights and revealing their potential applications in real-world financial markets. Our code is publicly available at https://github.com/HKUSTDial/DeepFund.", "citations": 2}
{"title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets", "year": 2025, "authors": "Yuzhe Yang, Yifei Zhang, Minghao Wu, Kaidi Zhang, Yunmiao Zhang, Honghai Yu, Yan Hu, Benyou Wang", "url": "https://api.semanticscholar.org/CorpusId:276106819", "relevance": 1, "abstract": "The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.", "citations": 23}
{"title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior", "year": 2025, "authors": "Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, \u2020. H.VickyZhao, Samuel A Assefa, Danial Dervovic, Mahmoud Mahfouz, Robert E Tillman, Prashant Reddy, Manuela Veloso. 2020, Christopher Avery, Peter Zemsky. 1998, Multidimensional, Yuntao Bai, Andy Jones, Kamal K. Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn Drain, Samuel R. Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamil\u02d9e Luko\u0161i\u00afut\u02d9e, Hong-you Chen, Cheng-Hao Tu, Ziwei Li, Han-Wei Shen, Wei-Lun Chao, Team Glm, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, L. Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, S. Cao, Weng Shuxun Yang, Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, Zihan Wang, Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, A. Schelten, Edward J. Hu, Yelong Shen, Zeyuan Phillip Wallis, An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Ke-Yang Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Shujuan Zhao, Lingfeng Qiao, Kangyang Luo, Qianwen Zhang, Junru Lu, Di Yin. 2024, SNFinLLM, Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang", "url": "https://api.semanticscholar.org/CorpusId:280034807", "relevance": 1, "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.", "citations": 1}
{"title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "authors": "Charidimos Papadakis, Angeliki Dimitriou, Giorgos Filandrianos, Maria Lymperaiou, Konstantinos Thomas, G. Stamou", "url": "https://api.semanticscholar.org/CorpusId:282209036", "relevance": 1, "abstract": "Large language models show promise for financial decision-making, yet deploying them as autonomous trading agents raises fundamental challenges: how to adapt instructions when rewards arrive late and obscured by market noise, how to synthesize heterogeneous information streams into coherent decisions, and how to bridge the gap between model outputs and executable market actions. We present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent framework that integrates structured information from markets, news, and corporate fundamentals to support robust trading decisions. Within ATLAS, the central trading agent operates in an order-aware action space, ensuring that outputs correspond to executable market orders rather than abstract signals. The agent can incorporate feedback while trading using Adaptive-OPRO, a novel prompt-optimization technique that dynamically adapts the prompt by incorporating real-time, stochastic feedback, leading to increasing performance over time. Across regime-specific equity studies and multiple LLM families, Adaptive-OPRO consistently outperforms fixed prompts, while reflection-based feedback fails to provide systematic gains.", "citations": 1}
{"title": "When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs", "year": 2025, "authors": "Fangyi Yu", "url": "https://api.semanticscholar.org/CorpusId:280527079", "relevance": 1, "abstract": "As large language models (LLMs) grow in capability and autonomy, evaluating their outputs-especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves. This\"agent-as-a-judge\"approach leverages the reasoning and perspective-taking abilities of LLMs to assess the quality and safety of other models, promising calable and nuanced alternatives to human evaluation. In this review, we define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education. Finally, we highlight pressing challenges-including bias, robustness, and meta evaluation-and outline future research directions. By bringing together these strands, our review demonstrates how agent-based judging can complement (but not replace) human oversight, marking a step toward trustworthy, scalable evaluation for next-generation LLMs.", "citations": 5}
{"title": "FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution", "year": 2026, "authors": "Mingxi Zou, Jiaxiang Chen, Aotian Luo, Jingyi Dai, Chi Zhang, Dongning Sun, Zenglin Xu", "url": "https://api.semanticscholar.org/CorpusId:285270243", "relevance": 1, "abstract": "Conventional financial strategy evaluation relies on isolated backtests in static environments. Such evaluations assess each policy independently, overlook correlations and interactions, and fail to explain why strategies ultimately persist or vanish in evolving markets. We shift to an ecological perspective, where trading strategies are modeled as adaptive agents that interact and learn within a shared market. Instead of proposing a new strategy, we present FinEvo, an ecological game formalism for studying the evolutionary dynamics of multi-agent financial strategies. At the individual level, heterogeneous ML-based traders-rule-based, deep learning, reinforcement learning, and large language model (LLM) agents-adapt using signals such as historical prices and external news. At the population level, strategy distributions evolve through three designed mechanisms-selection, innovation, and environmental perturbation-capturing the dynamic forces of real markets. Together, these two layers of adaptation link evolutionary game theory with modern learning dynamics, providing a principled environment for studying strategic behavior. Experiments with external shocks and real-world news streams show that FinEvo is both stable for reproducibility and expressive in revealing context-dependent outcomes. Strategies may dominate, collapse, or form coalitions depending on their competitors-patterns invisible to static backtests. By reframing strategy evaluation as an ecological game formalism, FinEvo provides a unified, mechanism-level protocol for analyzing robustness, adaptation, and emergent dynamics in multi-agent financial markets, and may offer a means to explore the potential impact of macroeconomic policies and financial regulations on price evolution and equilibrium.", "citations": 0}
{"title": "3S-Trader: A Multi-LLM Framework for Adaptive Stock Scoring, Strategy, and Selection in Portfolio Optimization", "year": 2025, "authors": "Kefan Chen, Hussain Ahmad, Diksha Goel, Claudia Szabo", "url": "https://api.semanticscholar.org/CorpusId:282210119", "relevance": 1, "abstract": "Large Language Models (LLMs) have recently gained popularity in stock trading for their ability to process multimodal financial data. However, most existing methods focus on single-stock trading and lack the capacity to reason over multiple candidates for portfolio construction. Moreover, they typically lack the flexibility to revise their strategies in response to market shifts, limiting their adaptability in real-world trading. To address these challenges, we propose 3S-Trader, a training-free framework that incorporates scoring, strategy, and selection modules for stock portfolio construction. The scoring module summarizes each stock's recent signals into a concise report covering multiple scoring dimensions, enabling efficient comparison across candidates. The strategy module analyzes historical strategies and overall market conditions to iteratively generate an optimized selection strategy. Based on this strategy, the selection module identifies and assembles a portfolio by choosing stocks with higher scores in relevant dimensions. We evaluate our framework across four distinct stock universes, including the Dow Jones Industrial Average (DJIA) constituents and three sector-specific stock sets. Compared with existing multi-LLM frameworks and time-series-based baselines, 3S-Trader achieves the highest accumulated return of 131.83% on DJIA constituents with a Sharpe ratio of 0.31 and Calmar ratio of 11.84, while also delivering consistently strong results across other sectors.", "citations": 3}
{"title": "Profit Mirage: Revisiting Information Leakage in LLM-based Financial Agents", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://www.semanticscholar.org/paper/b31220689481b2b5433956655e93cdf476256d6b", "relevance": 1, "abstract": "LLM-based financial agents have attracted widespread excitement for their ability to trade like human experts. However, most systems exhibit a\"profit mirage\": dazzling back-tested returns evaporate once the model's knowledge window ends, because of the inherent information leakage in LLMs. In this paper, we systematically quantify this leakage issue across four dimensions and release FinLake-Bench, a leakage-robust evaluation benchmark. Furthermore, to mitigate this issue, we introduce FactFin, a framework that applies counterfactual perturbations to compel LLM-based agents to learn causal drivers instead of memorized outcomes. FactFin integrates four core components: Strategy Code Generator, Retrieval-Augmented Generation, Monte Carlo Tree Search, and Counterfactual Simulator. Extensive experiments show that our method surpasses all baselines in out-of-sample generalization, delivering superior risk-adjusted performance.", "citations": 2}
{"title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation", "year": 2026, "authors": "Zeping Li, Guancheng Wan, Keyang Chen, Yu Chen, Yiwen Zhao, Philip Torr, Guangnan Ye, Zhenfei Yin, Hongfeng Chai", "url": "https://www.semanticscholar.org/paper/7550169d076668ede36673525ad2b96baa54fe0a", "relevance": 1, "abstract": "Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents'behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors are typically classified as fundamental or technical traders, but most simulations fix strategies at initialization, failing to reflect real-world trading dynamics. In this work, we assess whether agents'strategy switching aligns with financial theory, providing a framework for this evaluation. We operationalize four behavioral-finance drivers-loss aversion, herding, wealth differentiation, and price misalignment-as personality traits set via prompting and stored long-term. In year-long simulations, agents process daily price-volume data, trade under a designated style, and reassess their strategy every 10 trading days. We introduce four alignment metrics and use Mann-Whitney U tests to compare agents'style-switching behavior with financial theory. Our results show that recent LLMs'switching behavior is only partially consistent with behavioral-finance theories, highlighting the need for further refinement in aligning agent behavior with financial theory.", "citations": 0}
{"title": "Large Language Model Agents for Investment Management: Foundations, Benchmarks, and Research Frontiers", "year": 2025, "authors": "Preetha Saha, Jasmine Lyu, Arnav Saxena, Tianjiao Zhao, Dhagash Mehta", "url": "https://www.semanticscholar.org/paper/a5a80a83cf865a0f854332b02ec26353d436c036", "relevance": 1, "abstract": "Recent advances in Large Language Models (LLMs) have triggered a new wave of intelligent financial agents capable of complex reasoning, tool use, and autonomous decision-making. This survey presents a comprehensive review of LLM-based agents in the context of investment and trading, focusing on applications such as portfolio optimization, risk management, information retrieval, and automated strategy generation. We systematically categorize the literature by use case and architectural innovations including multi-agent collaborations, reflection mechanisms, and tool-augmented pipelines. Additionally, we review emerging evaluation frameworks and benchmark datasets tailored to finance-specific agent tasks. The survey identifies current trends, technical limitations, and open challenges related to robustness, explainability, and real-world deployment. We conclude with emerging directions for building more capable, adaptive, and trustworthy financial AI agents aligned with the demands of modern investment ecosystems.", "citations": 2}
{"title": "Large Language Model Applied in Multi-agent SystemA Survey", "year": 2024, "authors": "Kaiwen Dong", "url": "https://api.semanticscholar.org/CorpusId:274329949", "relevance": 1, "abstract": "Abstract. The application of large language models (LLMs) in single-agent systems within complex environments has proven successful, prompting a growing interest in their use within multi-agent systems (MAS). Despite the impressive capabilities of LLMs, it remains unclear how they can be optimally integrated and utilized to empower agents in MAS. Understanding how to effectively leverage the advantages of LLMs to enhance agent performance is crucial. This survey provides a comprehensive overview of the application of LLMs in MAS, focusing on their impact on agent cooperation, reasoning, and adaptive abilities. Finally, we discuss future directions and open questions in this evolving field.", "citations": 0}
{"title": "Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications", "year": 2024, "authors": "Qianqian Xie, Dong Li, Mengxi Xiao, Zihao Jiang, Ruoyu Xiang, Xiao Zhang, Zhengyu Chen, Yueru He, Weiguang Han, Yuzhe Yang, Shunian Chen, Yifei Zhang, Lihang Shen, Daniel Kim, Zhiwei Liu, Zheheng Luo, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Zhiyuan Yao, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Yilun Zhao, Yitao Long, Guojun Xiong, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Jimin Huang, Sophia Ananiadou", "url": "https://api.semanticscholar.org/CorpusId:271924104", "relevance": 1, "abstract": "Financial LLMs hold promise for advancing financial tasks and domain-specific applications. However, they are limited by scarce corpora, weak multimodal capabilities, and narrow evaluations, making them less suited for real-world application. To address this, we introduce \\textit{Open-FinLLMs}, the first open-source multimodal financial LLMs designed to handle diverse tasks across text, tabular, time-series, and chart data, excelling in zero-shot, few-shot, and fine-tuning settings. The suite includes FinLLaMA, pre-trained on a comprehensive 52-billion-token corpus; FinLLaMA-Instruct, fine-tuned with 573K financial instructions; and FinLLaVA, enhanced with 1.43M multimodal tuning pairs for strong cross-modal reasoning. We comprehensively evaluate Open-FinLLMs across 14 financial tasks, 30 datasets, and 4 multimodal tasks in zero-shot, few-shot, and supervised fine-tuning settings, introducing two new multimodal evaluation datasets. Our results show that Open-FinLLMs outperforms afvanced financial and general LLMs such as GPT-4, across financial NLP, decision-making, and multi-modal tasks, highlighting their potential to tackle real-world challenges. To foster innovation and collaboration across academia and industry, we release all codes (https://anonymous.4open.science/r/PIXIU2-0D70/B1D7/LICENSE) and models under OSI-approved licenses.", "citations": 42}
{"title": "Regret-Driven Portfolios: LLM-Guided Smart Clustering for Optimal Allocation", "year": 2026, "authors": "Muhammad Abro, Hassan Jaleel", "url": "https://api.semanticscholar.org/CorpusId:285050040", "relevance": 1, "abstract": "We attempt to mitigate the persistent tradeoff between risk and return in medium- to long-term portfolio management. This paper proposes a novel LLM-guided no-regret portfolio allocation framework that integrates online learning dynamics, market sentiment indicators, and large language model (LLM)-based hedging to construct high-Sharpe ratio portfolios tailored for risk-averse investors and institutional fund managers. Our approach builds on a follow-the-leader approach, enriched with sentiment-based trade filtering and LLM-driven downside protection. Empirical results demonstrate that our method outperforms a SPY buy-and-hold baseline by 69% in annualized returns and 119% in Sharpe ratio.", "citations": 0}
{"title": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents", "year": 2025, "authors": "George Fatouros, Kostas C. Metaxas, John Soldatos, Manos Karathanassis", "url": "https://api.semanticscholar.org/CorpusId:276094208", "relevance": 1, "abstract": "MarketSenseAI is a novel framework for holistic stock analysis which leverages Large Language Models (LLMs) to process financial news, historical prices, company fundamentals and the macroeconomic environment to support decision making in stock analysis and selection. In this paper, we present the latest advancements on MarketSenseAI, driven by rapid technological expansion in LLMs. Through a novel architecture combining Retrieval-Augmented Generation and LLM agents, the framework processes SEC filings and earnings calls, while enriching macroeconomic analysis through systematic processing of diverse institutional reports. We demonstrate a significant improvement in fundamental analysis accuracy over the previous version. Empirical evaluation on S\\&P 100 stocks over two years (2023-2024) shows MarketSenseAI achieving cumulative returns of 125.9% compared to the index return of 73.5%, while maintaining comparable risk profiles. Further validation on S\\&P 500 stocks during 2024 demonstrates the framework's scalability, delivering a 33.8% higher Sortino ratio than the market. This work marks a significant advancement in applying LLM technology to financial analysis, offering insights into the robustness of LLM-driven investment strategies.", "citations": 11}
{"title": "SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making", "year": 2025, "authors": "Yinsheng Wang, Tario G You, L'eonard Boussioux, Shan Liu", "url": "https://api.semanticscholar.org/CorpusId:283103715", "relevance": 1, "abstract": "This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.", "citations": 0}
{"title": "Design and Empirical Study of a Large Language Model-Based Multi-Agent Investment System for Chinese Public REITs", "year": 2026, "authors": "Zheng Li", "url": "https://www.semanticscholar.org/paper/4f1188a5073c4d475eb959e1a667ad5bc7cb2f1e", "relevance": 1, "abstract": "This study addresses the low-volatility Chinese Public Real Estate Investment Trusts (REITs) market, proposing a large language model (LLM)-driven trading framework based on multi-agent collaboration. The system constructs four types of analytical agents-announcement, event, price momentum, and market-each conducting analysis from different dimensions; then the prediction agent integrates these multi-source signals to output directional probability distributions across multiple time horizons, then the decision agent generates discrete position adjustment signals based on the prediction results and risk control constraints, thereby forming a closed loop of analysis-prediction-decision-execution. This study further compares two prediction model pathways: for the prediction agent, directly calling the general-purpose large model DeepSeek-R1 versus using a specialized small model Qwen3-8B fine-tuned via supervised fine-tuning and reinforcement learning alignment. In the backtest from October 2024 to October 2025, both agent-based strategies significantly outperformed the buy-and-hold benchmark in terms of cumulative return, Sharpe ratio, and maximum drawdown. The results indicate that the multi-agent framework can effectively enhance the risk-adjusted return of REITs trading, and the fine-tuned small model performs close to or even better than the general-purpose large model in some scenarios.", "citations": 0}
{"title": "The New Quant: A Survey of Large Language Models in Financial Prediction and Trading", "year": 2025, "authors": "Weilong Fu", "url": "https://api.semanticscholar.org/CorpusId:281886275", "relevance": 1, "abstract": "Large language models are reshaping quantitative investing by turning unstructured financial information into evidence-grounded signals and executable decisions. This survey synthesizes research with a focus on equity return prediction and trading, consolidating insights from domain surveys and more than fifty primary studies. We propose a task-centered taxonomy that spans sentiment and event extraction, numerical and economic reasoning, multimodal understanding, retrieval-augmented generation, time series prompting, and agentic systems that coordinate tools for research, backtesting, and execution. We review empirical evidence for predictability, highlight design patterns that improve faithfulness such as retrieval first prompting and tool-verified numerics, and explain how signals feed portfolio construction under exposure, turnover, and capacity controls. We assess benchmarks and datasets for prediction and trading and outline desiderata-for time safe and economically meaningful evaluation that reports costs, latency, and capacity. We analyze challenges that matter in production, including temporal leakage, hallucination, data coverage and structure, deployment economics, interpretability, governance, and safety. The survey closes with recommendations for standardizing evaluation, building auditable pipelines, and advancing multilingual and cross-market research so that language-driven systems deliver robust and risk-controlled performance in practice.", "citations": 1}
{"title": "Market-Dependent Communication in Multi-Agent Alpha Generation", "year": 2025, "authors": "Jerick Shi, Burton Hollifield", "url": "https://www.semanticscholar.org/paper/4258cc2fae45b46a80d8a0d836f88d99bef5166b", "relevance": 1, "abstract": "Multi-strategy hedge funds face a fundamental organizational choice: should analysts generating trading strategies communicate, and if so, how? We investigate this using 5-agent LLM-based trading systems across 450 experiments spanning 21 months, comparing five organizational structures from isolated baseline to collaborative and competitive conversation. We show that communication improves performance, but optimal communication design depends on market characteristics. Competitive conversation excels in volatile technology stocks, while collaborative conversation dominates stable general stocks. Finance stocks resist all communication interventions. Surprisingly, all structures, including isolated agents, converge to similar strategy alignments, challenging assumptions that transparency causes harmful diversity loss. Performance differences stem from behavioral mechanisms: competitive agents focus on stock-level allocation while collaborative agents develop technical frameworks. Conversation quality scores show zero correlation with returns. These findings demonstrate that optimal communication design must match market volatility characteristics, and sophisticated discussions don't guarantee better performance.", "citations": 0}
{"title": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "year": 2025, "authors": "Baptiste Lefort, E. Benhamou, B. Guez, J. Ohana, E. Setrouk, Alban Etienne", "url": "https://api.semanticscholar.org/CorpusId:280401014", "relevance": 1, "abstract": "This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.", "citations": 0}
{"title": "Empirical Asset Pricing with Large Language Model Agents", "year": 2024, "authors": "Junyan Cheng, Peter Chin", "url": "https://api.semanticscholar.org/CorpusId:272911122", "relevance": 1, "abstract": "In this study, we introduce a novel asset pricing model leveraging the Large Language Model (LLM) agents, which integrates qualitative discretionary investment evaluations from LLM agents with quantitative financial economic factors manually curated, aiming to explain the excess asset returns. The experimental results demonstrate that our methodology surpasses traditional machine learning-based baselines in both portfolio optimization and asset pricing errors. Notably, the Sharpe ratio for portfolio optimization and the mean magnitude of $|\\alpha|$ for anomaly portfolios experienced substantial enhancements of 10.6\\% and 10.0\\% respectively. Moreover, we performed comprehensive ablation studies on our model and conducted a thorough analysis of the method to extract further insights into the proposed approach. Our results show effective evidence of the feasibility of applying LLMs in empirical asset pricing.", "citations": 1}
{"title": "Leveraging Large Language Models for Institutional Portfolio Management: Persona-Based Ensembles", "year": 2024, "authors": "Yoshia Abe, Shuhei Matsuo, Ryoma Kondo, Ryohei Hisano", "url": "https://api.semanticscholar.org/CorpusId:274423140", "relevance": 1, "abstract": "Large language models (LLMs) have demonstrated promising performance in various financial applications, though their potential in complex investment strategies remains underexplored. To address this gap, we investigate how LLMs can predict price movements in stock and bond portfolios using economic indicators, enabling portfolio adjustments akin to those employed by institutional investors. Additionally, we explore the impact of incorporating different personas within LLMs, using an ensemble approach to leverage their diverse predictions. Our findings show that LLM-based strategies, especially when combined with the mode ensemble, outperform the buy-and-hold strategy in terms of Sharpe ratio during periods of rising consumer price index (CPI). However, traditional strategies are more effective during declining CPI trends or sharp market downturns. These results suggest that while LLMs can enhance portfolio management, they may require complementary strategies to optimize performance across varying market conditions.", "citations": 1}
{"title": "LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization", "year": 2025, "authors": "Bangyu Li, Boping Gu, Ziyang Ding", "url": "https://api.semanticscholar.org/CorpusId:283895913", "relevance": 1, "abstract": "In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender , an integrated framework that combines Large Language Models, reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making.", "citations": 0}
{"title": "Artificial Intelligence Models for Predicting Stock Returns Using Fundamental, Technical, and Entropy-Based Strategies: A Semantic-Augmented Hybrid Approach", "year": 2025, "authors": "Gil Cohen, Avishay Aiche, Ron Eichel", "url": "https://api.semanticscholar.org/CorpusId:278861650", "relevance": 1, "abstract": "This study examines the effectiveness of combining semantic intelligence drawn from large language models (LLMs) such as ChatGPT-4o with traditional machine-learning (ML) algorithms to develop predictive portfolio strategies for NASDAQ-100 stocks over the 2020\u20132025 period. Three different predictive frameworks\u2013\u2013fundamental, technical, and entropy-based\u2013\u2013are tested through examination of novel combinations of ML- and LLM-derived semantic metrics. The empirical results reveal a considerable divergence in optimal blending methods across the methodologies; namely, the technical methodology exhibits the best performance when using only ML predictions, with around 1978% cumulative returns with monthly rebalancing. In contrast, the fundamental methodology achieves its full potential when it is based primarily on LLM-derived semantic insights. The Entropy methodology is improved by a balanced combination of both semantic and ML signals, thus highlighting the potential of LLMs to improve predictive power by offering interpretative context for complex market interactions. These findings highlight the strategic importance of tailoring the semantic\u2013algorithmic fusion to suit the nature of the predictive data and the investment horizon, with significant implications for portfolio management and future research in financial modeling.", "citations": 4}
{"title": "Advanced simulation paradigm of human behaviour unveils complex financial systemic projection", "year": 2025, "authors": "Cheng Wang, Chuwen Wang, Shirong Zeng, Jianguo Liu, Changjun Jiang", "url": "https://api.semanticscholar.org/CorpusId:277349490", "relevance": 1, "abstract": "The high-order complexity of human behaviour is likely the root cause of extreme difficulty in financial market projections. We consider that behavioural simulation can unveil systemic dynamics to support analysis. Simulating diverse human groups must account for the behavioural heterogeneity, especially in finance. To address the fidelity of simulated agents, on the basis of agent-based modeling, we propose a new paradigm of behavioural simulation where each agent is supported and driven by a hierarchical knowledge architecture. This architecture, integrating language and professional models, imitates behavioural processes in specific scenarios. Evaluated on futures markets, our simulator achieves a 13.29% deviation in simulating crisis scenarios whose price increase rate reaches 285.34%. Under normal conditions, our simulator also exhibits lower mean square error in predicting futures price of specific commodities. This technique bridges non-quantitative information with diverse market behaviour, offering a promising platform to simulate investor behaviour and its impact on market dynamics.", "citations": 0}
{"title": "TradExpert: Revolutionizing Trading with Mixture of Expert LLMs", "year": 2024, "authors": "Qianggang Ding, Haochen Shi, Bang Liu", "url": "https://api.semanticscholar.org/CorpusId:273811282", "relevance": 1, "abstract": "The integration of Artificial Intelligence (AI) in the financial domain has opened new avenues for quantitative trading, particularly through the use of Large Language Models (LLMs). However, the challenge of effectively synthesizing insights from diverse data sources and integrating both structured and unstructured data persists. This paper presents TradeExpert, a novel framework that employs a mix of experts (MoE) approach, using four specialized LLMs, each analyzing distinct sources of financial data, including news articles, market data, alpha factors, and fundamental data. The insights of these expert LLMs are further synthesized by a General Expert LLM to make a final prediction or decision. With specific prompts, TradeExpert can be switched between the prediction mode and the ranking mode for stock movement prediction and quantitative stock trading, respectively. In addition to existing benchmarks, we also release a large-scale financial dataset to comprehensively evaluate TradeExpert's effectiveness. Our experimental results demonstrate TradeExpert's superior performance across all trading scenarios.", "citations": 10}
{"title": "A Self-Improving Multi-Agent Framework for Dynamic Portfolio Management", "year": 2025, "authors": "Wanjie Zhan, Chao Yu, Chengdong Xu, XiaWei Wu, Yuhe Wang", "url": "https://www.semanticscholar.org/paper/b8fa846e1044c1a05729ee76ecb1b800098274c2", "relevance": 1, "abstract": "Portfolio management (PM) is a dynamic asset allocation process aimed at maximizing returns while controlling risks. Recently, LLM-based agents have shown significant application potentials in PM. However, existing approaches often lack a complete modeling of the whole PM process and rely on fixed rule-based methods, limiting their adaptability and effectiveness. To address these limitations, we propose SIMA-DPM, a self-improving multi-agent framework for dynamic PM. SIMA-DPM simulates the end-to-end PM workflow, including stock screening, portfolio construction and risk control, with specialized agents for each stage. Additionally, SIMA-DPM employs a self-improving dynamic stock selection mechanism to iteratively refine selection strategies, so as to adapt to changing market. Experiments on a stock pool of about 680 stocks show that, under controlled risk, SIMA-DPM significantly outperforms baselines.", "citations": 0}
{"title": "Chain-of-Alpha: Unleashing the Power of Large Language Models for Alpha Mining in Quantitative Trading", "year": 2025, "authors": "Lang Cao, Zekun Xi, Longfei Liao, Ziwei Yang, Zheng Cao", "url": "https://www.semanticscholar.org/paper/d392598fbffaae986b15695b24611205be2e6ec3", "relevance": 1, "abstract": "Alpha factor mining is a fundamental task in quantitative trading, aimed at discovering interpretable signals that can predict asset returns beyond systematic market risk. While traditional methods rely on manual formula design or heuristic search with machine learning, recent advances have leveraged Large Language Models (LLMs) for automated factor discovery. However, existing LLM-based alpha mining approaches remain limited in terms of automation, generality, and efficiency. In this paper, we propose Chain-of-Alpha, a novel, simple, yet effective and efficient LLM-based framework for fully automated formulaic alpha mining. Our method features a dual-chain architecture, consisting of a Factor Generation Chain and a Factor Optimization Chain, which iteratively generate, evaluate, and refine candidate alpha factors using only market data, while leveraging backtest feedback and prior optimization knowledge. The two chains work synergistically to enable high-quality alpha discovery without human intervention and offer strong scalability. Extensive experiments on real-world A-share benchmarks demonstrate that Chain-of-Alpha outperforms existing baselines across multiple metrics, presenting a promising direction for LLM-driven quantitative research.", "citations": 6}
{"title": "Large Language Model Agents in Finance: A Survey Bridging Research, Practice, and Real-World Deployment", "year": 2025, "authors": "Yifei Dong, Fengyi Wu, Kunlin Zhang, Yilong Dai, Sanjian Zhang, Wanghao Ye, Sihan Chen, Zhi-Qi Cheng", "url": "https://www.semanticscholar.org/paper/f56ff0c8f868716244d1c0d490a72f762f1ab64a", "relevance": 1, "abstract": ",", "citations": 4}
{"title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining", "year": 2026, "authors": "Jun Han, Shuo Zhang, Wei Li, Zhi Yang, Yifan Dong, Tu Hu, Jialuo Yuan, Xiaomin Yu, Yumo Zhu, Fangqi Lou, Xin Guo, Zhaowei Liu, Tianyi Jiang, Ruichuan An, Jingping Liu, Biao Wu, Rongze Chen, Kunyi Wang, Yifan Wang, Sen Hu, Xinbing Kong, Liwen Zhang, Ronghao Chen, Huacan Wang", "url": "https://www.semanticscholar.org/paper/3821672c3b0665b1250e1fffabb20283f1d8cda6", "relevance": 1, "abstract": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard&Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.", "citations": 0}
{"title": "DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning", "year": 2024, "authors": "Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu", "url": "https://www.semanticscholar.org/paper/daf538dbf6038f424ac0b71e2ede0d8851a628c0", "relevance": 1, "abstract": "", "citations": 5}
{"title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "authors": "Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, N. Chawla, Olaf Wiest, Xiangliang Zhang", "url": "https://api.semanticscholar.org/CorpusId:267412980", "relevance": 1, "abstract": "Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to their notable capabilities in planning and reasoning, LLMs have been utilized as autonomous agents for the automatic execution of various tasks. Recently, LLM-based agent systems have rapidly evolved from single-agent planning or decision-making to operating as multi-agent systems, enhancing their ability in complex problem-solving and world simulation. To offer an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects and challenges of LLM-based multi-agent (LLM-MA) systems. Our objective is to provide readers with an in-depth understanding of these key points: the domains and settings where LLM-MA systems operate or simulate; the profiling and communication methods of these agents; and the means by which these agents develop their skills. For those interested in delving into this field, we also summarize the commonly used datasets or benchmarks. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository (github.com/taichengguo/LLM_MultiAgents_Survey_Papers), dedicated to outlining the research of LLM-MA research.", "citations": 702}
{"title": "CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading", "year": 2024, "authors": "Yuan Li, B. Luo, Qian Wang, Nuo Chen, Xu Liu, Bingsheng He", "url": "https://www.semanticscholar.org/paper/41e49f3e7cef50ec4b1fc4b2fe4dd3ba04ef3b9f", "relevance": 1, "abstract": "The utilization of Large Language Models (LLMs) in financial trading has primarily been concentrated within the stock market, aiding in economic and financial decisions. Yet, the unique opportunities presented by the cryptocurrency market, noted for its on-chain data\u2019s transparency and the critical influence of off-chain signals like news, remain largely untapped by LLMs. This work aims to bridge the gap by developing an LLM-based trading agent, CryptoTrade, which uniquely combines the analysis of on-chain and off-chain data. This approach leverages the transparency and immutability of on-chain data, as well as the timeliness and influence of off-chain signals, providing a comprehensive overview of the cryptocurrency market. CryptoTrade incorporates a reflective mechanism specifically engineered to refine its daily trading decisions by analyzing the outcomes of prior trading decisions. This research makes two significant contributions. Firstly, it broadens the applicability of LLMs to the domain of cryptocurrency trading. Secondly, it establishes a benchmark for cryptocurrency trading strategies. Through extensive experiments, CryptoTrade has demonstrated superior performance in maximizing returns compared to time-series baselines, but not compared to traditional trading signals, across various cryptocurrencies and market conditions. Our code and data are available at https://github.com/Xtra-Computing/CryptoTrade", "citations": 31}
{"title": "FinRL Contests: Benchmarking Data-driven Financial Reinforcement Learning Agents", "year": 2025, "authors": "Keyi Wang, Nikolaus Holzer, Ziyi Xia, Yupeng Cao, Jiechao Gao, Anwar Walid, Kairong Xiao, Xiao-Yang Liu Yanglet", "url": "https://api.semanticscholar.org/CorpusId:278715834", "relevance": 1, "abstract": "Financial reinforcement learning (FinRL) is now a practical paradigm for financial engineering. However, applying RL strategies to real-world trading tasks remains a challenge for individuals, as it is error-prone and engineering-heavy. The non-stationarity of financial data, low signal-to-noise ratios, and various market frictions require deep accumulations. Although numerous FinRL methods have been developed for tasks such as stock/crypto trading and portfolio management, the lack of standardized task definitions, real-time high-quality datasets, close-to-real market environments, and robust baselines has hindered consistent reproduction in both open-source community and FinTech industry. To bridge this gap, we organized a series of FinRL Contests from 2023 to 2025, covering a diverse range of financial tasks such as stock trading, order execution, crypto trading, and the use of large language model (LLM)-engineered signals. These contests attracted 200+ participants from 100+ institutions over 20+ countries. To encourage participations, we provided starter kits featuring GPU-optimized parallel market environments, ensemble learning, and comprehensive instructions. In this paper, we summarize these benchmarking efforts, detailing task formulations, data curation pipelines, environment implementations, evaluation protocols, participant performance, and organizational insights. It guides our follow-up FinRL contests, and also provides a reference for FinAI contests alike.", "citations": 3}
{"title": "LLM-Enhanced Trading Decision Framework with Multi-Scale Memory for Electricity Markets", "year": 2025, "authors": "Ruixiang Tian, Minghui Zhang, Yilei Liu, Hao Wang, Yanru Zhang", "url": "https://www.semanticscholar.org/paper/d4e56e4602de0c59ca5a41c47c9a6c495aaa6273", "relevance": 1, "abstract": "AI-based methods have advanced electricity market trading, yet most time-series and deep reinforcement learning (DRL) models struggle to incorporate unstructured information such as news and policies. This paper introduces a large language model (LLM)-driven trading framework that integrates multi-level memory\u2014short-, mid-, long-term, and reflective\u2014to emulate human decision processes under complex market signals. The framework dynamically evaluates the semantic relevance of news across temporal scales and models delayed effects in relation to market behavior. Experiments on the Australian electricity market show that our approach outperforms traditional strategies in both interpretability and predictive performance. These findings highlight the critical role of textual data in improving market foresight and adaptive trading under information-rich conditions.", "citations": 1}
{"title": "LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making", "year": 2023, "authors": "Kausik Lakkaraju, Sara E Jones, S. Vuruma, Vishal Pallagani, Bharath Muppasani, Biplav Srivastava", "url": "https://www.semanticscholar.org/paper/1dddc3cdca26cd434d48110f8d73674bb7f63c4f", "relevance": 1, "abstract": "As Large Language Model (LLM) based chatbots are becoming more accessible, users are relying on these chatbots for reliable and personalized recommendations in diverse domains, ranging from code generation to financial advisement. In this context, we set out to investigate how such systems perform in the personal finance domain, where financial inclusion has been an overarching stated aim of banks for decades. We test widely used LLM-based chatbots, ChatGPT and Bard, and compare their performance against SafeFinance, a rule-based chatbot built using the Rasa platform. The comparison is across two critical tasks: product discovery and multi-product interaction, where product refers to banking products like Credit Cards, Certificate of Deposits, and Checking Accounts. With this study, we provide interesting insights into the chatbots\u2019 efficacy in financial advisement and their ability to provide fair treatment across different user groups. We find that both Bard and ChatGPT can make errors in retrieving basic online information, the responses they generate are inconsistent across different user groups, and they cannot be relied on for reasoning involving banking products. On the other hand, despite their limited generalization capabilities, rule-based chatbots like SafeFinance provide safe and reliable answers to users that can be traced back to their original source. Overall, although the outputs of the LLM-based chatbots are fluent and plausible, there are still critical gaps in providing consistent and reliable financial information.", "citations": 48}
{"title": "Standard Benchmarks Fail -- Auditing LLM Agents in Finance Must Prioritize Risk", "year": 2025, "authors": "Zichen Chen, Jiaao Chen, Jianda Chen, Misha Sra", "url": "https://api.semanticscholar.org/CorpusId:276575244", "relevance": 1, "abstract": "Standard benchmarks fixate on how well large language model (LLM) agents perform in finance, yet say little about whether they are safe to deploy. We argue that accuracy metrics and return-based scores provide an illusion of reliability, overlooking vulnerabilities such as hallucinated facts, stale data, and adversarial prompt manipulation. We take a firm position: financial LLM agents should be evaluated first and foremost on their risk profile, not on their point-estimate performance. Drawing on risk-engineering principles, we outline a three-level agenda: model, workflow, and system, for stress-testing LLM agents under realistic failure modes. To illustrate why this shift is urgent, we audit six API-based and open-weights LLM agents on three high-impact tasks and uncover hidden weaknesses that conventional benchmarks miss. We conclude with actionable recommendations for researchers, practitioners, and regulators: audit risk-aware metrics in future studies, publish stress scenarios alongside datasets, and treat ``safety budget'' as a primary success criterion. Only by redefining what ``good'' looks like can the community responsibly advance AI-driven finance.", "citations": 5}
{"title": "QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading", "year": 2025, "authors": "Fei Xiong, Xiang Zhang, Aosong Feng, Siqi Sun, Chenyu You", "url": "https://api.semanticscholar.org/CorpusId:281309960", "relevance": 1, "abstract": "Recent advances in Large Language Models (LLMs) have shown remarkable capabilities in financial reasoning and market understanding. Multi-agent LLM frameworks such as TradingAgent and FINMEM augment these models to long-horizon investment tasks by leveraging fundamental and sentiment-based inputs for strategic decision-making. However, these approaches are ill-suited for the high-speed, precision-critical demands of High-Frequency Trading (HFT). HFT typically requires rapid, risk-aware decisions driven by structured, short-horizon signals, such as technical indicators, chart patterns, and trend features. These signals stand in sharp contrast to the long-horizon, text-driven reasoning that characterizes most existing LLM-based systems in finance. To bridge this gap, we introduce QuantAgent, the first multi-agent LLM framework explicitly designed for high-frequency algorithmic trading. The system decomposes trading into four specialized agents--Indicator, Pattern, Trend, and Risk--each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics over short temporal windows. Extensive experiments across nine financial instruments, including Bitcoin and Nasdaq futures, demonstrate that QuantAgent consistently outperforms baseline methods, achieving higher predictive accuracy at both 1-hour and 4-hour trading intervals across multiple evaluation metrics. Our findings suggest that coupling structured trading signals with LLM-based reasoning provides a viable path for traceable, real-time decision systems in high-frequency financial markets.", "citations": 5}
{"title": "LLM Agents Do Not Replicate Human Market Traders: Evidence From Experimental Finance", "year": 2025, "authors": "Thomas Henning, Siddhartha Ojha, Ross Spoon, Jiatong Han, C. F. Camerer", "url": "https://api.semanticscholar.org/CorpusId:276575185", "relevance": 1, "abstract": "This paper explores how Large Language Models (LLMs) behave in a classic experimental finance paradigm widely known for eliciting bubbles and crashes in human participants. We adapt an established trading design, where traders buy and sell a risky asset with a known fundamental value, and introduce several LLM-based agents, both in single-model markets (all traders are instances of the same LLM) and in mixed-model\"battle royale\"settings (multiple LLMs competing in the same market). Our findings reveal that LLMs generally exhibit a\"textbook-rational\"approach, pricing the asset near its fundamental value, and show only a muted tendency toward bubble formation. Further analyses indicate that LLM-based agents display less trading strategy variance in contrast to humans. Taken together, these results highlight the risk of relying on LLM-only data to replicate human-driven market phenomena, as key behavioral features, such as large emergent bubbles, were not robustly reproduced. While LLMs clearly possess the capacity for strategic decision-making, their relative consistency and rationality suggest that they do not accurately mimic human market dynamics.", "citations": 4}
{"title": "Exploring LLM Cryptocurrency Trading Through Fact-Subjectivity Aware Reasoning", "year": 2024, "authors": "Qian Wang, Yuchen Gao, Zhenheng Tang, B. Luo, Nuo Chen, Bingsheng He", "url": "https://api.semanticscholar.org/CorpusId:273374802", "relevance": 1, "abstract": "While many studies show that more advanced LLMs excel in tasks such as mathematics and coding, we observe that in cryptocurrency trading, stronger LLMs sometimes underperform compared to weaker ones. To investigate this counterintuitive phenomenon, we examine how LLMs reason when making trading decisions. Our findings reveal that (1) stronger LLMs show a preference for factual information over subjectivity; (2) separating the reasoning process into factual and subjective components leads to higher profits. Building on these insights, we propose a multi-agent framework, FS-ReasoningAgent, which enables LLMs to recognize and learn from both factual and subjective reasoning. Extensive experiments demonstrate that this fine-grained reasoning approach enhances LLM trading performance in cryptocurrency markets, yielding profit improvements of 7\\% in BTC, 2\\% in ETH, and 10\\% in SOL. Additionally, an ablation study reveals that relying on subjective news generates higher returns in bull markets, while focusing on factual information yields better results in bear markets. Code is available at https://github.com/Persdre/FS-ReasoningAgent.", "citations": 2}
{"title": "Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs", "year": 2025, "authors": "Hao Kang, Qingru Zhang, Han Cai, Weiyuan Xu, Tushar Krishna, Yilun Du, Tsachy Weissman", "url": "https://api.semanticscholar.org/CorpusId:278904558", "relevance": 1, "abstract": "Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards. Despite the importance of this latency quality trade off, it remains underexplored in the context of LLM based agents. In this work, we present the first systematic study of this trade off in real time decision making tasks. To support our investigation, we introduce two new benchmarks: HFTBench, a high frequency trading simulation, and StreetFighter, a competitive gaming platform. Our analysis reveals that optimal latency quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance. To address this, we propose FPX, an adaptive framework that dynamically selects model size and quantization level based on real time demands. Our method achieves the best performance on both benchmarks, improving win rate by up to 80% in Street Fighter and boosting daily yield by up to 26.52% in trading, underscoring the need for latency aware evaluation and deployment strategies for LLM based agents. These results demonstrate the critical importance of latency aware evaluation and deployment strategies for real world LLM based agents. Our benchmarks are available at Latency Sensitive Benchmarks.", "citations": 6}
{"title": "TraderTalk: An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions", "year": 2024, "authors": "Alicia Vidler, Toby Walsh", "url": "https://api.semanticscholar.org/CorpusId:273661563", "relevance": 1, "abstract": "We introduce a novel hybrid approach that augments Agent-Based Models (ABMs) with behaviours generated by Large Language Models (LLMs) to simulate human trading interactions. We call our model TraderTalk. Leveraging LLMs trained on extensive human-authored text, we capture detailed and nuanced representations of bilateral conversations in financial trading. Applying this Generative Agent-Based Model (GABM) to government bond markets, we replicate trading decisions between two stylised virtual humans. Our method addresses both structural challenges\u2014such as coordinating turn-taking between realistic LLM-based agents\u2014and design challenges, including the interpretation of LLM outputs by the agent model. By exploring prompt design opportunistically rather than systematically, we enhance the realism of agent interactions without exhaustive overfitting or model reliance. Our approach successfully replicates trade-to-order volume ratios observed in related asset markets, demonstrating the potential of LLM-augmented ABMs in financial simulations.", "citations": 3}
{"title": "FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios", "year": 2025, "authors": "Yingqian Wu, Qiushi Wang, Zefei Long, Rong Ye, Zhongtian Lu, Xianyin Zhang, Bingxuan Li, Wei Chen, Liwen Zhang, Zhongyu Wei", "url": "https://api.semanticscholar.org/CorpusId:280276469", "relevance": 1, "abstract": "Financial report generation tasks range from macro- to micro-economics analysis, also requiring extensive data analysis. Existing LLM models are usually fine-tuned on simple QA tasks and cannot comprehensively analyze real financial scenarios. Given the complexity, financial companies often distribute tasks among departments. Inspired by this, we propose FinTeam, a financial multi-agent collaborative system, with a workflow with four LLM agents: document analyzer, analyst, accountant, and consultant. We train these agents with specific financial expertise using constructed datasets. We evaluate FinTeam on comprehensive financial tasks constructed from real online investment forums, including macroeconomic, industry, and company analysis. The human evaluation shows that by combining agents, the financial reports generate from FinTeam achieved a 62.00% acceptance rate, outperforming baseline models like GPT-4o and Xuanyuan. Additionally, FinTeam's agents demonstrate a 7.43% average improvement on FinCUGE and a 2.06% accuracy boost on FinEval. Project is available at https://github.com/FudanDISC/DISC-FinLLM/.", "citations": 2}
{"title": "MASCA: LLM based-Multi Agents System for Credit Assessment", "year": 2025, "authors": "Gautam Jajoo, Pranjal A. Chitale, Saksham Agarwal", "url": "https://api.semanticscholar.org/CorpusId:280391092", "relevance": 1, "abstract": "Recent advancements in financial problem-solving have leveraged LLMs and agent-based systems, with a primary focus on trading and financial modeling. However, credit assessment remains an underexplored challenge, traditionally dependent on rule-based methods and statistical models. In this paper, we introduce MASCA, an LLM-driven multi-agent system designed to enhance credit evaluation by mirroring real-world decision-making processes. The framework employs a layered architecture where specialized LLM-based agents collaboratively tackle sub-tasks. Additionally, we integrate contrastive learning for risk and reward assessment to optimize decision-making. We further present a signaling game theory perspective on hierarchical multi-agent systems, offering theoretical insights into their structure and interactions. Our paper also includes a detailed bias analysis in credit assessment, addressing fairness concerns. Experimental results demonstrate that MASCA outperforms baseline approaches, highlighting the effectiveness of hierarchical LLM-based multi-agent systems in financial applications, particularly in credit scoring.", "citations": 4}
{"title": "WebCryptoAgent: Agentic Crypto Trading with Web Informatics", "year": 2026, "authors": "Ali Kurban, Wei Luo, Liangyu Zuo, Zeyu Zhang, Renda Han, Zhaolu Kang, Hao Tang", "url": "https://api.semanticscholar.org/CorpusId:284544510", "relevance": 1, "abstract": "Cryptocurrency trading increasingly depends on timely integration of heterogeneous web information and market microstructure signals to support short-horizon decision making under extreme volatility. However, existing trading systems struggle to jointly reason over noisy multi-source web evidence while maintaining robustness to rapid price shocks at sub-second timescales. The first challenge lies in synthesizing unstructured web content, social sentiment, and structured OHLCV signals into coherent and interpretable trading decisions without amplifying spurious correlations, while the second challenge concerns risk control, as slow deliberative reasoning pipelines are ill-suited for handling abrupt market shocks that require immediate defensive responses. To address these challenges, we propose WebCryptoAgent, an agentic trading framework that decomposes web-informed decision making into modality-specific agents and consolidates their outputs into a unified evidence document for confidence-calibrated reasoning. We further introduce a decoupled control architecture that separates strategic hourly reasoning from a real-time second-level risk model, enabling fast shock detection and protective intervention independent of the trading loop. Extensive experiments on real-world cryptocurrency markets demonstrate that WebCryptoAgent improves trading stability, reduces spurious activity, and enhances tail-risk handling compared to existing baselines. Code will be available at https://github.com/AIGeeksGroup/WebCryptoAgent.", "citations": 0}
{"title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model", "year": 2024, "authors": "Sai Wang, Hang Yuan, Lionel M. Ni, Jian Guo", "url": "https://api.semanticscholar.org/CorpusId:267499667", "relevance": 1, "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and tackle real-world challenges have gained prominence.However, tailoring these agents for specialized domains like quantitative investment remains a formidable task. The core challenge involves efficiently building and integrating a domain-specific knowledge base for the agent's learning process. This paper introduces a principled framework to address this challenge, comprising a two-layer loop.In the inner loop, the agent refines its responses by drawing from its knowledge base, while in the outer loop, these responses are tested in real-world scenarios to automatically enhance the knowledge base with new insights.We demonstrate that our approach enables the agent to progressively approximate optimal behavior with provable efficiency.Furthermore, we instantiate this framework through an autonomous agent for mining trading signals named QuantAgent. Empirical results showcase QuantAgent's capability in uncovering viable financial signals and enhancing the accuracy of financial forecasts.", "citations": 26}
{"title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation", "year": 2025, "authors": "Song Jin, Shuqi Li, Shukun Zhang, Rui Yan", "url": "https://api.semanticscholar.org/CorpusId:282911316", "relevance": 1, "abstract": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.", "citations": 1}
{"title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis", "year": 2024, "authors": "Frank Xing", "url": "https://api.semanticscholar.org/CorpusId:266933455", "relevance": 1, "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focus from massive data acquisition and new model training to human alignment and strategic elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA) due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage existing generative models in such a context. This study investigates the effectiveness of the new paradigm, that is, using LLMs without fine-tuning for FSA. Rooted in Minsky\u2019s theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed and applied to FSA. The framework instantiates specialized agents using prior guiding knowledge from both linguistics and finance. Then, a summative agent reasons on the aggregated agent discussions. Comprehensive evaluations using six FSA datasets show that the framework yields better accuracies compared to many alternative multi-LLM agent settings, especially when the discussion contents are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA and potentially other tasks. Implications for business and management have also been discussed.", "citations": 103}
{"title": "LLM-Enhanced Black-Litterman Portfolio Optimization", "year": 2025, "authors": "Youngbin Lee, Yejin Kim, Juhyeon Kim, Suin Kim, Yongjae Lee", "url": "https://api.semanticscholar.org/CorpusId:277955509", "relevance": 1, "abstract": "The Black-Litterman model addresses the sensitivity issues of tra- ditional mean-variance optimization by incorporating investor views, but systematically generating these views remains a key challenge. This study proposes and validates a systematic frame- work that translates return forecasts and predictive uncertainty from Large Language Models (LLMs) into the core inputs for the Black-Litterman model: investor views and their confidence lev- els. Through a backtest on S&P 500 constituents, we demonstrate that portfolios driven by top-performing LLMs significantly out- perform traditional baselines in both absolute and risk-adjusted terms. Crucially, our analysis reveals that each LLM exhibits a dis- tinct and consistent investment style which is the primary driver of performance. We found that the selection of an LLM is therefore not a search for a single best forecaster, but a strategic choice of an investment style whose success is contingent on its alignment with the prevailing market regime. The source code and data are available at https://github.com/youngandbin/LLM-BLM.", "citations": 5}
{"title": "Advancing innovation in financial stability: A comprehensive review of ai agent frameworks, challenges and applications", "year": 2025, "authors": "Satyadhar Joshi", "url": "https://api.semanticscholar.org/CorpusId:276434260", "relevance": 1, "abstract": "Artificial Intelligence (AI) agents are revolutionizing industries by enabling autonomous decision-making, task execution, and multi-agent collaboration. This paper provides a comprehensive review of AI agent frameworks, focusing on their architectures, applications, and challenges in financial services. We conduct a comparative analysis of leading frameworks, including LangGraph, CrewAI, and AutoGen, evaluating their strengths, limitations, and suitability for complex financial tasks such as trading, risk assessment, and investment analysis. The integration of AI agents in financial markets presents both opportunities and challenges, particularly in terms of regulatory compliance, ethical considerations, and model robustness. We examine agentic AI design patterns, multi-agent systems, and the deployment of AI agents advancing the proposal to use them for fraud detection and risk management. By synthesizing insights from academic research and industry practices, this review identifies key trends and future directions in AI agent development. This work contributes to the growing discourse on AI-driven automation by outlining technical considerations and open challenges in deploying AI agents at scale. We highlight the need for enhanced transparency, interpretability, and security in AI-driven Agentic systems. Our findings provide valuable insights for researchers and practitioners seeking to harness AI agents for more efficient and intelligent decision-making.", "citations": 24}
{"title": "Multimodal Gen-AI for Fundamental Investment Research", "year": 2023, "authors": "Lezhi Li, Ting-Yu Chang, Hai Wang", "url": "https://www.semanticscholar.org/paper/4a2731d14f1ffbd8e7a2718664b5c026ae579109", "relevance": 1, "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.", "citations": 12}
{"title": "Predicting Liquidity-Aware Bond Yields using Causal GANs and Deep Reinforcement Learning with LLM Evaluation", "year": 2025, "authors": "J. Walia, Aarush Sinha, Srinitish Srinivasan, Srihari Unnikrishnan", "url": "https://api.semanticscholar.org/CorpusId:276574592", "relevance": 1, "abstract": "Financial bond yield forecasting is challenging due to data scarcity, nonlinear macroeconomic dependencies, and evolving market conditions. In this paper, we propose a novel framework that leverages Causal Generative Adversarial Networks (CausalGANs) and Soft Actor-Critic (SAC) reinforcement learning (RL) to generate high-fidelity synthetic bond yield data for four major bond categories (AAA, BAA, US10Y, Junk). By incorporating 12 key macroeconomic variables, we ensure statistical fidelity by preserving essential market properties. To transform this market dependent synthetic data into actionable insights, we employ a finetuned Large Language Model (LLM) Qwen2.5-7B that generates trading signals (BUY/HOLD/SELL), risk assessments, and volatility projections. We use automated, human and LLM evaluations, all of which demonstrate that our framework improves forecasting performance over existing methods, with statistical validation via predictive accuracy, MAE evaluation(0.103%), profit/loss evaluation (60% profit rate), LLM evaluation (3.37/5) and expert assessments scoring 4.67 out of 5. The reinforcement learning-enhanced synthetic data generation achieves the least Mean Absolute Error of 0.103, demonstrating its effectiveness in replicating real-world bond market dynamics. We not only enhance data-driven trading strategies but also provides a scalable, high-fidelity synthetic financial data pipeline for risk&volatility management and investment decision-making. This work establishes a bridge between synthetic data generation, LLM driven financial forecasting, and language model evaluation, contributing to AI-driven financial decision-making.", "citations": 1}
{"title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs for Monetary Policy Decision Classification", "year": 2025, "authors": "Kaito Takano, Masanori Hirano, Kei Nakagawa", "url": "https://api.semanticscholar.org/CorpusId:282748851", "relevance": 1, "abstract": "Accurately forecasting central bank policy decisions, particularly those of the Federal Open Market Committee(FOMC) has become increasingly important amid heightened economic uncertainty. While prior studies have used monetary policy texts to predict rate changes, most rely on static classification models that overlook the deliberative nature of policymaking. This study proposes a novel framework that structurally imitates the FOMC's collective decision-making process by modeling multiple large language models(LLMs) as interacting agents. Each agent begins with a distinct initial belief and produces a prediction based on both qualitative policy texts and quantitative macroeconomic indicators. Through iterative rounds, agents revise their predictions by observing the outputs of others, simulating deliberation and consensus formation. To enhance interpretability, we introduce a latent variable representing each agent's underlying belief(e.g., hawkish or dovish), and we theoretically demonstrate how this belief mediates the perception of input information and interaction dynamics. Empirical results show that this debate-based approach significantly outperforms standard LLMs-based baselines in prediction accuracy. Furthermore, the explicit modeling of beliefs provides insights into how individual perspectives and social influence shape collective policy forecasts.", "citations": 0}
{"title": "FinLlama: LLM-Based Financial Sentiment Analysis for Algorithmic Trading", "year": 2024, "authors": "Giorgos Iacovides, Thanos Konstantinidis, Mingxue Xu, Danilo Mandic", "url": "https://www.semanticscholar.org/paper/d798dea2a4e995e08de033809ec3fd63c53d8b46", "relevance": 1, "abstract": "Online sources of financial news have a profound influence on both market movements and trading decisions. Standard sentiment analysis employs a lexicon-based approach to aid financial decisions, but struggles with context sensitivity and word ordering. On the other hand, Large Language Models (LLMs) are powerful, but are not finance-specific and require significant computational resources. To this end, we introduce a finance specific LLM framework, based on the Llama 2 7B foundational model, in order to benefit from its generative nature and comprehensive language manipulation. Such a generator-discriminator scheme, referred to as FinLlama, both classifies sentiment valence and quantifies its strength, offering a nuanced insight into financial news. The FinLlama model is fine-tuned on supervised financial sentiment analysis data, to make it handle the complexities of financial lexicon and context, and is equipped with a neural network-based decision mechanism. The subsequent parameter-efficient fine-tuning optimises trainable parameters, thus minimising computational and memory requirements without sacrificing accuracy. Simulation results demonstrate the ability of FinLlama to increase market returns in portfolio management scenarios, yielding high-return and resilient portfolios, even during volatile periods.", "citations": 35}
{"title": "PriceSeer: Evaluating Large Language Models in Real-Time Stock Prediction", "year": 2025, "authors": "Bohan Liang, Zijian Chen, Qi Jia, Kaiwei Zhang, Kaiyuan Ji, Guangtao Zhai", "url": "https://www.semanticscholar.org/paper/baf62e648a717c636b2fd5c2b12dec500191327f", "relevance": 1, "abstract": "Stock prediction, a subject closely related to people's investment activities in fully dynamic and live environments, has been widely studied. Current large language models (LLMs) have shown remarkable potential in various domains, exhibiting expert-level performance through advanced reasoning and contextual understanding. In this paper, we introduce PriceSeer, a live, dynamic, and data-uncontaminated benchmark specifically designed for LLMs performing stock prediction tasks. Specifically, PriceSeer includes 110 U.S. stocks from 11 industrial sectors, with each containing 249 historical data points. Our benchmark implements both internal and external information expansion, where LLMs receive extra financial indicators, news, and fake news to perform stock price prediction. We evaluate six cutting-edge LLMs under different prediction horizons, demonstrating their potential in generating investment strategies after obtaining accurate price predictions for different sectors. Additionally, we provide analyses of LLMs'suboptimal performance in long-term predictions, including the vulnerability to fake news and specific industries. The code and evaluation data will be open-sourced at https://github.com/BobLiang2113/PriceSeer.", "citations": 0}
{"title": "Domain Specific Benchmarks for Evaluating Multimodal Large Language Models", "year": 2025, "authors": "Khizar Anjum, Muhammad Arbab Arshad, Kadhim Hayawi, Efstathios Polyzos, Asadullah Tariq, M. Serhani, Laiba Batool, Brady D. Lund, Nishith Reddy Mannuru, Ravi Varma Kumar Bevara, Taslim Mahbub, Muhammad Zeeshan Akram, Sakib Shahriar", "url": "https://api.semanticscholar.org/CorpusId:279403486", "relevance": 1, "abstract": "Large language models (LLMs) are increasingly being deployed across disciplines due to their advanced reasoning and problem solving capabilities. To measure their effectiveness, various benchmarks have been developed that measure aspects of LLM reasoning, comprehension, and problem-solving. While several surveys address LLM evaluation and benchmarks, a domain-specific analysis remains underexplored in the literature. This paper introduces a taxonomy of seven key disciplines, encompassing various domains and application areas where LLMs are extensively utilized. Additionally, we provide a comprehensive review of LLM benchmarks and survey papers within each domain, highlighting the unique capabilities of LLMs and the challenges faced in their application. Finally, we compile and categorize these benchmarks by domain to create an accessible resource for researchers, aiming to pave the way for advancements toward artificial general intelligence (AGI)", "citations": 4}
{"title": "FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs", "year": 2025, "authors": "Giorgos Iacovides, Wuyang Zhou, Danilo P. Mandic", "url": "https://api.semanticscholar.org/CorpusId:280018100", "relevance": 1, "abstract": "Opinions expressed in online finance-related textual data are having an increasingly profound impact on trading decisions and market movements. This trend highlights the vital role of sentiment analysis as a tool for quantifying the nature and strength of such opinions. With the rapid development of Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs) have become the de facto standard for financial sentiment analysis. However, the SFT paradigm can lead to memorization of the training data and often fails to generalize to unseen samples. This is a critical limitation in financial domains, where models must adapt to previously unobserved events and the nuanced, domain-specific language of finance. To this end, we introduce FinDPO, the first finance-specific LLM framework based on post-training human preference alignment via Direct Preference Optimization (DPO). The proposed FinDPO achieves state-of-the-art performance on standard sentiment classification benchmarks, outperforming existing supervised fine-tuned models by 11% on the average. Uniquely, the FinDPO framework enables the integration of a fine-tuned causal LLM into realistic portfolio strategies through a novel \u2018logit-to-score\u2019 conversion, which transforms discrete sentiment predictions into continuous, rankable sentiment scores (probabilities). In this way, simulations demonstrate that FinDPO is the first sentiment-based approach to maintain substantial positive returns of 67% annually and strong risk-adjusted performance, as indicated by a Sharpe ratio of 2.0, even under realistic transaction costs of 5 basis points (bps).", "citations": 4}
{"title": "Generative AI-enhanced Sector-based Investment Portfolio Construction", "year": 2025, "authors": "Alina Voronina, Oleksandr Romanko, Rui Cao, Roy H. Kwon, Rafael Mendoza-Arriaga", "url": "https://api.semanticscholar.org/CorpusId:284351296", "relevance": 1, "abstract": "This paper investigates how Large Language Models (LLMs) from leading providers (OpenAI, Google, Anthropic, DeepSeek, and xAI) can be applied to quantitative sector-based portfolio construction. We use LLMs to identify investable universes of stocks within S&P 500 sector indices and evaluate how their selections perform when combined with classical portfolio optimization methods. Each model was prompted to select and weight 20 stocks per sector, and the resulting portfolios were compared with their respective sector indices across two distinct out-of-sample periods: a stable market phase (January-March 2025) and a volatile phase (April-June 2025). Our results reveal a strong temporal dependence in LLM portfolio performance. During stable market conditions, LLM-weighted portfolios frequently outperformed sector indices on both cumulative return and risk-adjusted (Sharpe ratio) measures. However, during the volatile period, many LLM portfolios underperformed, suggesting that current models may struggle to adapt to regime shifts or high-volatility environments underrepresented in their training data. Importantly, when LLM-based stock selection is combined with traditional optimization techniques, portfolio outcomes improve in both performance and consistency. This study contributes one of the first multi-model, cross-provider evaluations of generative AI algorithms in investment management. It highlights that while LLMs can effectively complement quantitative finance by enhancing stock selection and interpretability, their reliability remains market-dependent. The findings underscore the potential of hybrid AI-quantitative frameworks, integrating LLM reasoning with established optimization techniques, to produce more robust and adaptive investment strategies.", "citations": 0}
{"title": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "year": 2025, "authors": "Yulin Liu, Mocca Schweitzer", "url": "https://api.semanticscholar.org/CorpusId:280985031", "relevance": 1, "abstract": "The Decentralized Physical Infrastructure (DePIN) market is revolutionizing the sharing economy through token-based economics and smart contracts that govern decentralized operations. By 2024, DePIN projects have exceeded \\$10 billion in market capitalization, underscoring their rapid growth. However, the unregulated nature of these markets, coupled with the autonomous deployment of AI agents in smart contracts, introduces risks such as inefficiencies and potential misalignment with human values. To address these concerns, we introduce EconAgentic, a Large Language Model (LLM)-powered framework designed to mitigate these challenges. Our research focuses on three key areas: 1) modeling the dynamic evolution of DePIN markets, 2) evaluating stakeholders'actions and their economic impacts, and 3) analyzing macroeconomic indicators to align market outcomes with societal goals. Through EconAgentic, we simulate how AI agents respond to token incentives, invest in infrastructure, and adapt to market conditions, comparing AI-driven decisions with human heuristic benchmarks. Our results show that EconAgentic provides valuable insights into the efficiency, inclusion, and stability of DePIN markets, contributing to both academic understanding and practical improvements in the design and governance of decentralized, tokenized economies.", "citations": 0}
{"title": "Finance Agent Benchmark: Benchmarking LLMs on Real-world Financial Research Tasks", "year": 2025, "authors": "Antoine Bigeard, Langston Nashold, Rayan Krishnan, Shirley Wu", "url": "https://www.semanticscholar.org/paper/fd97920ead5575d2203d8633fd9aa1073a2d9fd2", "relevance": 1, "abstract": "Artificial Intelligence (AI) technology has emerged as a transformative force in financial analysis and the finance industry, though significant questions remain about the full capabilities of Large Language Model (LLM) agents in this domain. We present the Finance Agent Benchmark, featuring challenging and diverse real-world finance research problems that require LLMs to perform complex analysis using recent SEC filings. We construct the benchmark using a taxonomy of nine financial task categories, developed in consultation with experts from banks, hedge funds, and private equity firms. The dataset includes 537 expert-authored questions covering tasks from information retrieval to complex financial modeling, each validated through a rigorous review process to ensure accuracy and relevance. Moreover, we implement an agentic harness that equips LLMs with tools sufficient to produce accurate responses, including Google Search and EDGAR database access. Overall, the Finance Agent Benchmark provides a comprehensive testbed for measuring the progress of LLM-driven finance agents. Our evaluation reveals significant limitations in current AI capabilities - even the best-performing model (OpenAI o3) achieved only 46.8% accuracy at an average cost of $3.79 per query. This underscores the need for further advancements before reliable deployment in high-stakes finance settings.", "citations": 13}
{"title": "Simulating Financial Market via Large Language Model based Agents", "year": 2024, "authors": "Shen Gao, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, Shuo Shang", "url": "https://www.semanticscholar.org/paper/7150e17eac46cfdfc303ceef882d115e0232de46", "relevance": 1, "abstract": "Most economic theories typically assume that financial market participants are fully rational individuals and use mathematical models to simulate human behavior in financial markets. However, human behavior is often not entirely rational and is challenging to predict accurately with mathematical models. In this paper, we propose \\textbf{A}gent-based \\textbf{S}imulated \\textbf{F}inancial \\textbf{M}arket (ASFM), which first constructs a simulated stock market with a real order matching system. Then, we propose a large language model based agent as the stock trader, which contains the profile, observation, and tool-learning based action module. The trading agent can comprehensively understand current market dynamics and financial policy information, and make decisions that align with their trading strategy. In the experiments, we first verify that the reactions of our ASFM are consistent with the real stock market in two controllable scenarios. In addition, we also conduct experiments in two popular economics research directions, and we find that conclusions drawn in our \\model align with the preliminary findings in economics research. Based on these observations, we believe our proposed ASFM provides a new paradigm for economic research.", "citations": 29}
{"title": "A Deep-Reinforcement-Learning-Based Multi-Source Information Fusion Portfolio Management Approach via Sector Rotation", "year": 2025, "authors": "Yuxiao Yan, Changsheng Zhang, Yang An, Bin Zhang", "url": "https://api.semanticscholar.org/CorpusId:276834807", "relevance": 1, "abstract": "As a research objective in quantitative trading, the aim of portfolio management is to find the optimal allocation of funds by following the dynamic changes in stock prices. The principal issue with current portfolio management methods is their narrow focus on a single data source, neglecting the changes or news arising from sectors. Methods for integrating news data frequently face challenges with regard to quantifying text data and embedding them into portfolio models; this process often necessitates considerable manual labeling. To address these issues, we proposed a sector rotation portfolio management approach based on deep reinforcement learning (DRL) via multi-source information. The multi-source information includes the temporal data of sector and stock features, as well as news data. In terms of structure, in this method, a dual-layer reinforcement learning structure is deployed, comprising a multi-agent sector layer and a graph convolution layer. The former learns the trend of sectors, while the latter learns the connections between stocks in sectors, and the impact of news on sectors is integrated through large language models without manual labeling or fusing output information of other modules to provide the final portfolio management scheme. The results of simulation experiments on the Chinese and US (United States) stock markets show that our method demonstrates significant improvements over multiple state-of-the-art approaches.", "citations": 3}
{"title": "Decision-informed Neural Networks with Large Language Model Integration for Portfolio Optimization", "year": 2025, "authors": "Yoon-Jeong Hwang, Yaxuan Kong, Stefan Zohren, Yongjae Lee", "url": "https://api.semanticscholar.org/CorpusId:276094545", "relevance": 1, "abstract": "This paper addresses the critical disconnect between prediction and decision quality in portfolio optimization by integrating Large Language Models (LLMs) with decision-focused learning. We demonstrate both theoretically and empirically that minimizing the prediction error alone leads to suboptimal portfolio decisions. We aim to exploit the representational power of LLMs for investment decisions. An attention mechanism processes asset relationships, temporal dependencies, and macro variables, which are then directly integrated into a portfolio optimization layer. This enables the model to capture complex market dynamics and align predictions with the decision objectives. Extensive experiments on S\\&P100 and DOW30 datasets show that our model consistently outperforms state-of-the-art deep learning models. In addition, gradient-based analyses show that our model prioritizes the assets most crucial to decision making, thus mitigating the effects of prediction errors on portfolio performance. These findings underscore the value of integrating decision objectives into predictions for more robust and context-aware portfolio management.", "citations": 8}
{"title": "From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation", "year": 2025, "authors": "A. Hossain, Mufakir Qamar Ansari, Haziq Jeelani, Monia Digra, F. Syed", "url": "https://api.semanticscholar.org/CorpusId:283672241", "relevance": 1, "abstract": "Generative AI (GenAI) has enormous potential for improving two critical areas in investing, namely portfolio optimization (choosing the best combination of assets) and risk management (protecting those investments). Our study works at this intersection, using Large Language Models (LLMs) to upgrade how financial decisions are traditionally made. This research specifically tested how well advanced LLMs like Microsoft Phi 2, Mistral 7B, and Zypher 7B can create practical, risk-aware strategies for investing mutual funds in different sectors of the economy. Our method is sophisticated: it combines a Retrieval-Augmented Generation (RAG) pipeline, which enables the LLM to check external, real-time data with standard financial optimization methods. The model's advice is context-aware because we feed it large economic signals, like changes in the global economy. The Zypher 7B model was the clear winner. It consistently produced strategies that maximized investment returns while delivering better risk-adjusted results than the other models. Its ability to process complex relationships and contextual information makes it a highly powerful tool for financial allocation. In conclusion, our findings show that GenAI substantially improves performance over basic allocation methods. By connecting GenAI to real-world financial applications, this work lays the groundwork for creating smarter, more efficient, and more adaptable solutions for asset management professionals.", "citations": 0}
{"title": "MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting", "year": 2025, "authors": "Marc S. Montalvo, Hamed Yaghoobian", "url": "https://www.semanticscholar.org/paper/5f9c40e3fa61c6d6f8c0a9bf6ccea580eca9deea", "relevance": 1, "abstract": "Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential. Traditional quantitative methods remain vulnerable to survivorship bias, while many AI-driven approaches struggle with signal integration, reproducibility, and computational efficiency. We introduce MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news, while embedding explicit bias-mitigation protocols. The system leverages GPT-4.1-nano for reproducability and cost-efficient inference and generates weekly portfolios of 15-30 equities with allocation weights optimized for short-term performance. In an eight-week evaluation, MASFIN delivered a 7.33% cumulative return, outperforming the S&P 500, NASDAQ-100, and Dow Jones benchmarks in six of eight weeks, albeit with higher volatility. These findings demonstrate the promise of bias-aware, generative AI frameworks for financial forecasting and highlight opportunities for modular multi-agent design to advance practical, transparent, and reproducible approaches in quantitative finance.", "citations": 1}
{"title": "ChatGPT-Based Investment Portfolio Selection", "year": 2023, "authors": "Oleksandr Romanko, Akhilesh Narayan, R. Kwon", "url": "https://www.semanticscholar.org/paper/adab086f6c7a4a413beb7ac10bbd2a4cdd2fbe58", "relevance": 1, "abstract": "In this paper, we explore potential uses of generative AI models, such as ChatGPT, for investment portfolio selection. Trusting investment advice from Generative Pre-Trained Transformer (GPT) models is a challenge due to model \u201challucinations,\u201d necessitating careful verification and validation of the output. Therefore, we take an alternative approach. We use ChatGPT to obtain a universe of stocks from S&P500 market index that are potentially attractive for investing. Subsequently, we compared various portfolio optimization strategies that utilized this AI-generated trading universe, evaluating those against quantitative portfolio optimization models as well as comparing to some of the popular investment funds. Our findings indicate that ChatGPT is effective in stock selection but may not perform as well in assigning optimal weights to stocks within the portfolio. But when stocks selection by ChatGPT is combined with established portfolio optimization models, we achieve even better results. By blending strengths of AI-generated stock selection with advanced quantitative optimization techniques, we observed the potential for more robust and favorable investment outcomes, suggesting a hybrid approach for more effective and reliable investment decision-making in the future.", "citations": 38}
{"title": "AlphaSharpe: LLM-Driven Discovery of Robust Risk-Adjusted Metrics", "year": 2025, "authors": "K. Yuksel, H. Sawaf", "url": "https://api.semanticscholar.org/CorpusId:276094354", "relevance": 1, "abstract": "Financial metrics like the Sharpe ratio are pivotal in evaluating investment performance by balancing risk and return. However, traditional metrics often struggle with robustness and generalization, particularly in dynamic and volatile market conditions. This paper introduces AlphaSharpe, a novel framework leveraging large language models (LLMs) to iteratively evolve and optimize financial metrics to discover enhanced risk-return metrics that outperform traditional approaches in robustness and correlation with future performance metrics by employing iterative crossover, mutation, and evaluation. Key contributions of this work include: (1) a novel use of LLMs to generate and refine financial metrics with implicit domain-specific knowledge, (2) a scoring mechanism to ensure that evolved metrics generalize effectively to unseen data, and (3) an empirical demonstration of 3x predictive power for future risk-returns, and 2x portfolio performance. Experimental results in a real-world dataset highlight the superiority of discovered metrics, making them highly relevant to portfolio managers and financial decision-makers. This framework not only addresses the limitations of existing metrics but also showcases the potential of LLMs in advancing financial analytics, paving the way for informed and robust investment strategies.", "citations": 1}
{"title": "Biased echoes: Large language models reinforce investment biases and increase portfolio risks of private investors", "year": 2025, "authors": "Philipp Winder, Christian Hildebrand, Jochen Hartmann", "url": "https://api.semanticscholar.org/CorpusId:279614959", "relevance": 1, "abstract": "Large language models are increasingly used by private investors seeking financial advice. The current paper examines the potential of these models to perpetuate investment biases and affect the economic security of individuals at scale. We provide a systematic assessment of how large language models used for investment advice shape the portfolio risks of private investors. We offer a comprehensive model of large language model investment advice risk, examining five key dimensions of portfolio risks (geographical cluster risk, sector cluster risk, trend chasing risk, active investment allocation risk, and total expense risk). We demonstrate across four studies that large language models used for investment advice induce increased portfolio risks across all five risk dimensions, and that a range of debiasing interventions only partially mitigate these risks. Our findings show that large language models exhibit similar \u201ccognitive\u201d biases as human investors, reinforcing existing investment biases inherent in their training data. These findings have important implications for private investors, policymakers, artificial intelligence developers, financial institutions, and the responsible development of large language models in the financial sector.", "citations": 4}
{"title": "Wall Street Tree Search: Risk-Aware Planning for Offline Reinforcement Learning", "year": 2022, "authors": "D. Elbaz, Gal Novik, Oren Salzman", "url": "https://api.semanticscholar.org/CorpusId:253420238", "relevance": 1, "abstract": "Offline reinforcement-learning (RL) algorithms learn to make decisions using a given, fixed training dataset without online data collection. This problem setting is captivating because it holds the promise of utilizing previously collected datasets without any costly or risky interaction with the environment. However, this promise also bears the drawback of this setting as the restricted dataset induces uncertainty because the agent can encounter unfamiliar sequences of states and actions that the training data did not cover. To mitigate the destructive uncertainty effects, we need to balance the aspiration to take reward-maximizing actions with the incurred risk due to incorrect ones. In financial economics, modern portfolio theory (MPT) is a method that risk-averse investors can use to construct diversified portfolios that maximize their returns without unacceptable levels of risk. We propose integrating MPT into the agent's decision-making process, presenting a new simple-yet-highly-effective risk-aware planning algorithm for offline RL. Our algorithm allows us to systematically account for the \\emph{estimated quality} of specific actions and their \\emph{estimated risk} due to the uncertainty. We show that our approach can be coupled with the Transformer architecture to yield a state-of-the-art planner, which maximizes the return for offline RL tasks. Moreover, our algorithm reduces the variance of the results significantly compared to conventional Transformer decoding, which results in a much more stable algorithm -- a property that is essential for the offline RL setting, where real-world exploration and failures can be costly or dangerous.", "citations": 0}
{"title": "GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration", "year": 2024, "authors": "Ben Wang", "url": "https://api.semanticscholar.org/CorpusId:268691932", "relevance": 1, "abstract": "The advent of ChatGPT and similar large language models (LLMs) has revolutionized the human-AI interaction and information-seeking process. Leveraging LLMs as an alternative to search engines, users can now access summarized information tailored to their queries, significantly reducing the cognitive load in navigating vast information resources. This shift underscores the potential of LLMs in redefining information access paradigms [1]. Drawing on the foundation of task-focused information retrieval and LLMs' task planning ability, this research extends the scope of LLM capabilities beyond short-term task automation (i.e., smaller-scale and routine tasks that LLM agents can automate with less human intervention) to support users in navigating long-term and significant life tasks. The long-term tasks encompass broader personal life goals or development in aspects like health, finances, education, and professional development, which cannot be fully completed by LLM agents but require significant human involvement. This study introduces the GOLF framework (Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability to assist in significant life decisions through goal orientation and long-term planning. Figure 1 presents the GOLF framework, including a task taxonomy and the process for task management. The GOLF framework envisions the completion of complex tasks as a strategic journey toward a final goal, incorporating a sequence of activities, tasks, and subtasks, adopting the task taxonomy in Figure 1a [2]. Figure 1b illustrates the task process within the GOLF framework, which operates on AutoGen [3], a sophisticated multi-agent system, and involves multiple LLM agents to facilitate user support and workload distribution for achieving long-term goals. The multi-agent system processes the task following steps: Initial Planning, Step Planning, Task Assignment, Multi-Agent Coordination, User Engagement, and Evaluation and Iteration. The methodology encompasses a comprehensive simulation study to test the framework's efficacy, followed by model and human evaluations to develop a dataset benchmark for long-term life tasks, and experiments across different models and settings. By shifting the focus from short-term tasks to the broader spectrum of long-term life goals, this research underscores the transformative potential of LLMs in enhancing human decision-making processes and task management, marking a significant step forward in the evolution of human-AI collaboration.", "citations": 0}
{"title": "Combining Reinforcement Learning and Barrier Functions for Adaptive Risk Management in Portfolio Optimization", "year": 2023, "authors": "Z. Li, He-lu Huang, V. Tam", "url": "https://api.semanticscholar.org/CorpusId:259138726", "relevance": 1, "abstract": "Reinforcement learning (RL) based investment strategies have been widely adopted in portfolio management (PM) in recent years. Nevertheless, most RL-based approaches may often emphasize on pursuing returns while ignoring the risks of the underlying trading strategies that may potentially lead to great losses especially under high market volatility. Therefore, a risk-manageable PM investment framework integrating both RL and barrier functions (BF) is proposed to carefully balance the needs for high returns and acceptable risk exposure in PM applications. Up to our understanding, this work represents the first attempt to combine BF and RL for financial applications. While the involved RL approach may aggressively search for more profitable trading strategies, the BF-based risk controller will continuously monitor the market states to dynamically adjust the investment portfolio as a controllable measure for avoiding potential losses particularly in downtrend markets. Additionally, two adaptive mechanisms are provided to dynamically adjust the impact of risk controllers such that the proposed framework can be flexibly adapted to uptrend and downtrend markets. The empirical results of our proposed framework clearly reveal such advantages against most well-known RL-based approaches on real-world data sets. More importantly, our proposed framework shed lights on many possible directions for future investigation.", "citations": 1}
{"title": "FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness", "year": 2025, "authors": "Yuanjian Xu, Jianing Hao, Kunsheng Tang, Jingnan Chen, Anxian Liu, Peng Liu, Guang Zhang", "url": "https://api.semanticscholar.org/CorpusId:279070868", "relevance": 1, "abstract": "Financial markets exhibit complex dynamics where localized events trigger ripple effects across entities. Previous event studies, constrained by static single-company analyses and simplistic assumptions, fail to capture these ripple effects. While large language models (LLMs) offer emergent reasoning capabilities, their direct application falters due to structural market unawareness and limited capacity to analyze ripple effects. We propose FinRipple, an elegant framework that empowers LLMs with the ability to analyze ripple effects through financial theory-guided large-scale reinforcement learning. We begin by relaxing the assumptions of previous methods, incorporating a time-varying knowledge graph to accurately represent market structure. By seamlessly integrating classical asset pricing theory, we align the LLM with the market, enabling it to predict ripple effects. To the best of our knowledge, we are the first to provide a standardized definition of ripple effect prediction, a task that is extremely important yet unexplored in the financial domain. Extensive experiments demonstrate that FinRipple provides a promising solution to this task.", "citations": 5}
{"title": "Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning", "year": 2025, "authors": "Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua", "url": "https://www.semanticscholar.org/paper/edce9c10e3932d2d2d138a0523bb3e8a6bbe1b6b", "relevance": 1, "abstract": "Signal decay and regime shifts pose recurring challenges for data-driven investment strategies in non-stationary markets. Conventional time-series and machine learning approaches, which rely primarily on historical correlations, often struggle to generalize when the economic environment changes. While large language models (LLMs) offer strong capabilities for processing unstructured information, their potential to support quantitative factor screening through explicit economic reasoning remains underexplored. Existing factor-based methods typically reduce alphas to numerical time series, overlooking the semantic rationale that determines when a factor is economically relevant. We propose Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. Alpha-R1 reasons over factor logic and real-time news to evaluate alpha relevance under changing market conditions, selectively activating or deactivating factors based on contextual consistency. Empirical results across multiple asset pools show that Alpha-R1 consistently outperforms benchmark strategies and exhibits improved robustness to alpha decay. The full implementation and resources are available at https://github.com/FinStep-AI/Alpha-R1.", "citations": 1}
{"title": "The evolution, applications, and future prospects of large language models: An in-depth overview", "year": 2024, "authors": "Jiayin Li", "url": "https://api.semanticscholar.org/CorpusId:267402678", "relevance": 1, "abstract": "The evolution of natural language processing has transpired through three primary phases, with large-scale language models significantly transforming the field. These models have heightened the machine's capability to understand, produce, and interact with human language in unprecedented ways. Progressing from RNNs to transformer models, transitioning from encoder-decoder frameworks to decoder-centric designs, and the journey from BERT to the Chat-GPT series have marked significant shifts in the academic discourse. Impressively, these sophisticated models have infiltrated a range of sectors, including finance, healthcare, biology, and education, revolutionizing both traditional and emerging domains. However, as these advancements are celebrated, the ethical and economic challenges they introduce must also be addressed. Confronting these pivotal issues and harnessing technology for societal betterment has become a priority for academia and industry alike, sparking intense research endeavors in recent times. This review dives into the history of natural language processing, highlighting the pivotal developments and core principles of large language models. It provides a comprehensive perspective on their adoption and influence within the financial sector, crafting a detailed narrative of their deployment. In conclusion, the analysis reflects on the current challenges posed by these models and presents potential solutions. This study stands as a definitive guide, offering readers an in-depth understanding of the development, application, and future trajectories of large-scale language models.", "citations": 3}
{"title": "An intelligent financial portfolio trading strategy using deep Q-learning", "year": 2019, "authors": "Hyungju Park, M. Sim, D. Choi", "url": "https://api.semanticscholar.org/CorpusId:195833369", "relevance": 1, "abstract": "Portfolio traders strive to identify dynamic portfolio allocation schemes so that their total budgets are efficiently allocated through the investment horizon. This study proposes a novel portfolio trading strategy in which an intelligent agent is trained to identify an optimal trading action by using deep Q-learning. We formulate a Markov decision process model for the portfolio trading process, and the model adopts a discrete combinatorial action space, determining the trading direction at prespecified trading size for each asset, to ensure practical applicability. Our novel portfolio trading strategy takes advantage of three features to outperform in real-world trading. First, a mapping function is devised to handle and transform an initially found but infeasible action into a feasible action closest to the originally proposed ideal action. Second, by overcoming the dimensionality problem, this study establishes models of agent and Q-network for deriving a multi-asset trading strategy in the predefined action space. Last, this study introduces a technique that has the advantage of deriving a well-fitted multi-asset trading strategy by designing an agent to simulate all feasible actions in each state. To validate our approach, we conduct backtests for two representative portfolios and demonstrate superior results over the benchmark strategies.", "citations": 103}
{"title": "Structural Embeddings of Tools for Large Language Models", "year": 2023, "authors": "Eren Unlu", "url": "https://api.semanticscholar.org/CorpusId:260350878", "relevance": 1, "abstract": "It is evident that the current state of Large Language Models (LLMs) necessitates the incorporation of external tools. The lack of straightforward algebraic and logical reasoning is well documented and prompted researchers to develop frameworks which allow LLMs to operate via external tools. The ontological nature of tool utilization for a specific task can be well formulated with a Directed Acyclic Graph (DAG). The central aim of the paper is to highlight the importance of graph based approaches to LLM-tool interaction in near future. We propose an exemplary framework to guide the orchestration of exponentially increasing numbers of external tools with LLMs,where objectives and functionalities of tools are graph encoded hierarchically. Assuming that textual segments of a Chain-of-Thought (CoT) can be imagined as a tool as defined here, the graph based framework can pave new avenues in that particular direction as well.", "citations": 1}
{"title": "Dynamic portfolio rebalancing through reinforcement learning", "year": 2021, "authors": "Qing Yang Eddy Lim, Qi Cao, Hiok Chai Quek", "url": "https://api.semanticscholar.org/CorpusId:245514569", "relevance": 1, "abstract": "Portfolio managements in financial markets involve risk management strategies and opportunistic responses to individual trading behaviours. Optimal portfolios constructed aim to have a minimal risk with highest accompanying investment returns, regardless of market conditions. This paper focuses on providing an alternative view in maximising portfolio returns using Reinforcement Learning (RL) by considering dynamic risks appropriate to market conditions through dynamic portfolio rebalancing. The proposed algorithm is able to improve portfolio management by introducing the dynamic rebalancing of portfolios with vigorous risk through an RL agent. This is done while accounting for market conditions, asset diversifications, risk and returns in the global financial market. Studies have been performed in this paper to explore four types of methods with variations in fully portfolio rebalancing and gradual portfolio rebalancing, which combine with and without the use of the Long Short-Term Memory (LSTM) model to predict stock prices for adjusting the technical indicator centring. Performances of the four methods have been evaluated and compared using three constructed financial portfolios, including one portfolio with global market index assets with different risk levels, and two portfolios with uncorrelated stock assets from different sectors and risk levels. Observed from the experiment results, the proposed RL agent for gradual portfolio rebalancing with the LSTM model on price prediction outperforms the other three methods, as well as returns of individual assets in these three portfolios. The improvements of the returns using the RL agent for gradual rebalancing with prediction model are achieved at about 27.9\u201393.4% over those of the full rebalancing without prediction model. It has demonstrated the ability to dynamically adjust portfolio compositions according to the market trends, risks and returns of the global indices and stock assets.", "citations": 42}
{"title": "Multi-period portfolio optimization using model predictive control with mean-variance and risk parity frameworks", "year": 2021, "authors": "Xiaoyue Li, A. Uysal, J. Mulvey", "url": "https://api.semanticscholar.org/CorpusId:232290551", "relevance": 1, "abstract": "We employ model predictive control for a multi-period portfolio optimization problem. In addition to the mean-variance objective, we construct a portfolio whose allocation is given by model predictive control with a riskparity objective, and provide a successive convex program algorithm that provides 30 times faster and robust solutions in the experiments. Computational results on the multi-asset universe show that multi-period models perform better than their single period counterparts in out-of-sample period, 20062020. The out-of-sample risk-adjusted performance of both mean-variance and risk-parity formulations beat the fix-mix benchmark, and achieve Sharpe ratio of 0.64 and 0.97, respectively.", "citations": 68}
{"title": "Simul-RL Portfolio Framework: Black-Scholes-Merton and Reinforcement Learning for Asset Allocation", "year": 2025, "authors": "Jungyu Ahn, Hyoung-Goo Kang", "url": "https://api.semanticscholar.org/CorpusId:277133375", "relevance": 1, "abstract": "Asset allocation method using reinforcement learning is being actively researched. However, the existing asset allocation methods do not consider the following viewpoints in solving the asset allocation problem. First, State design without considering portfolio management and financial market characteristics. Second, Model Overfitting. Third, Model training design without considering the statistical structure of financial time series data. To solve these problems, we propose a new Reinforcement Learning asset allocation method. First, financial market state and agent state. Second, Monte Carlo simulation data are used to increase training data complexity. Third, Monte Carlo simulation data are created considering various statistical structures of financial markets. We show experimentally that our method outperforms the benchmark at several test intervals.", "citations": 1}
{"title": "Cognitive User Interface for Portfolio Optimization", "year": 2021, "authors": "Yuehuan He, Oleksandr Romanko, Alina Sienkiewicz, Robert H. Seidman, R. Kwon", "url": "https://api.semanticscholar.org/CorpusId:234803376", "relevance": 1, "abstract": "This paper describes the development of a chatbot as a cognitive user interface for portfolio optimization. The financial portfolio optimization chatbot is proposed to provide an easy-to-use interface for portfolio optimization, including a wide range of investment objectives and flexibility to include a variety of constraints representing investment preferences when compared to existing online automated portfolio advisory services. Additionally, the use of a chatbot interface allows investors lacking a background in quantitative finance and optimization to utilize optimization services. The chatbot is capable of extracting investment preferences from natural text inputs, handling these inputs with a backend financial optimization solver, analyzing the results, and communicating the characteristics of the optimized portfolio back to the user. The architecture and design of the chatbot are presented, along with an implementation using the IBM Cloud, SS&C Algorithmics Portfolio Optimizer, and Slack as an example of this approach. The design and implementation using cloud applications provides scalability, potential performance improvements, and could inspire future applications for financial optimization services.", "citations": 5}
{"title": "PRUDEX-Compass: Towards Systematic Evaluation of Reinforcement Learning in Financial Markets", "year": 2023, "authors": "Shuo Sun, Molei Qin, Xinrun Wang, Bo An", "url": "https://api.semanticscholar.org/CorpusId:256459307", "relevance": 1, "abstract": "The financial markets, which involve more than $90 trillion market capitals, attract the attention of innumerable investors around the world. Recently, reinforcement learning in financial markets (FinRL) has emerged as a promising direction to train agents for making profitable investment decisions. However, the evaluation of most FinRL methods only focuses on profit-related measures and ignores many critical axes, which are far from satisfactory for financial practitioners to deploy these methods into real-world financial markets. Therefore, we introduce PRUDEX-Compass, which has 6 axes, i.e., Profitability, Risk-control, Universality, Diversity, rEliability, and eXplainability, with a total of 17 measures for a systematic evaluation. Specifically, i) we propose AlphaMix+ as a strong FinRL baseline, which leverages mixture-of-experts (MoE) and risk-sensitive approaches to make diversified risk-aware investment decisions, ii) we evaluate 8 FinRL methods in 4 long-term real-world datasets of influential financial markets to demonstrate the usage of our PRUDEX-Compass, iii) PRUDEX-Compass together with 4 real-world datasets, standard implementation of 8 FinRL methods and a portfolio management environment is released as public resources to facilitate the design and comparison of new FinRL methods. We hope that PRUDEX-Compass can not only shed light on future FinRL research to prevent untrustworthy results from stagnating FinRL into successful industry deployment but also provide a new challenging algorithm evaluation scenario for the reinforcement learning (RL) community.", "citations": 10}
{"title": "Deep Reinforcement Learning for Optimal Asset Allocation Using DDPG with TiDE", "year": 2025, "authors": "Rongwei Liu, Jin Zheng, John Cartlidge", "url": "https://api.semanticscholar.org/CorpusId:280950360", "relevance": 1, "abstract": "", "citations": 0}
{"title": "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents", "year": 2025, "authors": "Axel Backlund, Lukas Petersson", "url": "https://www.semanticscholar.org/paper/c2fa7d5acc7ab42fb39e8a40b2f3f5b2a9986b2b", "relevance": 1, "abstract": "While Large Language Models (LLMs) can exhibit impressive proficiency in isolated, short-term tasks, they often fail to maintain coherent performance over longer time horizons. In this paper, we present Vending-Bench, a simulated environment designed to specifically test an LLM-based agent's ability to manage a straightforward, long-running business scenario: operating a vending machine. Agents must balance inventories, place orders, set prices, and handle daily fees - tasks that are each simple but collectively, over long horizons (>20M tokens per run) stress an LLM's capacity for sustained, coherent decision-making. Our experiments reveal high variance in performance across multiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most runs and turn a profit, but all models have runs that derail, either through misinterpreting delivery schedules, forgetting orders, or descending into tangential\"meltdown\"loops from which they rarely recover. We find no clear correlation between failures and the point at which the model's context window becomes full, suggesting that these breakdowns do not stem from memory limits. Apart from highlighting the high variance in performance over long time horizons, Vending-Bench also tests models' ability to acquire capital, a necessity in many hypothetical dangerous AI scenarios. We hope the benchmark can help in preparing for the advent of stronger AI systems.", "citations": 25}
{"title": "Predictable forward performance processes: Infrequent evaluation and applications to human\u2010machine interactions", "year": 2021, "authors": "Gechun Liang, M. Strub, Yuwei Wang", "url": "https://api.semanticscholar.org/CorpusId:257219110", "relevance": 1, "abstract": "We study discrete\u2010time predictable forward processes when trading times do not coincide with performance evaluation times in a binomial tree model for the financial market. The key step in the construction of these processes is to solve a linear functional equation of higher order associated with the inverse problem driving the evolution of the predictable forward process. We provide sufficient conditions for the existence and uniqueness and an explicit construction of the predictable forward process under these conditions. Furthermore, we find that these processes are inherently myopic in the sense that optimal strategies do not make use of future model parameters even if these are known. Finally, we argue that predictable forward preferences are a viable framework to model human\u2010machine interactions occurring in automated trading or robo\u2010advising. For both applications, we determine an optimal interaction schedule of a human agent interacting infrequently with a machine that is in charge of trading.", "citations": 8}
{"title": "QuantEvolve: Automating Quantitative Strategy Discovery through Multi-Agent Evolutionary Framework", "year": 2025, "authors": "Junhyeog Yun, Hyoun Jun Lee, Insu Jeon", "url": "https://api.semanticscholar.org/CorpusId:282246502", "relevance": 1, "abstract": "Automating quantitative trading strategy development in dynamic markets is challenging, especially with increasing demand for personalized investment solutions. Existing methods often fail to explore the vast strategy space while preserving the diversity essential for robust performance across changing market conditions. We present QuantEvolve, an evolutionary framework that combines quality-diversity optimization with hypothesis-driven strategy generation. QuantEvolve employs a feature map aligned with investor preferences, such as strategy type, risk profile, turnover, and return characteristics, to maintain a diverse set of effective strategies. It also integrates a hypothesis-driven multi-agent system to systematically explore the strategy space through iterative generation and evaluation. This approach produces diverse, sophisticated strategies that adapt to both market regime shifts and individual investment needs. Empirical results show that QuantEvolve outperforms conventional baselines, validating its effectiveness. We release a dataset of evolved strategies to support future research.", "citations": 0}
{"title": "Enhancing LLM Performance in Asset Selection: Investigating the Integration Challenges of Traditional Quantitative Signals", "year": 2025, "authors": "Xingyou Li", "url": "https://www.semanticscholar.org/paper/7cc721ba30b48a6f344dce54e990f64ed0436b50", "relevance": 1, "abstract": "This study examines the application of LLM to the field of financial asset selection. The primary objective of this study is to examine the impact of integrating traditional quantitative signals (predictions from OLS and XGBoost) into LLM. Initial experimental results show that LLM significantly improves the fund selection efficiency of ETFs compared to traditional quantitative models. However, when OLS and XGBoost predictions are provided as supplementary information to the LLM, its performance deteriorates and in some cases it fails to produce even valid outputs. In view of this, the present paper explores further how the integration of external information affects the prediction process of LLM. A series of experiments were conducted to investigate the impact of external information on the performance of LLM. The experiments involved the use of different external information, the adjustment of prompts and the application of different LLMs.The results demonstrate that additional information has a significant effect on the output of the LLM. In most cases, the predictive performance of LLM is significantly diminished. It is evident that providing more detailed information or advanced models does not result in a substantial improvement in the outcomes. Final conclusions: Despite LLM's strong capabilities in financial asset selection, further improvements to its predictive performance are a complex challenge. It is clear that information aggregation, prompts and the use of more advanced models alone will not suffice.", "citations": 0}
{"title": "Adaptive and Regime-Aware RL for Portfolio Optimization", "year": 2025, "authors": "Gabriel Nixon Raj", "url": "https://api.semanticscholar.org/CorpusId:281394285", "relevance": 1, "abstract": "This study proposes a regime-aware reinforcement learning framework for long-horizon portfolio optimization. Moving beyond traditional feedforward and GARCH-based models, we design realistic environments where agents dynamically reallocate capital in response to latent macroeconomic regime shifts. Agents receive hybrid observations and are trained using constrained reward functions that incorporate volatility penalties, capital resets, and tail-risk shocks. We benchmark multiple architectures, including PPO, LSTM-based PPO, and Transformer PPO, against classical baselines such as equal-weight and Sharpe-optimized portfolios. Our agents demonstrate robust performance under financial stress. While Transformer PPO achieves the highest risk-adjusted returns, LSTM variants offer a favorable trade-off between interpretability and training cost. The framework promotes regime-adaptive, explainable reinforcement learning for dynamic asset allocation.", "citations": 0}
{"title": "Robo-advising: Learning Investors' Risk Preferences via Portfolio Choices", "year": 2019, "authors": "Humoud Alsabah, A. Capponi, Octavio Ruiz Lacedelli, Matt Stern", "url": "https://api.semanticscholar.org/CorpusId:207880717", "relevance": 1, "abstract": "\n We introduce a reinforcement learning framework for retail robo-advising. The robo-advisor does not know the investor\u2019s risk preference but learns it over time by observing her portfolio choices in different market environments. We develop an exploration\u2013exploitation algorithm that trades off costly solicitations of portfolio choices by the investor with autonomous trading decisions based on stale estimates of investor\u2019s risk aversion.\u00a0We show that the approximate value function constructed by the algorithm converges to the value function of an omniscient robo-advisor over a number of periods that is polynomial in the state and action space. By correcting for the investor\u2019s mistakes, the robo-advisor may outperform a stand-alone investor, regardless of the investor\u2019s opportunity cost for making portfolio decisions.", "citations": 52}
{"title": "Robo-Advising in Motion: A Model Predictive Control Approach", "year": 2026, "authors": "T. Bielecki, Igor Cialenco", "url": "https://api.semanticscholar.org/CorpusId:284718072", "relevance": 1, "abstract": "Robo-advisors (RAs) are automated portfolio management systems that complement traditional financial advisors by offering lower fees and smaller initial investment requirements. While most existing RAs rely on static, one-period allocation methods, we propose a dynamic, multi-period asset-allocation framework that leverages Model Predictive Control (MPC) to generate suboptimal but practically effective strategies. Our approach combines a Hidden Markov Model with Black-Litterman (BL) methodology to forecast asset returns and covariances, and incorporates practically important constraints, including turnover limits, transaction costs, and target portfolio allocations. We study two predominant optimality criteria in wealth management: dynamic mean-variance (MV) and dynamic risk-budgeting (MRB). Numerical experiments demonstrate that MPC-based strategies consistently outperform myopic approaches, with MV providing flexible and diversified portfolios, while MRB delivers smoother allocations less sensitive to key parameters. These findings highlight the trade-offs between adaptability and stability in practical robo-advising design.", "citations": 0}
{"title": "Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets", "year": 2026, "authors": "Wang Yi, Takashi Hasuike", "url": "https://api.semanticscholar.org/CorpusId:284532014", "relevance": 1, "abstract": "Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.", "citations": 0}
{"title": "Integrated Prediction and Multi-period Portfolio Optimization", "year": 2025, "authors": "Yuxuan Linghu, Zhiyuan Liu, Qi Deng", "url": "https://api.semanticscholar.org/CorpusId:283883358", "relevance": 1, "abstract": "Multi-period portfolio optimization is important for real portfolio management, as it accounts for transaction costs, path-dependent risks, and the intertemporal structure of trading decisions that single-period models cannot capture. Classical methods usually follow a two-stage framework: machine learning algorithms are employed to produce forecasts that closely fit the realized returns, and the predicted values are then used in a downstream portfolio optimization problem to determine the asset weights. This separation leads to a fundamental misalignment between predictions and decision outcomes, while also ignoring the impact of transaction costs. To bridge this gap, recent studies have proposed the idea of end-to-end learning, integrating the two stages into a single pipeline. This paper introduces IPMO (Integrated Prediction and Multi-period Portfolio Optimization), a model for multi-period mean-variance portfolio optimization with turnover penalties. The predictor generates multi-period return forecasts that parameterize a differentiable convex optimization layer, which in turn drives learning via portfolio performance. For scalability, we introduce a mirror-descent fixed-point (MDFP) differentiation scheme that avoids factorizing the Karush-Kuhn-Tucker (KKT) systems, which thus yields stable implicit gradients and nearly scale-insensitive runtime as the decision horizon grows. In experiments with real market data and two representative time-series prediction models, the IPMO method consistently outperforms the two-stage benchmarks in risk-adjusted performance net of transaction costs and achieves more coherent allocation paths. Our results show that integrating machine learning prediction with optimization in the multi-period setting improves financial outcomes and remains computationally tractable.", "citations": 0}
{"title": "Beating the Best Constant Rebalancing Portfolio in Long-Term Investment: A Generalization of the Kelly Criterion and Universal Learning Algorithm for Markets with Serial Dependence", "year": 2025, "authors": "Duy Khanh Lam", "url": "https://api.semanticscholar.org/CorpusId:280149326", "relevance": 1, "abstract": "In the online portfolio optimization framework, existing learning algorithms generate strategies that yield significantly poorer cumulative wealth compared to the best constant rebalancing portfolio in hindsight, despite being consistent in asymptotic growth rate. While this unappealing performance can be improved by incorporating more side information, it raises difficulties in feature selection and high-dimensional settings. Instead, the inherent serial dependence of assets'returns, such as day-of-the-week and other calendar effects, can be leveraged. Although latent serial dependence patterns are commonly detected using large training datasets, this paper proposes an algorithm that learns such dependence using only gradually revealed data, without any assumption on their distribution, to form a strategy that eventually exceeds the cumulative wealth of the best constant rebalancing portfolio. Moreover, the classical Kelly criterion, which requires independent assets'returns, is generalized to accommodate serial dependence in a market modeled as an independent and identically distributed process of random matrices. In such a stochastic market, where existing learning algorithms designed for stationary processes fail to apply, the proposed learning algorithm still generates a strategy that asymptotically grows to the highest rate among all strategies, matching that of the optimal strategy constructed under the generalized Kelly criterion. The experimental results with real market data demonstrate the theoretical guarantees of the algorithm and its performance as expected, as long as serial dependence is significant, regardless of the validity of the generalized Kelly criterion in the experimental market. This further affirms the broad applicability of the algorithm in general contexts.", "citations": 0}
{"title": "Guided Learning: Lubricating End-to-End Modeling for Multi-stage Decision-making", "year": 2024, "authors": "Jian Guo, Sai Wang, Yiyan Qi", "url": "https://api.semanticscholar.org/CorpusId:274131143", "relevance": 1, "abstract": "Multi-stage decision-making is crucial in various real-world artificial intelligence applications, including recommendation systems, autonomous driving, and quantitative investment systems. In quantitative investment, for example, the process typically involves several sequential stages such as factor mining, alpha prediction, portfolio optimization, and sometimes order execution. While state-of-the-art end-to-end modeling aims to unify these stages into a single global framework, it faces significant challenges: (1) training such a unified neural network consisting of multiple stages between initial inputs and final outputs often leads to suboptimal solutions, or even collapse, and (2) many decision-making scenarios are not easily reducible to standard prediction problems. To overcome these challenges, we propose Guided Learning, a novel methodological framework designed to enhance end-to-end learning in multi-stage decision-making. We introduce the concept of a ``guide'', a function that induces the training of intermediate neural network layers towards some phased goals, directing gradients away from suboptimal collapse. For decision scenarios lacking explicit supervisory labels, we incorporate a utility function that quantifies the ``reward'' of the throughout decision. Additionally, we explore the connections between Guided Learning and classic machine learning paradigms such as supervised, unsupervised, semi-supervised, multi-task, and reinforcement learning. Experiments on quantitative investment strategy building demonstrate that guided learning significantly outperforms both traditional stage-wise approaches and existing end-to-end methods.", "citations": 0}
{"title": "Hidden neighbours: extracting industry momentum from stock networks", "year": 2024, "authors": "Joon Chul James Ahn, Dragos Gorduza, Seonho Park", "url": "https://api.semanticscholar.org/CorpusId:273389796", "relevance": 1, "abstract": "This paper introduces an innovative method for constructing industry momentum portfolios by leveraging two stock networks: one based on stock price correlations and the other on corporate text similarity. We find that these networks capture different aspects of company relationships, motivating us to combine them and form a portfolio that exploits less visible industry momentum. Our Hidden Neighbours portfolio, analysed from 2013 to 2022, delivered an annualised return of 18.16% with a Sharpe ratio of 0.85, outperforming the S&P 500 and other traditional momentum strategies. Factor decomposition attributes returns primarily to the idiosyncratic factor \u03b1\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\alpha$$\\end{document}. Our study employs interdisciplinary methods, merging network analysis and Natural Language Processing (NLP) techniques for portfolio construction. Utilising advanced text embedding models, we enhance portfolio construction by integrating textual insights from corporate disclosures into stock networks. The paper offers a comprehensive strategy across diverse data and the interdisciplinary approach, uniting financial theory, network science, and NLP, advances both theory and practice of portfolio management.", "citations": 0}
{"title": "A parsimonious neural network approach to solve portfolio optimization problems without using dynamic programming", "year": 2023, "authors": "Pieter M. van Staden, P. Forsyth, Yuying Li", "url": "https://api.semanticscholar.org/CorpusId:257557311", "relevance": 1, "abstract": "We present a parsimonious neural network approach, which does not rely on dynamic programming techniques, to solve dynamic portfolio optimization problems subject to multiple investment constraints. The number of parameters of the (potentially deep) neural network remains independent of the number of portfolio rebalancing events, and in contrast to, for example, reinforcement learning, the approach avoids the computation of high-dimensional conditional expectations. As a result, the approach remains practical even when considering large numbers of underlying assets, long investment time horizons or very frequent rebalancing events. We prove convergence of the numerical solution to the theoretical optimal solution of a large class of problems under fairly general conditions, and present ground truth analyses for a number of popular formulations, including mean-variance and mean-conditional value-at-risk problems. We also show that it is feasible to solve Sortino ratio-inspired objectives (penalizing only the variance of wealth outcomes below the mean) in dynamic trading settings with the proposed approach. Using numerical experiments, we demonstrate that if the investment objective functional is separable in the sense of dynamic programming, the correct time-consistent optimal investment strategy is recovered, otherwise we obtain the correct pre-commitment (time-inconsistent) investment strategy. The proposed approach remains agnostic as to the underlying data generating assumptions, and results are illustrated using (i) parametric models for underlying asset returns, (ii) stationary block bootstrap resampling of empirical returns, and (iii) generative adversarial network (GAN)-generated synthetic asset returns.", "citations": 3}
{"title": "Long-Term Modeling of Financial Machine Learning for Active Portfolio Management", "year": 2023, "authors": "Kazuki Amagai, Tomoya Suzuki", "url": "https://api.semanticscholar.org/CorpusId:256390026", "relevance": 1, "abstract": "In the practical business of asset management by investment trusts and the like, the general practice is to manage over the medium to long term owing to the burden of operations and increase in transaction costs with the increase in turnover ratio. However, when machine learning is used to construct a management model, the number of learning data decreases with the increase in the long-term time scale; this causes a decline in the learning precision. Accordingly, in this study, data augmentation was applied by the combined use of not only the time scales of the target tasks but also the learning data of shorter term time scales, demonstrating that degradation of the generalization performance can be inhibited even if the target tasks of machine learning have long-term time scales. Moreover, as an illustration of how this data augmentation can be applied, we conducted portfolio management in which machine learning of a multifactor model was done by an autoencoder and mispricing was used from the estimated theoretical values. The effectiveness could be confirmed in not only the stock market but also the FX market, and a general-purpose management model could be constructed in various financial markets.", "citations": 1}
{"title": "Influence of Stocks Intrinsic Valuation on Investment Decision Making: A Literature Review", "year": 2022, "authors": "M. Mensah, W. K. Peprah, Adu Bismark Owusu-Sekyere, Mensah Morris Ayaa, Bamfo Daniel", "url": "https://api.semanticscholar.org/CorpusId:248875101", "relevance": 1, "abstract": "\u2013", "citations": 8}
{"title": "EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies", "year": 2026, "authors": "Xavier Hu, Jinxiang Xia, Shengze Xu, Kangqi Song, Yishuo Yuan, Guibin Zhang, Jincheng Ren, Boyu Feng, Li Lu, Tieyong Zeng, Jiaheng Liu, Minghao Liu, He Zhu, Y. Jiang, Wei Wang, Wangchunshu Zhou", "url": "https://www.semanticscholar.org/paper/2c6137fb1415b22059d478f6c172aefa84b86d1a", "relevance": 1, "abstract": "Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity. Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.", "citations": 0}
{"title": "Architecture of Automated Crypto-Finance Agent", "year": 2021, "authors": "Ali Raheman, A. Kolonin, B. Goertzel, Gergely Hegykozi, Ikram Ansari", "url": "https://api.semanticscholar.org/CorpusId:236034191", "relevance": 1, "abstract": "We present the cognitive architecture of an autonomous agent for active portfolio management in decentralized finance, involving activities such as asset selection, portfolio balancing, liquidity provision and trading. Partial implementation of the architecture is provided and supplied with preliminary results and conclusions.", "citations": 12}
{"title": "Pareto Driven Surrogate (ParDen-Sur) Assisted Optimisation of Multi-period Portfolio Backtest Simulations", "year": 2022, "authors": "Terence L van Zyl, M. Woolway, A. Paskaramoorthy", "url": "https://api.semanticscholar.org/CorpusId:252544799", "relevance": 1, "abstract": "Portfolio management is a multi-period multi-objective optimisation problem subject to a wide range of constraints. However, in practice, portfolio management is treated as a single-period problem partly due to the computationally burdensome hyper-parameter search procedure needed to construct a multi-period Pareto frontier. This study presents the \\gls{ParDen-Sur} modelling framework to efficiently perform the required hyper-parameter search. \\gls{ParDen-Sur} extends previous surrogate frameworks by including a reservoir sampling-based look-ahead mechanism for offspring generation in \\glspl{EA} alongside the traditional acceptance sampling scheme. We evaluate this framework against, and in conjunction with, several seminal \\gls{MO} \\glspl{EA} on two datasets for both the single- and multi-period use cases. Our results show that \\gls{ParDen-Sur} can speed up the exploration for optimal hyper-parameters by almost $2\\times$ with a statistically significant improvement of the Pareto frontiers, across multiple \\glspl{EA}, for both datasets and use cases.", "citations": 0}
{"title": "Multi-Period Portfolio Optimization with Investor Views under Regime Switching", "year": 2020, "authors": "Razvan Oprisor, R. Kwon", "url": "https://api.semanticscholar.org/CorpusId:234420438", "relevance": 1, "abstract": "We propose a novel multi-period trading model that allows portfolio managers to perform optimal portfolio allocation while incorporating their interpretable investment views. This model\u2019s significant advantage is its intuitive and reactive design that incorporates the latest asset return regimes to quantitatively solve managers\u2019 question: how certain should one be that a given investment view is occurring? First, we describe a framework for multi-period portfolio allocation formulated as a convex optimization problem that trades off expected return, risk and transaction costs. Using a framework borrowed from model predictive control introduced by Boyd et al., we employ optimization to plan a sequence of trades using forecasts of future quantities, only the first set being executed. Multi-period trading lends itself to dynamic readjustment of the portfolio when gaining new information. Second, we use the Black-Litterman model to combine investment views specified in a simple linear combination based format with the market portfolio. A data-driven method to adjust the confidence in the manager\u2019s views by comparing them to dynamically updated regime-switching forecasts is proposed. Our contribution is to incorporate both multi-period trading and interpretable investment views into one framework and offer a novel method of using regime-switching to determine each view\u2019s confidence. This method replaces portfolio managers\u2019 need to provide estimated confidence levels for their views, substituting them with a dynamic quantitative approach. The framework is reactive, tractable and tested on 15 years of daily historical data. In a numerical example, this method\u2019s benefits are found to deliver higher excess returns for the same degree of risk in both the case when an investment view proves to be correct, but, more notably, also the case when a view proves to be incorrect. To facilitate ease of use and future research, we also developed an open-source software library that replicates our results.", "citations": 18}
{"title": "Deep Learning, Predictability, and Optimal Portfolio Returns", "year": 2020, "authors": "M. Babiak, Jozef Barun\u00edk", "url": "https://api.semanticscholar.org/CorpusId:221535194", "relevance": 1, "abstract": "We study optimal dynamic portfolio choice of a long-horizon investor who uses deep learning methods to predict equity returns when forming optimal portfolios. The results show statistically and economically significant out-of-sample portfolio benefits of deep learning as measured by high certainty equivalent returns and Sharpe ratios. Return predictability via deep learning generates substantially improved portfolio performance across different subsamples, particularly the recession periods. These gains are robust to including transaction costs, short-selling and borrowing constraints.", "citations": 7}
{"title": "FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning", "year": 2025, "authors": "Liang Hu, Jianpeng Jiao, Jiashuo Liu, Yanle Ren, Zhoufutu Wen, Kaiyuan Zhang, Xuanliang Zhang, Xiang Gao, Tianci He, Fei Hu, Yali Liao, Zaiyuan Wang, Chenghao Yang, Qianyu Yang, Mingren Yin, Zhiyuan Zeng, Ge Zhang, Xinyi Zhang, Xiying Zhao, Zhenwei Zhu, Hongseok Namkoong, Wenhao Huang, Yuwen Tang", "url": "https://www.semanticscholar.org/paper/d9f3ba8b48b68304b611e7d87c3d3ccf9abab32c", "relevance": 1, "abstract": "Search has emerged as core infrastructure for LLM-based agents and is widely viewed as critical on the path toward more general intelligence. Finance is a particularly demanding proving ground: analysts routinely conduct complex, multi-step searches over time-sensitive, domain-specific data, making it ideal for assessing both search proficiency and knowledge-grounded reasoning. Yet no existing open financial datasets evaluate data searching capability of end-to-end agents, largely because constructing realistic, complicated tasks requires deep financial expertise and time-sensitive data is hard to evaluate. We present FinSearchComp, the first fully open-source agent benchmark for realistic, open-domain financial search and reasoning. FinSearchComp comprises three tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and Complex Historical Investigation -- closely reproduce real-world financial analyst workflows. To ensure difficulty and reliability, we engage 70 professional financial experts for annotation and implement a rigorous multi-stage quality-assurance pipeline. The benchmark includes 635 questions spanning global and Greater China markets, and we evaluate 21 models (products) on it. Grok 4 (web) tops the global subset, approaching expert-level accuracy. DouBao (web) leads on the Greater China subset. Experimental analyses show that equipping agents with web search and financial plugins substantially improves results on FinSearchComp, and the country origin of models and tools impact performance significantly.By aligning with realistic analyst tasks and providing end-to-end evaluation, FinSearchComp offers a professional, high-difficulty testbed for complex financial search and reasoning.", "citations": 13}
{"title": "Risk Budgeting: A Tactical Asset Allocation Approach for Retirement Reserve Funds in Morocco", "year": 2023, "authors": "Moulay Slimane Kabiri, C. E. Msiyah, O. Nouisser", "url": "https://www.semanticscholar.org/paper/3b4c073b2a6ca717786f229c3e5fbe47634ae41d", "relevance": 1, "abstract": "", "citations": 2}
{"title": "EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities", "year": 2023, "authors": "Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao", "url": "https://api.semanticscholar.org/CorpusId:264146527", "relevance": 1, "abstract": "The advent of artificial intelligence has led to a growing emphasis on data-driven modeling in macroeconomics, with agent-based modeling (ABM) emerging as a prominent bottom-up simulation paradigm. In ABM, agents (e.g., households, firms) interact within a macroeconomic environment, collectively generating market dynamics. Existing agent modeling typically employs predetermined rules or learning-based neural networks for decision-making. However, customizing each agent presents significant challenges, complicating the modeling of agent heterogeneity. Additionally, the influence of multi-period market dynamics and multifaceted macroeconomic factors are often overlooked in decision-making processes. In this work, we introduce EconAgent, a large language model-empowered agent with human-like characteristics for macroeconomic simulation. We first construct a simulation environment that incorporates various market dynamics driven by agents' decisions regarding work and consumption. Through the perception module, we create heterogeneous agents with distinct decision-making mechanisms. Furthermore, we model the impact of macroeconomic trends using a memory module, which allows agents to reflect on past individual experiences and market dynamics. Simulation experiments show that EconAgent can make realistic decisions, leading to more reasonable macroeconomic phenomena compared to existing rule-based or learning-based agents. Our codes are released at https://github.com/tsinghua-fib-lab/ACL24-EconAgent.", "citations": 147}
{"title": "OPTIMAL TRADING STRATEGY DURING BULL AND BEAR MARKETS FOR HONG KONG-LISTED STOCKS", "year": 2018, "authors": "E. Hui, Ka Kwan Kevin Chan", "url": "https://www.semanticscholar.org/paper/e6e9c9c46ef652524585a4ca4ff446b70295ce74", "relevance": 1, "abstract": "The \u201cbuy-and-hold\u201d strategy based on the EMH was believed by many people to be optimal for a long time. However, there has been more criticism on the EMH since the global financial crisis in 2008. Hence many people attempt to find a trading strategy to beat \u201cbuy-and-hold\u201d. Moreover, the financial market fluctuates a lot. Sometimes it is in a bull market, but it may be in a bear market during other periods of time, so the optimal strategy during different periods of time may vary and hence switching of strategies may be necessary. In this study, we apply Hui and Chan (2018)\u2019s generalized time-dependent strategy on 12 Hong Kong listed stocks during the whole period of observation and two sub-periods. The results show that when the sub-period December 31, 2004\u2013December 31, 2008 is chosen, the strategy outperforms \u201cbuy-and-hold\u201d by the largest extent. This reflects that the strategy is most effective during adverse market conditions. This study can help investors to apply appropriate trading strategies to earn more profits, and help property practitioners to improve their strategic property management to increase the value of their portfolio.", "citations": 3}
{"title": "Does Trend Following Work on Stocks", "year": 2009, "authors": "Cole Wilcox, Eric Crittenden, Blackstar Funds", "url": "https://www.semanticscholar.org/paper/1453464b12d66c43ba6d1b28b58baf4871f6b4bc", "relevance": 1, "abstract": "", "citations": 21}
{"title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems", "year": 2023, "authors": "N. Nascimento, Paulo Alencar, Donald D. Cowan", "url": "https://www.semanticscholar.org/paper/1f9822022f586e375461660db792f23e891c7123", "relevance": 1, "abstract": "The complexity of managing multiagent systems (MASs) in autonomic computing can be mitigated using a self-adaptation approach, where systems are equipped to monitor and adjust themselves based on specific concerns. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, the tasks of boosting communication expressiveness within MASs and logically processing a multitude of variables in dynamic environments are still challenging. This paper presents a novel strategy: integrating large language models (LLMs) like GPT-based technologies into MASs to boost communication and agent autonomy. Our proposal encompasses the development of a novel LLM/GPT-based agent architecture, focusing not only on advanced conversation features but also on the reasoning and decision-making capacities of these models. This is grounded in the MAPE-K model, known for supporting system adaptability in dynamic environments. We illustrate our approach through a marketplace scenario. This work represents a paradigm shift in MAS self-adaptation, utilizing LLMs' capabilities and indicating further research opportunities to assess LLMs' applicability in more complex MAS scenarios. This could pave the way for more potent problem-solving capabilities and refined communication within MASs.", "citations": 67}
{"title": "Buy and Hold Versus Timing Strategies: The Winner Is \u2026", "year": 2015, "authors": "Todd J. Feldman, A. Jung, Jim Klein", "url": "https://www.semanticscholar.org/paper/5757157c41d1f323ee24eb56a3542ccd95145890", "relevance": 1, "abstract": "", "citations": 12}
{"title": "InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning", "year": 2023, "authors": "Yi Yang, Yixuan Tang, K. Tam", "url": "https://www.semanticscholar.org/paper/844bc3b26b5c63ec3b251ae634c194dcfb41a7d2", "relevance": 1, "abstract": "We present a new financial domain large language model, InvestLM, tuned on LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset related to financial investment. Inspired by less-is-more-for-alignment (Zhou et al., 2023), we manually curate a small yet diverse instruction dataset, covering a wide range of financial related topics, from Chartered Financial Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative finance discussions. InvestLM shows strong capabilities in understanding financial text and provides helpful responses to investment related questions. Financial experts, including hedge fund managers and research analysts, rate InvestLM's response as comparable to those of state-of-the-art commercial models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of financial NLP benchmarks demonstrates strong generalizability. From a research perspective, this work suggests that a high-quality domain specific LLM can be tuned using a small set of carefully curated instructions on a well-trained foundation model, which is consistent with the Superficial Alignment Hypothesis (Zhou et al., 2023). From a practical perspective, this work develops a state-of-the-art financial domain LLM with superior capability in understanding financial texts and providing helpful investment advice, potentially enhancing the work efficiency of financial professionals. We release the model parameters to the research community.", "citations": 106}
{"title": "Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework", "year": 2024, "authors": "Tianming Liu, Jirong Yang, Yafeng Yin", "url": "https://api.semanticscholar.org/CorpusId:274597928", "relevance": 1, "abstract": "In transportation system demand modeling and simulation, agent-based models and microsimulations are current state-of-the-art approaches. However, existing agent-based models still have some limitations on behavioral realism and resource demand that limit their applicability. In this study, leveraging the emerging technology of large language models (LLMs) and LLM-based agents, we propose a general LLM-agent-based modeling framework for transportation systems. We argue that LLM agents not only possess the essential capabilities to function as agents but also offer promising solutions to overcome some limitations of existing agent-based models. Our conceptual framework design closely replicates the decision-making and interaction processes and traits of human travelers within transportation networks, and we demonstrate that the proposed systems can meet critical behavioral criteria for decision-making and learning behaviors using related studies and a demonstrative example of LLM agents' learning and adjustment in the bottleneck setting. Although further refinement of the LLM-agent-based modeling framework is necessary, we believe that this approach has the potential to improve transportation system modeling and simulation.", "citations": 26}
{"title": "Evaluating and Aligning Human Economic Risk Preferences in LLMs", "year": 2025, "authors": "Jiaxin Liu, Yi Yang, K. Tam", "url": "https://api.semanticscholar.org/CorpusId:276902692", "relevance": 1, "abstract": "Large Language Models (LLMs) are increasingly used in decision-making scenarios that involve risk assessment, yet their alignment with human economic rationality remains unclear. In this study, we investigate whether LLMs exhibit risk preferences consistent with human expectations across different personas. Specifically, we assess whether LLM-generated responses reflect appropriate levels of risk aversion or risk-seeking behavior based on individual's persona. Our results reveal that while LLMs make reasonable decisions in simplified, personalized risk contexts, their performance declines in more complex economic decision-making tasks. To address this, we propose an alignment method designed to enhance LLM adherence to persona-specific risk preferences. Our approach improves the economic rationality of LLMs in risk-related applications, offering a step toward more human-aligned AI decision-making.", "citations": 6}
{"title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "authors": "Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\u00f6lkopf, Mrinmaya Sachan, Rada Mihalcea", "url": "https://api.semanticscholar.org/CorpusId:271088841", "relevance": 1, "abstract": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge. We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. In GovSim, a society of AI agents must collectively balance exploiting a common resource with sustaining it for future use. This environment enables the study of how ethical considerations, strategic planning, and negotiation skills impact cooperative outcomes. We develop an LLM-based agent architecture and test it with the leading open and closed LLMs. We find that all but the most powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with the highest survival rate below 54%. Ablations reveal that successful multi-agent communication between agents is critical for achieving cooperation in these cases. Furthermore, our analyses show that the failure to achieve sustainable cooperation in most LLMs stems from their inability to formulate and analyze hypotheses about the long-term effects of their actions on the equilibrium of the group. Finally, we show that agents that leverage\"Universalization\"-based reasoning, a theory of moral thinking, are able to achieve significantly better sustainability. Taken together, GovSim enables us to study the mechanisms that underlie sustainable self-government with specificity and scale. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.", "citations": 63}
{"title": "An Application of Deep Reinforcement Learning to Algorithmic Trading", "year": 2020, "authors": "Thibaut Th\u00e9ate, D. Ernst", "url": "https://www.semanticscholar.org/paper/95ff34ee03133e924d340f26041a8d2e459e17a8", "relevance": 1, "abstract": "This scientific research paper presents an innovative approach based on deep reinforcement learning (DRL) to solve the algorithmic trading problem of determining the optimal trading position at any point in time during a trading activity in stock markets. It proposes a novel DRL trading strategy so as to maximise the resulting Sharpe ratio performance indicator on a broad range of stock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this new trading strategy is inspired from the popular DQN algorithm and significantly adapted to the specific algorithmic trading problem at hand. The training of the resulting reinforcement learning (RL) agent is entirely based on the generation of artificial trajectories from a limited set of stock market historical data. In order to objectively assess the performance of trading strategies, the research paper also proposes a novel, more rigorous performance assessment methodology. Following this new performance assessment approach, promising results are reported for the TDQN strategy.", "citations": 202}
{"title": "Towards a Realistic Long-Term Benchmark for Open-Web Research Agents", "year": 2024, "authors": "Peter M\u00fchlbacher, N. Bosse, Lawrence Phillips", "url": "https://www.semanticscholar.org/paper/c7edf4733ae230433f09fb5cdd3f43cca7926f41", "relevance": 1, "abstract": "We present initial results of a forthcoming benchmark for evaluating LLM agents on white-collar tasks of economic value. We evaluate agents on real-world\"messy\"open-web research tasks of the type that are routine in finance and consulting. In doing so, we lay the groundwork for an LLM agent evaluation suite where good performance directly corresponds to a large economic and societal impact. We built and tested several agent architectures with o1-preview, GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), and GPT-4o-mini. On average, LLM agents powered by Claude-3.5 Sonnet and o1-preview substantially outperformed agents using GPT-4o, with agents based on Llama 3.1 (405b) and GPT-4o-mini lagging noticeably behind. Across LLMs, a ReAct architecture with the ability to delegate subtasks to subagents performed best. In addition to quantitative evaluations, we qualitatively assessed the performance of the LLM agents by inspecting their traces and reflecting on their observations. Our evaluation represents the first in-depth assessment of agents' abilities to conduct challenging, economically valuable analyst-style research on the real open web.", "citations": 3}
{"title": "AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents", "year": 2024, "authors": "Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, Qiang Qu, Shiwen Ni, Min Yang", "url": "https://api.semanticscholar.org/CorpusId:271874640", "relevance": 1, "abstract": "Current research in LLM-based simulation systems lacks comprehensive solutions for modeling real-world court proceedings, while existing legal language models struggle with dynamic courtroom interactions. We present AgentCourt, a comprehensive legal simulation framework that addresses these challenges through adversarial evolution of LLM-based agents. Our AgentCourt introduces a new adversarial evolutionary approach for agents called AdvEvol, which performs dynamic knowledge learning and evolution through structured adversarial interactions in a simulated courtroom program, breaking the limitations of the traditional reliance on static knowledge bases or manual annotations. By simulating 1,000 civil cases, we construct an evolving knowledge base that enhances the agents' legal reasoning abilities. The evolved lawyer agents demonstrated outstanding performance on our newly introduced CourtBench benchmark, achieving a 12.1% improvement in performance compared to the original lawyer agents. Evaluations by professional lawyers confirm the effectiveness of our approach across three critical dimensions: cognitive agility, professional knowledge, and logical rigor. Beyond outperforming specialized legal models in interactive reasoning tasks, our findings emphasize the importance of adversarial learning in legal AI and suggest promising directions for extending simulation-based legal reasoning to broader judicial and regulatory contexts. The project's code is available at: https://github.com/relic-yuexi/AgentCourt", "citations": 23}
{"title": "LLM-Generated Counterfactual Stress Scenarios for Portfolio Risk Simulation via Hybrid Prompt-RAG Pipeline", "year": 2025, "authors": "Masoud Soleimani", "url": "https://api.semanticscholar.org/CorpusId:283712015", "relevance": 1, "abstract": "We develop a transparent and fully auditable LLM-based pipeline for macro-financial stress testing, combining structured prompting with optional retrieval of country fundamentals and news. The system generates machine-readable macroeconomic scenarios for the G7, which cover GDP growth, inflation, and policy rates, and are translated into portfolio losses through a factor-based mapping that enables Value-at-Risk and Expected Shortfall assessment relative to classical econometric baselines. Across models, countries, and retrieval settings, the LLMs produce coherent and country-specific stress narratives, yielding stable tail-risk amplification with limited sensitivity to retrieval choices. Comprehensive plausibility checks, scenario diagnostics, and ANOVA-based variance decomposition show that risk variation is driven primarily by portfolio composition and prompt design rather than by the retrieval mechanism. The pipeline incorporates snapshotting, deterministic modes, and hash-verified artifacts to ensure reproducibility and auditability. Overall, the results demonstrate that LLM-generated macro scenarios, when paired with transparent structure and rigorous validation, can provide a scalable and interpretable complement to traditional stress-testing frameworks.", "citations": 0}
{"title": "The Memorization Problem: Can We Trust LLMs'Economic Forecasts?", "year": 2025, "authors": "Alejandro Lopez-Lira, Yuehua Tang, Mingyin Zhu", "url": "https://www.semanticscholar.org/paper/fa9b130f82c34376d296f3acb31aa402ab7d4978", "relevance": 1, "abstract": "Large language models (LLMs) cannot be trusted for economic forecasts during periods covered by their training data. Counterfactual forecasting ability is non-identified when the model has seen the realized values: any observed output is consistent with both genuine skill and memorization. Any evidence of memorization represents only a lower bound on encoded knowledge. We demonstrate LLMs have memorized economic and financial data, recalling exact values before their knowledge cutoff. Instructions to respect historical boundaries fail to prevent recall-level accuracy, and masking fails as LLMs reconstruct entities and dates from minimal context. Post-cutoff, we observe no recall. Memorization extends to embeddings.", "citations": 17}
{"title": "Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading", "year": 2025, "authors": "Jifeng Li, Arnav Grover, Abraham Alpuerto, Yupeng Cao, Xiao-Yang Liu", "url": "https://api.semanticscholar.org/CorpusId:283457821", "relevance": 1, "abstract": "The financial market is a mission-critical playground for AI agents due to its temporal dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for financial agents, which aims to democratize financial intelligence to the general public. We map each component of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execution agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of $20.42\\%$, a Sharpe ratio of 2.63, and a maximum drawdown of $-3.59\\%$, while the S&P 500 index yielded a return of $15.97\\%$. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of $8.39\\%$, a Sharpe ratio of $0.38$, and a maximum drawdown of $-2.80\\%$, whereas the BTC price increased by $3.80\\%$. Our code is available on \\href{https://github.com/Open-Finance-Lab/AgenticTrading}{GitHub}.", "citations": 0}
{"title": "A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models", "year": 2024, "authors": "Syed Affan Daimi, Asma Iqbal", "url": "https://api.semanticscholar.org/CorpusId:272911280", "relevance": 1, "abstract": "The number of companies listed on the NYSE has been growing exponentially, creating a significant challenge for market analysts, traders, and stockholders who must monitor and assess the performance and strategic shifts of a large number of companies regularly. There is an increasing need for a fast, cost-effective, and comprehensive method to evaluate the performance and detect and compare many companies' strategy changes efficiently. We propose a novel data-driven approach that leverages large language models (LLMs) to systematically analyze and rate the performance of companies based on their SEC 10-K filings. These filings, which provide detailed annual reports on a company's financial performance and strategic direction, serve as a rich source of data for evaluating various aspects of corporate health, including confidence, environmental sustainability, innovation, and workforce management. We also introduce an automated system for extracting and preprocessing 10-K filings. This system accurately identifies and segments the required sections as outlined by the SEC, while also isolating key textual content that contains critical information about the company. This curated data is then fed into Cohere's Command-R+ LLM to generate quantitative ratings across various performance metrics. These ratings are subsequently processed and visualized to provide actionable insights. The proposed scheme is then implemented on an interactive GUI as a no-code solution for running the data pipeline and creating the visualizations. The application showcases the rating results and provides year-on-year comparisons of company performance.", "citations": 2}
{"title": "Large investment model", "year": 2024, "authors": "Jian Guo, H. Shum", "url": "https://api.semanticscholar.org/CorpusId:271909355", "relevance": 1, "abstract": "Traditional quantitative investment research is encountering diminishing returns alongside rising labor and time costs. To overcome these challenges, we introduce the large investment model (LIM), a novel research paradigm designed to enhance both performance and efficiency at scale. LIM employs end-to-end learning and universal modeling to create an upstream foundation model, which is capable of autonomously learning comprehensive signal patterns from diverse financial data spanning multiple exchanges, instruments, and frequencies. These \u201cglobal patterns\u201d are subsequently transferred to downstream strategy modeling, optimizing performance for specific tasks. We detail the system architecture design of LIM, address the technical challenges inherent in this approach, and outline potential directions for future research.", "citations": 1}
{"title": "Inherent and emergent liability issues in LLM-based agentic systems: a principal-agent perspective", "year": 2025, "authors": "Garry Gabison, R. P. Xian, Ck Sq, An Ck Sq", "url": "https://api.semanticscholar.org/CorpusId:277596142", "relevance": 1, "abstract": "Agentic systems powered by large language models (LLMs) are becoming progressively more complex and capable. Their increasing agency and expanding deployment settings attract growing attention to effective governance policies, monitoring, and control protocols. Based on the emerging landscape of the agentic market, we analyze potential liability issues arising from the delegated use of LLM agents and their extended systems through a principal-agent perspective. Our analysis complements existing risk-based studies on artificial agency and covers the spectrum of important aspects of the principal-agent relationship and their potential consequences at deployment. Furthermore, we motivate method developments for technical governance along the directions of interpretability and behavior evaluations, reward and conflict management, and the mitigation of misalignment and misconduct through principled engineering of detection and fail-safe mechanisms. By illustrating the outstanding issues in AI liability for LLM-based agentic systems, we aim to inform the system design, auditing, and tracing to enhance transparency and liability attribution.", "citations": 11}
{"title": "Navigating Social Dilemmas with LLM-based Agents via Consideration of Future Consequences", "year": 2025, "authors": "D. Nguyen, Hung Le, Kien Do, Sunil Gupta, S. Venkatesh, T. Tran", "url": "https://www.semanticscholar.org/paper/d1650edb11e722dc905c0274c90e284feffbf58b", "relevance": 1, "abstract": "Artificial agents with the aid of large language models (LLMs) are effective in various real-world scenarios but struggle to cooperate in social dilemmas. When making decisions under the strain of selecting between long-term consequences and short-term benefits in commonly shared resources, LLM-based agents often exploit the environment, leading to early depletion. Inspired by the concept of consideration of future consequences (CFC), which is well-known in social psychology, we propose a framework to enable the ability to consider future consequences for LLM-based agents, which results in a new kind of agent that we term the CFC-Agent. We enable the CFC-Agent to act toward different levels of consideration for future consequences. Our first set of experiments, where LLM is directly asked to make decisions, shows that agents considering future consequences exhibit sustainable behaviour and achieve high common rewards for the population. Extensive experiments in complex environments showed that the CFC-Agent can manage a sequence of calls to LLM for reasoning and engaging in communication to cooperate with others to resolve the common dilemma better. Finally, our analysis showed that considering future consequences not only affects the final decision but also improves the conversations between LLM-based agents toward a better resolution of social dilemmas.", "citations": 2}
{"title": "DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments", "year": 2025, "authors": "Wenjie Tang, Yuan Zhou, Erqiang Xu, Keyan Cheng, Minne Li, Li Xiao", "url": "https://www.semanticscholar.org/paper/9c3fd36fce1d4ee1ad8240700a2938be7f582c73", "relevance": 1, "abstract": "Large Language Model~(LLM) based agents have been increasingly popular in solving complex and dynamic tasks, which requires proper evaluation systems to assess their capabilities. Nevertheless, existing benchmarks usually either focus on single-objective tasks or use overly broad assessing metrics, failing to provide a comprehensive inspection of the actual capabilities of LLM-based agents in complicated decision-making tasks. To address these issues, we introduce DSGBench, a more rigorous evaluation platform for strategic decision-making. Firstly, it incorporates six complex strategic games which serve as ideal testbeds due to their long-term and multi-dimensional decision-making demands and flexibility in customizing tasks of various difficulty levels or multiple targets. Secondly, DSGBench employs a fine-grained evaluation scoring system which examines the decision-making capabilities by looking into the performance in five specific dimensions and offering a comprehensive assessment in a well-designed way. Furthermore, DSGBench also incorporates an automated decision-tracking mechanism which enables in-depth analysis of agent behaviour patterns and the changes in their strategies. We demonstrate the advances of DSGBench by applying it to multiple popular LLM-based agents and our results suggest that DSGBench provides valuable insights in choosing LLM-based agents as well as improving their future development. DSGBench is available at https://github.com/DeciBrain-Group/DSGBench.", "citations": 11}
{"title": "MMAC-Copilot: Multi-modal Agent Collaboration Operating Copilot", "year": 2024, "authors": "Zirui Song, Yaohang Li, Meng Fang, Yanda Li, Zhenhao Chen, Zecheng Shi, Yuan Huang, Xiuying Chen, Ling Chen", "url": "https://api.semanticscholar.org/CorpusId:277271928", "relevance": 1, "abstract": "Large language model agents that interact with PC applications often face limitations due to their singular mode of interaction with real-world environments, leading to restricted versatility and frequent hallucinations. To address this, we propose the Multi-Modal Agent Collaboration framework (MMAC-Copilot), a framework utilizes the collective expertise of diverse agents to enhance interaction ability with application. The framework introduces a team collaboration chain, enabling each participating agent to contribute insights based on their specific domain knowledge, effectively reducing the hallucination associated with knowledge domain gaps. We evaluate MMAC-Copilot using the GAIA benchmark and our newly introduced Visual Interaction Benchmark (VIBench). MMAC-Copilot achieved exceptional performance on GAIA, with an average improvement of 6.8\\% over existing leading systems. VIBench focuses on non-API-interactable applications across various domains, including 3D gaming, recreation, and office scenarios. It also demonstrated remarkable capability on VIBench. We hope this work can inspire in this field and provide a more comprehensive assessment of Autonomous agents. The anonymous Github is available at \\href{https://anonymous.4open.science/r/ComputerAgentWithVision-3C12}{Anonymous Github}", "citations": 5}
{"title": "Can AI help with your personal finances?", "year": 2024, "authors": "Oudom Hean, Utsha Saha, Binita Saha", "url": "https://api.semanticscholar.org/CorpusId:275118850", "relevance": 1, "abstract": "ABSTRACT In recent years, Large Language Models (LLMs) have emerged as a transformative development in artificial intelligence (AI), drawing significant attention from industry and academia. Trained on vast datasets, these sophisticated AI systems exhibit impressive natural language processing and content generation capabilities. This paper explores the potential of LLMs to address key challenges in personal finance, focusing on the United States. We evaluate several leading LLMs, including OpenAI\u2019s ChatGPT, Google\u2019s Gemini, Anthropic\u2019s Claude, and Meta\u2019s Llama, to assess their effectiveness in providing accurate financial advice on topics such as mortgages, taxes, loans, and investments. Our findings show that, while these models achieve an average accuracy rate of approximately 70%, they also display notable limitations in certain areas. Specifically, LLMs struggle to provide accurate responses to complex financial queries, with performance varying significantly across different topics. Despite these limitations, the analysis reveals notable improvements in newer versions of these models, highlighting their growing utility for individuals and financial advisors. As these AI systems continue to evolve, their potential for advancing AI-driven applications in personal finance becomes increasingly promising.", "citations": 9}
{"title": "Decision Alignment Protocols: Harmonising AI Agents for Comprehensive Market Assessment", "year": 2025, "authors": "Akinyemi Arabambi, B. Kayode, Olamide Faroun, Fatimat Okeleye, Emereuwaonu Ezechukwu, Abiola Oludotun, Oluwatosin Oyeladun, Gabriel Aiyeetan", "url": "https://www.semanticscholar.org/paper/6845f676f49d186ea558565b1a53eed96c9cf219", "relevance": 1, "abstract": "As the complexity of global markets increases, the demand for coherent, high-fidelity decision-making in AI-driven investment analysis has intensified. This paper introduces Decision Alignment Protocols (DAPs), a novel framework that advances beyond existing multi-agent coordination approaches through structured negotiation protocols and formal alignment guarantees. Unlike current systems that rely on simple voting or averaging mechanisms, our approach introduces Weighted Practical Byzantine Fault Tolerance (WPBFT) consensus with evidence-based conflict resolution and systematic four-dimensional assessment integration (financial, technological, regulatory, sociocultural). We propose the Enhanced Decision Alignment Protocol (EDAP), which achieves $95 \\%+$ alignment consistency and 99.7 % conflict resolution success rate through mathematically formalized negotiation processes, significantly outperforming existing trading systems that lack formal decision coherence guarantees. Our evaluation demonstrates that while traditional models achieve up to 85.1 % accuracy in single-dimension optimization, EDAP provides 91.2 % accuracy with superior long-term risk management through comprehensive perspective integration and formal alignment verification.", "citations": 0}
{"title": "NegotiationGym: Self-Optimizing Agents in a Multi-Agent Social Simulation Environment", "year": 2025, "authors": "Shashank Mangla, Chris Hokamp, Jack Boylan, D. Ghalandari, Yuuv Jauhari, Lauren Cassidy, Oisin Duffy", "url": "https://api.semanticscholar.org/CorpusId:281843114", "relevance": 1, "abstract": "We design and implement NegotiationGym, an API and user interface for configuring and running multi-agent social simulations focused upon negotiation and cooperation. The NegotiationGym codebase offers a user-friendly, configuration-driven API that enables easy design and customization of simulation scenarios. Agent-level utility functions encode optimization criteria for each agent, and agents can self-optimize by conducting multiple interaction rounds with other agents, observing outcomes, and modifying their strategies for future rounds.", "citations": 2}
{"title": "A novel deep reinforcement learning framework with BiLSTM-Attention networks for algorithmic trading", "year": 2023, "authors": "Yuling Huang, Xiaoxiao Wan, Lin Zhang, Xiaoping Lu", "url": "https://www.semanticscholar.org/paper/5f4ca21e50b5b36e97f907a47b18f8c1aaf604d9", "relevance": 1, "abstract": "", "citations": 44}
{"title": "Multimodal Financial Foundation Models (MFFMs): Progress, Prospects, and Challenges", "year": 2025, "authors": "Xiao-Yang Liu Yanglet, Yupeng Cao, Li Deng", "url": "https://www.semanticscholar.org/paper/290fe5dfb5d33902c9311aaead75201747acc4d8", "relevance": 1, "abstract": "Financial Large Language Models (FinLLMs), such as open FinGPT and proprietary BloombergGPT, have demonstrated great potential in select areas of financial services. Beyond this earlier language-centric approach, Multimodal Financial Foundation Models (MFFMs) can digest interleaved multimodal financial data, including fundamental data, market data, data analytics, macroeconomic, and alternative data (e.g., natural language, audio, images, and video). In this position paper, presented at the MFFM Workshop joined with ACM International Conference on AI in Finance (ICAIF) 2024, we describe the progress, prospects, and challenges of MFFMs. This paper also highlights ongoing research on FinAgents in the \\textbf{SecureFinAI Lab}\\footnote{\\https://openfin.engineering.columbia.edu/} at Columbia University. We believe that MFFMs will enable a deeper understanding of the underlying complexity associated with numerous financial tasks and data, streamlining the operation of financial services and investment processes. Github Repo https://github.com/Open-Finance-Lab/Awesome-MFFMs/.", "citations": 5}
{"title": "QTMRL: An Agent for Quantitative Trading Decision-Making Based on Multi-Indicator Guided Reinforcement Learning", "year": 2025, "authors": "Xiangdong Liu, Jiahao Chen", "url": "https://api.semanticscholar.org/CorpusId:280950028", "relevance": 1, "abstract": "In the highly volatile and uncertain global financial markets, traditional quantitative trading models relying on statistical modeling or empirical rules often fail to adapt to dynamic market changes and black swan events due to rigid assumptions and limited generalization. To address these issues, this paper proposes QTMRL (Quantitative Trading Multi-Indicator Reinforcement Learning), an intelligent trading agent combining multi-dimensional technical indicators with reinforcement learning (RL) for adaptive and stable portfolio management. We first construct a comprehensive multi-indicator dataset using 23 years of S&P 500 daily OHLCV data (2000-2022) for 16 representative stocks across 5 sectors, enriching raw data with trend, volatility, and momentum indicators to capture holistic market dynamics. Then we design a lightweight RL framework based on the Advantage Actor-Critic (A2C) algorithm, including data processing, A2C algorithm, and trading agent modules to support policy learning and actionable trading decisions. Extensive experiments compare QTMRL with 9 baselines (e.g., ARIMA, LSTM, moving average strategies) across diverse market regimes, verifying its superiority in profitability, risk adjustment, and downside risk control. The code of QTMRL is publicly available at https://github.com/ChenJiahaoJNU/QTMRL.git", "citations": 0}
{"title": "Method For Medium- to Long-Term Time-of-day Trading Decision in Agent-Based Power Purchase of Grid Enterprises Considering CVaR", "year": 2024, "authors": "Yue Shi, Jiangbo Wang, Junhui Liu, Yao Lu, Shuo Yin, Mingshun Ji, Xinrui Zhong, Yihang Zhang", "url": "https://www.semanticscholar.org/paper/b07278f1ab70a8876a89774f22cccce8acf1da39", "relevance": 1, "abstract": ". To further promote fair participation of grid enterprise agent power purchasers in electricity spot trading, it is necessary to strengthen the connection mechanism between agent power purchase activities and the medium-to long-term electricity market and spot market. Given the uncertainty in the electricity demand of agent users and market prices, a reasonable allocation of power purchase proportions in multi-time scales and multi-product electricity trading can help reduce cash flow risks for grid enterprises and promote the safe and stable operation of the electricity market. The optimal strategy is determined using the Monte Carlo simulation method, and the effectiveness of the proposed model and method is validated through numerical examples. The results demonstrate a reduction in conditional risk value and other relevant indicators, providing grid enterprises with valuable references for mitigating trading risks and formulating agent power purchase strategies.", "citations": 0}
{"title": "Your AI, Not Your View: The Bias of LLMs in Investment Analysis", "year": 2025, "authors": "Hoyoung Lee, Junhyuk Seo, Suhwan Park, Junhyeong Lee, Wonbin Ahn, Chanyeol Choi, Alejandro Lopez-Lira, Yongjae Lee", "url": "https://api.semanticscholar.org/CorpusId:280323470", "relevance": 1, "abstract": "In finance, Large Language Models (LLMs) face frequent knowledge conflicts arising from discrepancies between their pre-trained parametric knowledge and real-time market data. These conflicts are especially problematic in real-world investment services, where a model\u2019s inherent biases can misalign with institutional objectives, leading to unreliable recommendations. Despite this risk, the intrinsic investment biases of LLMs remain underexplored. We propose an experimental framework to investigate emergent behaviors in such conflict scenarios, offering a quantitative analysis of bias in LLM-based investment analysis. Using hypothetical scenarios with balanced and imbalanced arguments, we extract the latent biases of models and measure their persistence. Our analysis, centered on sector, size, and momentum, reveals distinct, model-specific biases. Across most models, a tendency to prefer technology stocks, large-cap stocks, and contrarian strategies is observed. These foundational biases often escalate into confirmation bias, causing models to cling to initial judgments even when faced with increasing counter-evidence. A public leaderboard benchmarking bias across a broader set of models is available at https://linqalpha.com/leaderboard.", "citations": 6}
{"title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "authors": "Yuzhi Hao, Danyang Xie", "url": "https://api.semanticscholar.org/CorpusId:276575123", "relevance": 1, "abstract": "This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial economic agents. We first evaluate five LLMs' economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: with explicit utility functions and based on intuitive reasoning. While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB) framework by mapping these LLMs to specific educational groups and corresponding income brackets. Using interest-income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs' human-like reasoning capabilities and computational power.", "citations": 6}
{"title": "ESG Beliefs of Large Language Models: Evidence and Impact", "year": 2025, "authors": "Tong Li, Luping Yu", "url": "https://api.semanticscholar.org/CorpusId:284487817", "relevance": 1, "abstract": "We examine whether large language models (LLMs) hold systematic beliefs about environmental, social, and governance (ESG) issues and how these beliefs compare with-and potentially influence-those of human market participants. Based on established surveys originally administered to professional and retail investors, we show that major LLMs exhibit a strong pro-ESG orientation. Compared with human investors, LLMs assign greater financial relevance for ESG performance, expect larger return premia for high-ESG firms, and display a stronger willingness to sacrifice financial returns for ESG improvements. These preferences are highly uniform and values-driven, in contrast to heterogeneous human views. Using a large dataset of analyst reports, we further show that sell-side analysts become significantly more optimistic about high-ESG firms after adopting LLMs for research. Our findings reveal that LLMs embed distinct, coherent ESG beliefs and that these beliefs can shape human judgments, highlighting a new channel through which AI adoption may influence financial markets.", "citations": 0}
{"title": "Large Language Models in Finance: A Survey", "year": 2023, "authors": "Yinheng Li, Shaofei Wang, Han Ding, Hang Chen", "url": "https://www.semanticscholar.org/paper/5432b77bfb1dced97c5b1fc684b0fa7d0d84c424", "relevance": 1, "abstract": "Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.", "citations": 375}
{"title": "A Literature Review of Gen AI Agents in Financial Applications: Models and Implementations", "year": 2025, "authors": "Satyadhar Joshi", "url": "https://api.semanticscholar.org/CorpusId:275985200", "relevance": 1, "abstract": ": This paper presents a structured literature review of AI agents in financial applications, focusing on their implementation frameworks, model architectures, and future directions. The review categorizes AI agents into five key domains: financial risk management, investment strategies, fraud detection, stock market analysis, and customer support. By analyzing measurable outcomes, the paper highlights significant contributions (from the literature) of AI agents, including a 25% improvement in risk model accuracy, a 20% reduction in loan defaults, and a 40% decrease in false-positive fraud detections. Additionally, it identifies gaps in scalability, interpretability, and adaptability, proposing future research into hybrid models and ethical integration. This review provides actionable insights into the transformative potential of AI agents to reshape financial ecosystems and enhance decision-making capabilities. Quantitative outcomes are highlighted to showcase the impact of these agents across each domain. Also, this paper discusses and compare the modeling implementation and models with the financial domain using van diagrams, heat maps and radars. And finally proposes how to address the gaps in the current literature. This work uses research and white-papers only from the last six months making it one of the most current works in the subject of Gen AI.", "citations": 22}
{"title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning", "year": 2025, "authors": "Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Jingze Song, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wei Wang, Peng Zhang", "url": "https://api.semanticscholar.org/CorpusId:280017868", "relevance": 1, "abstract": "Large Language Models (LLMs) exhibit considerable promise in financial applications; however, prevailing models frequently demonstrate limitations when confronted with scenarios that necessitate sophisticated reasoning capabilities, stringent trustworthiness criteria, and efficient adaptation to domain-specific requirements. We introduce the Agentar-Fin-R1 series of financial large language models (8B and 32B parameters), specifically engineered based on the Qwen3 foundation model to enhance reasoning capabilities, reliability, and domain specialization for financial applications. Our optimization approach integrates a high-quality, systematic financial task label system with a comprehensive multi-layered trustworthiness assurance framework. This framework encompasses high-quality trustworthy knowledge engineering, multi-agent trustworthy data synthesis, and rigorous data validation governance. Through label-guided automated difficulty-aware optimization, tow-stage training pipeline, and dynamic attribution systems, we achieve substantial improvements in training efficiency. Our models undergo comprehensive evaluation on mainstream financial benchmarks including Fineva, FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500 and GPQA-diamond. To thoroughly assess real-world deployment capabilities, we innovatively propose the Finova evaluation benchmark, which focuses on agent-level financial reasoning and compliance verification. Experimental results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art performance on financial tasks but also exhibits exceptional general reasoning capabilities, validating its effectiveness as a trustworthy solution for high-stakes financial applications. The Finova bench is available at https://github.com/antgroup/Finova.", "citations": 1}
{"title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra", "year": 2025, "authors": "Seth Karten, Wenzhe Li, Zihan Ding, Samuel Kleiner, Yu Bai, Chi Jin", "url": "https://api.semanticscholar.org/CorpusId:280271612", "relevance": 1, "abstract": "We present the LLM Economist, a novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agents -- instantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statistics -- choose labor supply to maximize text-based utility functions learned in-context. At the upper level, a planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism design -- the ultimate nudging problem -- expressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while a periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing a tractable test bed for policy evaluation at the societal scale to help build better civilizations.", "citations": 8}
{"title": "Prompt Engineering Through the Lens of Optimal Control", "year": 2023, "authors": "Yifan Luo, Yiming Tang, Chengfeng Shen, Zhennan Zhou, Bin Dong", "url": "https://api.semanticscholar.org/CorpusId:264426100", "relevance": 1, "abstract": "Prompt Engineering (PE) has emerged as a critical technique for guiding Large Language Models (LLMs) in solving intricate tasks. Its importance is highlighted by its potential to significantly enhance the efficiency and effectiveness of human-machine interaction. As tasks grow increasingly complex, recent advanced PE methods have extended beyond the limitations of single-round interactions to embrace multi-round interactions, which allows for a deeper and more nuanced engagement with LLMs. In this paper, we propose an optimal control framework tailored for multi-round interactions with LLMs. This framework provides a unified mathematical structure that not only systematizes the existing PE methods but also sets the stage for rigorous analytical improvements. Furthermore, we extend this framework to include PE via ensemble methods and multi-agent collaboration, thereby enlarging the scope of applicability. By adopting an optimal control perspective, we offer fresh insights into existing PE methods and highlight theoretical challenges that warrant future research. Besides, our work lays a foundation for the development of more effective and interpretable PE methods.", "citations": 15}
{"title": "FinGPT: Open-Source Financial Large Language Models", "year": 2023, "authors": "Hongyang Yang, Xiao-Yang Liu, Chris Wang", "url": "https://www.semanticscholar.org/paper/5dea206e2a36e672f197252bdd27d156d058f48c", "relevance": 1, "abstract": "Large language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparking great interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data. In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes a data-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and low-code development. Through collaborative efforts within the open-source AI4Finance community, FinGPT aims to stimulate innovation, democratize FinLLMs, and unlock new opportunities in open finance. Two associated code repos are https://github.com/AI4Finance-Foundation/FinGPT and https://github.com/AI4Finance-Foundation/FinNLP", "citations": 330}
{"title": "Large Language Models in Finance (FinLLMs)", "year": 2024, "authors": "Jean Lee, Nicholas Stevens, S. Han, Minseok Song", "url": "https://www.semanticscholar.org/paper/d80a87f3624461b36acdeb809c50979ba89fb1be", "relevance": 1, "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities and have attracted significant attention across diverse domains, including financial services. Despite the extensive research into general-domain LLMs and their immense potential in finance, financial LLMs (FinLLMs) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, downstream tasks associated with datasets, evaluations, and opportunities and challenges. Firstly, we present a chronological overview of general-domain language models (LMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across eight financial LMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets and provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and benchmarks on GitHub. (https://github.com/adlnlp/FinLLMs)", "citations": 121}
{"title": "Building crypto portfolios with agentic AI", "year": 2025, "authors": "Antonino Castelli, Paolo Giudici, Alessandro Piergallini", "url": "https://api.semanticscholar.org/CorpusId:280322919", "relevance": 1, "abstract": "The rapid growth of crypto markets has opened new opportunities for investors, but at the same time exposed them to high volatility. To address the challenge of managing dynamic portfolios in such an environment, this paper presents a practical application of a multi-agent system designed to autonomously construct and evaluate crypto-asset allocations. Using data on daily frequencies of the ten most capitalized cryptocurrencies from 2020 to 2025, we compare two automated investment strategies. These are a static equal weighting strategy and a rolling-window optimization strategy, both implemented to maximize the evaluation metrics of the Modern Portfolio Theory (MPT), such as Expected Return, Sharpe and Sortino ratios, while minimizing volatility. Each step of the process is handled by dedicated agents, integrated through a collaborative architecture in Crew AI. The results show that the dynamic optimization strategy achieves significantly better performance in terms of risk-adjusted returns, both in-sample and out-of-sample. This highlights the benefits of adaptive techniques in portfolio management, particularly in volatile markets such as cryptocurrency markets. The following methodology proposed also demonstrates how multi-agent systems can provide scalable, auditable, and flexible solutions in financial automation.", "citations": 0}
{"title": "Revolutionizing Finance with LLMs: An Overview of Applications and Insights", "year": 2024, "authors": "Huaqin Zhao, Zheng Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, Tianming Liu", "url": "https://api.semanticscholar.org/CorpusId:267069342", "relevance": 1, "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seen considerable advancements and have been applied in diverse fields. Built on the Transformer architecture, these models are trained on extensive datasets, enabling them to understand and generate human language effectively. In the financial domain, the deployment of LLMs is gaining momentum. These models are being utilized for automating financial report generation, forecasting market trends, analyzing investor sentiment, and offering personalized financial advice. Leveraging their natural language processing capabilities, LLMs can distill key insights from vast financial data, aiding institutions in making informed investment choices and enhancing both operational efficiency and customer satisfaction. In this study, we provide a comprehensive overview of the emerging integration of LLMs into various financial tasks. Additionally, we conducted holistic tests on multiple financial tasks through the combination of natural language instructions. Our findings show that GPT-4 effectively follow prompt instructions across various financial tasks. This survey and evaluation of LLMs in the financial domain aim to deepen the understanding of LLMs'current role in finance for both financial practitioners and LLM researchers, identify new research and application prospects, and highlight how these technologies can be leveraged to solve practical challenges in the finance industry.", "citations": 147}
{"title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "year": 2023, "authors": "Alejandro Lopez-Lira, Yuehua Tang", "url": "https://api.semanticscholar.org/CorpusId:258071542", "relevance": 1, "abstract": "We document the capability of large language models (LLMs) like ChatGPT to predict stock market reactions from news headlines without direct financial training. Using post-knowledge-cutoff headlines, GPT-4 captures initial market responses, achieving approximately 90% portfolio-day hit rates for the non-tradable initial reaction. GPT-4 scores also significantly predict the subsequent drift, especially for small stocks and negative news. Forecasting ability generally increases with model size, suggesting that financial reasoning is an emerging capacity of complex LLMs. Strategy returns decline as LLM adoption rises, consistent with improved price efficiency. To rationalize these findings, we develop a theoretical model that incorporates LLM technology, information-processing capacity constraints, underreaction, and limits to arbitrage.", "citations": 270}
{"title": "Temporal Data Meets LLM - Explainable Financial Time Series Forecasting", "year": 2023, "authors": "Xinli Yu, Zheng Chen, Yuan Ling, Shujing Dong, Zongying Liu, Yanbin Lu", "url": "https://api.semanticscholar.org/CorpusId:259203723", "relevance": 1, "abstract": "This paper presents a novel study on harnessing Large Language Models' (LLMs) outstanding knowledge and reasoning abilities for explainable financial time series forecasting. The application of machine learning models to financial time series comes with several challenges, including the difficulty in cross-sequence reasoning and inference, the hurdle of incorporating multi-modal signals from historical news, financial knowledge graphs, etc., and the issue of interpreting and explaining the model results. In this paper, we focus on NASDAQ-100 stocks, making use of publicly accessible historical stock price data, company metadata, and historical economic/financial news. We conduct experiments to illustrate the potential of LLMs in offering a unified solution to the aforementioned challenges. Our experiments include trying zero-shot/few-shot inference with GPT-4 and instruction-based fine-tuning with a public LLM model Open LLaMA. We demonstrate our approach outperforms a few baselines, including the widely applied classic ARMA-GARCH model and a gradient-boosting tree model. Through the performance comparison results and a few examples, we find LLMs can make a well-thought decision by reasoning over information from both textual news and price time series and extracting insights, leveraging cross-sequence information, and utilizing the inherent knowledge embedded within the LLM. Additionally, we show that a publicly available LLM such as Open-LLaMA, after fine-tuning, can comprehend the instruction to generate explainable forecasts and achieve reasonable performance, albeit relatively inferior in comparison to GPT-4.", "citations": 113}
{"title": "FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets", "year": 2023, "authors": "Neng Wang, Hongyang Yang, Chris Wang", "url": "https://api.semanticscholar.org/CorpusId:263829590", "relevance": 1, "abstract": "In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for open-source large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, we delve into a comprehensive model, executing multi-task operations by amalgamating all instructional tunings to examine versatility. Finally, we explore the zero-shot capabilities by earmarking unseen tasks and incorporating novel datasets to understand adaptability in uncharted terrains. Such a paradigm fortifies the principles of openness and reproducibility, laying a robust foundation for future investigations in open-source financial large language models (FinLLMs).", "citations": 97}
{"title": "What Teaches Robots to Walk, Teaches Them to Trade too - Regime Adaptive Execution using Informed Data and LLMs", "year": 2024, "authors": "Raeid Saqur", "url": "https://api.semanticscholar.org/CorpusId:270703762", "relevance": 1, "abstract": "Machine learning techniques applied to the problem of financial market forecasting struggle with dynamic regime switching, or underlying correlation and covariance shifts in true (hidden) market variables. Drawing inspiration from the success of reinforcement learning in robotics, particularly in agile locomotion adaptation of quadruped robots to unseen terrains, we introduce an innovative approach that leverages world knowledge of pretrained LLMs (aka. 'privileged information' in robotics) and dynamically adapts them using intrinsic, natural market rewards using LLM alignment technique we dub as\"Reinforcement Learning from Market Feedback\"(**RLMF**). Strong empirical results demonstrate the efficacy of our method in adapting to regime shifts in financial markets, a challenge that has long plagued predictive models in this domain. The proposed algorithmic framework outperforms best-performing SOTA LLM models on the existing (FLARE) benchmark stock-movement (SM) tasks by more than 15\\% improved accuracy. On the recently proposed NIFTY SM task, our adaptive policy outperforms the SOTA best performing trillion parameter models like GPT-4. The paper details the dual-phase, teacher-student architecture and implementation of our model, the empirical results obtained, and an analysis of the role of language embeddings in terms of Information Gain.", "citations": 3}
{"title": "Trust & Safety of LLMs and LLMs in Trust & Safety", "year": 2024, "authors": "Doohee You, Dan Chon", "url": "https://api.semanticscholar.org/CorpusId:274445619", "relevance": 1, "abstract": "In recent years, Large Language Models (LLMs) have garnered considerable attention for their remarkable abilities in natural language processing tasks. However, their widespread adoption has raised concerns pertaining to trust and safety. This systematic review investigates the current research landscape on trust and safety in LLMs, with a particular focus on the novel application of LLMs within the field of Trust and Safety itself. We delve into the complexities of utilizing LLMs in domains where maintaining trust and safety is paramount, offering a consolidated perspective on this emerging trend.\\ By synthesizing findings from various studies, we identify key challenges and potential solutions, aiming to benefit researchers and practitioners seeking to understand the nuanced interplay between LLMs and Trust and Safety. This review provides insights on best practices for using LLMs in Trust and Safety, and explores emerging risks such as prompt injection and jailbreak attacks. Ultimately, this study contributes to a deeper understanding of how LLMs can be effectively and responsibly utilized to enhance trust and safety in the digital realm.", "citations": 3}
{"title": "FinRL: deep reinforcement learning framework to automate trading in quantitative finance", "year": 2021, "authors": "Xiao-Yang Liu, Hongyang Yang, Jiechao Gao, Chris Wang", "url": "https://www.semanticscholar.org/paper/69b0012f366367a3bb2d182aa0a8ebae35b95255", "relevance": 1, "abstract": "Deep reinforcement learning (DRL) has been envisioned to have a competitive edge in quantitative finance. However, there is a steep development curve for quantitative traders to obtain an agent that automatically positions to win in the market, namely to decide where to trade, at what price and what quantity, due to the error-prone programming and arduous debugging. In this paper, we present the first open-source framework FinRL as a full pipeline to help quantitative traders overcome the steep learning curve. FinRL is featured with simplicity, applicability and extensibility under the key principles, full-stack framework, customization, reproducibility and hands-on tutoring. Embodied as a three-layer architecture with modular structures, FinRL implements fine-tuned state-of-the-art DRL algorithms and common reward functions, while alleviating the debugging workloads. Thus, we help users pipeline the strategy design at a high turnover rate. At multiple levels of time granularity, FinRL simulates various markets as training environments using historical data and live trading APIs. Being highly extensible, FinRL reserves a set of user-import interfaces and incorporates trading constraints such as market friction, market liquidity and investor's risk-aversion. Moreover, serving as practitioners' stepping stones, typical trading tasks are provided as step-by-step tutorials, e.g., stock trading, portfolio allocation, cryptocurrency trading, etc.", "citations": 128}
{"title": "Knowing What You Know Is Not Enough: Large Language Model Confidences Don't Align With Their Actions", "year": 2025, "authors": "Arka Pal, Teo Kitanovski, Arthur Liang, Akilesh Potti, Micah Goldblum", "url": "https://www.semanticscholar.org/paper/3259e1c0608311b072d560323ae293572832fc5c", "relevance": 1, "abstract": "Large language models (LLMs) are increasingly deployed in agentic and multi-turn workflows where they are tasked to perform actions of significant consequence. In order to deploy them reliably and manage risky outcomes in these settings, it is helpful to access model uncertainty estimates. However, confidence elicitation methods for LLMs are typically not evaluated directly in agentic settings; instead, they are evaluated on static datasets, such as Q&A benchmarks. In this work we investigate the relationship between confidence estimates elicited in static settings and the behavior of LLMs in interactive settings. We uncover a significant action-belief gap -- LLMs frequently take actions that contradict their elicited confidences. In a prediction market setting, we find that models often bet against their own high-confidence predictions; in a tool-use setting, models fail to reliably invoke information-seeking tools when their internal confidence is low; and in a user-challenge setting, models change their answers when they have high confidence in them, whilst sticking to answers they have low confidence in. Crucially, we show that static calibration is an insufficient predictor of consistency in the above dynamic settings, as stronger, better calibrated models are somtimes less consistent than their smaller and weaker open-source counterparts. Our results highlight a critical blind spot in current evaluation methodologies: ensuring that a model knows what it knows does not guarantee that it will act rationally on that knowledge.", "citations": 1}
{"title": "Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning", "year": 2025, "authors": "Zhaowei Liu, Xin Guo, Fangqi Lou, Lingfeng Zeng, Jinyi Niu, Zixuan Wang, Jiajie Xu, Weige Cai, Ziwei Yang, Xueqian Zhao, Chaojun Li, Sheng Xu, Dezhi Chen, Yun Chen, Zuo Bai, Liwen Zhang", "url": "https://www.semanticscholar.org/paper/95d638e7705ec561382268405bc488df4c26c7f7", "relevance": 1, "abstract": "In recent years, general-purpose large language models (LLMs) such as GPT, Gemini, Claude, and DeepSeek have advanced at an unprecedented pace. Despite these achievements, their application to finance remains challenging, due to fragmented data sources, intransparent reasoning processes, and weak transferability to business applications. In response, we introduce Fin-R1, a reasoning LLM designed for financial scenarios. With a compact size of 7 billion parameters, Fin-R1 reduces deployment costs while addressing the aforementioned challenges. Its development follows a two-stage pipeline. First, we construct Fin-R1-Data, a high-quality financial dataset consisting of 60,091 chain-of-thought (CoT) samples, distilled and filtered from multiple authoritative benchmarks to ensure consistency and reliability. Second, we train Fin-R1 using Fin-R1-Data through supervised fine-tuning (SFT), followed by reinforcement learning (RL). This stage substantially improves the model's ability to solve complex financial reasoning tasks, yielding outputs that are both accurate and interpretable. Despite its relatively small parameter scale, Fin-R1 achieves competitive empirical performance across established financial benchmarks and demonstrates practical utility in compliance checking and robo-advisory. Our code is publicly available at https://github.com/SUFE-AIFLM-Lab/Fin-R1, and has already attracted over 700 stars.", "citations": 55}
{"title": "The Evolution of Reinforcement Learning in Quantitative Finance: A Survey", "year": 2024, "authors": "Nikolaos Pippas, C. Turkay, Elliot A. Ludvig", "url": "https://api.semanticscholar.org/CorpusId:271909804", "relevance": 1, "abstract": "Reinforcement Learning (RL) has experienced significant advancement over the past decade, prompting a growing interest in applications within finance. This survey critically evaluates 167 publications, exploring diverse RL applications and frameworks in finance. Financial markets, marked by their complexity, multi-agent nature, information asymmetry, and inherent randomness, serve as an intriguing test-bed for RL. Traditional finance offers certain solutions, and RL advances these with a more dynamic approach, incorporating machine learning methods, including transfer learning, meta-learning, and multi-agent solutions. This survey dissects key RL components through the lens of Quantitative Finance. We uncover emerging themes, propose areas for future research, and critique the strengths and weaknesses of existing methods.", "citations": 15}
{"title": "Developing A Multi-Agent and Self-Adaptive Framework with Deep Reinforcement Learning for Dynamic Portfolio Risk Management", "year": 2024, "authors": "Zhenglong Li, Vincent Tam, K. L. Yeung", "url": "https://api.semanticscholar.org/CorpusId:267364984", "relevance": 1, "abstract": "Deep or reinforcement learning (RL) approaches have been adapted as reactive agents to quickly learn and respond with new investment strategies for portfolio management under the highly turbulent financial market environments in recent years. In many cases, due to the very complex correlations among various financial sectors, and the fluctuating trends in different financial markets, a deep or reinforcement learning based agent can be biased in maximising the total returns of the newly formulated investment portfolio while neglecting its potential risks under the turmoil of various market conditions in the global or regional sectors. Accordingly, a multi-agent and self-adaptive framework namely the MASA is proposed in which a sophisticated multi-agent reinforcement learning (RL) approach is adopted through two cooperating and reactive agents to carefully and dynamically balance the trade-off between the overall portfolio returns and their potential risks. Besides, a very flexible and proactive agent as the market observer is integrated into the MASA framework to provide some additional information on the estimated market trends as valuable feedbacks for multi-agent RL approach to quickly adapt to the ever-changing market conditions. The obtained empirical results clearly reveal the potential strengths of our proposed MASA framework based on the multi-agent RL approach against many well-known RL-based approaches on the challenging data sets of the CSI 300, Dow Jones Industrial Average and S&P 500 indexes over the past 10 years. More importantly, our proposed MASA framework shed lights on many possible directions for future investigation.", "citations": 12}
{"title": "Deep Graph Convolutional Reinforcement Learning for Financial Portfolio Management - DeepPocket", "year": 2021, "authors": "Farzan Soleymani, E. Paquet", "url": "https://api.semanticscholar.org/CorpusId:234763402", "relevance": 1, "abstract": "Portfolio management aims at maximizing the return on investment while minimizing risk by continuously reallocating the assets forming the portfolio These assets are not independent but correlated during a short time period A graph convolutional reinforcement learning framework called DeepPocket is proposed whose objective is to exploit the time-varying interrelations between financial instruments These interrelations are represented by a graph whose nodes correspond to the financial instruments while the edges correspond to a pair-wise correlation function in between assets DeepPocket consists of a restricted, stacked autoencoder for feature extraction, a convolutional network to collect underlying local information shared among financial instruments and an actor\u2013critic reinforcement learning agent The actor\u2013critic structure contains two convolutional networks in which the actor learns and enforces an investment policy which is, in turn, evaluated by the critic in order to determine the best course of action by constantly reallocating the various portfolio assets to optimize the expected return on investment The agent is initially trained offline with online stochastic batching on historical data As new data become available, it is trained online with a passive concept drift approach to handle unexpected changes in their distributions DeepPocket is evaluated against five real-life datasets over three distinct investment periods, including during the Covid-19 crisis, and clearly outperformed market indexes", "citations": 65}
{"title": "Beyond Classification: Financial Reasoning in State-of-the-Art Language Models", "year": 2023, "authors": "Guijin Son, Han-Na Jung, M. Hahm, Keonju Na, Sol Jin", "url": "https://api.semanticscholar.org/CorpusId:258437058", "relevance": 1, "abstract": "Large Language Models (LLMs), consisting of 100 billion or more parameters, have demonstrated remarkable ability in complex multi-step reasoning tasks. However, the application of such generic advancements has been limited to a few fields, such as clinical or legal, with the field of financial reasoning remaining largely unexplored. To the best of our knowledge, the ability of LLMs to solve financial reasoning problems has never been dealt with, and whether it can be performed at any scale remains unknown. To address this knowledge gap, this research presents a comprehensive investigation into the potential application of LLMs in the financial domain. The investigation includes a detailed exploration of a range of subjects, including task formulation, synthetic data generation, prompting methods, and evaluation capability. Furthermore, the study benchmarks various GPT variants with parameter scales ranging from 2.8B to 13B, with and without instruction tuning, on diverse dataset sizes. By analyzing the results, we reveal that the ability to generate coherent financial reasoning first emerges at 6B parameters, and continues to improve with better instruction-tuning or larger datasets. Additionally, the study provides a publicly accessible dataset named sFIOG (Synthetic-Financial Investment Opinion Generation), consisting of 11,802 synthetic investment thesis samples, to support further research in the field of financial reasoning. Overall, this research seeks to contribute to the understanding of the efficacy of language models in the field of finance, with a particular emphasis on their ability to engage in sophisticated reasoning and analysis within the context of investment decision-making.", "citations": 23}
{"title": "Portfolio construction using explainable reinforcement learning", "year": 2024, "authors": "Daniel Gonz\u00e1lez-Cort\u00e9s, Enrique Onieva, Iker Pastor, Laura Trinchera, Jian Wu", "url": "https://api.semanticscholar.org/CorpusId:270999002", "relevance": 1, "abstract": "While machine learning's role in financial trading has advanced considerably, algorithmic transparency and explainability challenges still exist. This research enriches prior studies focused on high\u2010frequency financial data prediction by introducing an explainable reinforcement learning model for portfolio management. This model transcends basic asset prediction, formulating concrete, actionable trading strategies. The methodology is applied in a custom trading environment mimicking the CAC\u201040 index's financial conditions, allowing the model to adapt dynamically to market changes based on iterative learning from historical data. Empirical findings reveal that the model outperforms an equally weighted portfolio in out\u2010of\u2010sample tests. The study offers a dual contribution: it elevates algorithmic planning while significantly boosting transparency and interpretability in financial machine learning. This approach tackles the enduring \u2018black\u2010box\u2019 issue and provides a holistic, transparent framework for managing investment portfolios.", "citations": 4}
{"title": "Cross-Asset Risk Management: Integrating LLMs for Real-Time Monitoring of Equity, Fixed Income, and Currency Markets", "year": 2025, "authors": "Jie Yang, Yiqiu Tang, Yongjie Li, Lihua Zhang, Haoran Zhang", "url": "https://api.semanticscholar.org/CorpusId:277621874", "relevance": 1, "abstract": "Large language models (LLMs) have emerged as powerful tools in the field of finance, particularly for risk management across different asset classes. In this work, we introduce a Cross-Asset Risk Management framework that utilizes LLMs to facilitate real-time monitoring of equity, fixed income, and currency markets. This innovative approach enables dynamic risk assessment by aggregating diverse data sources, ultimately enhancing decision-making processes. Our model effectively synthesizes and analyzes market signals to identify potential risks and opportunities while providing a holistic view of asset classes. By employing advanced analytics, we leverage LLMs to interpret financial texts, news articles, and market reports, ensuring that risks are contextualized within broader market narratives. Extensive backtesting and real-time simulations validate the framework, showing increased accuracy in predicting market shifts compared to conventional methods. The focus on real-time data integration enhances responsiveness, allowing financial institutions to manage risks adeptly under varying market conditions and promoting financial stability through the advanced application of LLMs in risk analysis.", "citations": 1}
{"title": "Novel Deep Reinforcement Algorithm With Adaptive Sampling Strategy for Continuous Portfolio Optimization", "year": 2021, "authors": "Szu-Hao Huang, Yu-Hsiang Miao, Yi-Ting Hsiao", "url": "https://api.semanticscholar.org/CorpusId:235308542", "relevance": 1, "abstract": "Quantitative trading targets favorable returns by determining patterns in historical data through statistical or mathematical approaches. With advances in artificial intelligence, many studies have indicated that deep reinforcement learning (RL) can perform well in quantitative trading by predicting price change trends in the financial market. However, most of the related frameworks display poor generalizability in the testing stage. Thus, we incorporated adversarial learning and a novel sampling strategy for RL portfolio management. The goal was to construct a portfolio comprising five assets from the constituents of the Dow Jones Industrial Average and to achieve excellent performance through our trading strategy. We used adversarial learning during the RL process to enhance the model\u2019s robustness. Moreover, to improve the model\u2019s computational efficiency, we introduced a novel sampling strategy to determine which data are worth learning by observing the learning condition. The experimental results revealed that the model with our sampling strategy had more favorable performance than the random learning strategy. The Sharpe ratio increased by 6 %\u20137 %, and profit increased by nearly 45 %. Thus, our proposed learning framework and the sampling strategy we employed are conducive to obtaining reliable trading rules.", "citations": 21}
{"title": "Reinforcement-Learning Portfolio Allocation with Dynamic Embedding of Market Information", "year": 2025, "authors": "Jinghai He, Cheng Hua, Chunyang Zhou, Zeyu Zheng", "url": "https://api.semanticscholar.org/CorpusId:275994079", "relevance": 1, "abstract": "We develop a portfolio allocation framework that leverages deep learning techniques to address challenges arising from high-dimensional, non-stationary, and low-signal-to-noise market information. Our approach includes a dynamic embedding method that reduces the non-stationary, high-dimensional state space into a lower-dimensional representation. We design a reinforcement learning (RL) framework that integrates generative autoencoders and online meta-learning to dynamically embed market information, enabling the RL agent to focus on the most impactful parts of the state space for portfolio allocation decisions. Empirical analysis based on the top 500 U.S. stocks demonstrates that our framework outperforms common portfolio benchmarks and the predict-then-optimize (PTO) approach using machine learning, particularly during periods of market stress. Traditional factor models do not fully explain this superior performance. The framework's ability to time volatility reduces its market exposure during turbulent times. Ablation studies confirm the robustness of this performance across various reinforcement learning algorithms. Additionally, the embedding and meta-learning techniques effectively manage the complexities of high-dimensional, noisy, and non-stationary financial data, enhancing both portfolio performance and risk management.", "citations": 6}
{"title": "Enhancing Portfolio Optimization with Deep Learning Insights", "year": 2026, "authors": "B. Luo, Jim Skufca", "url": "https://api.semanticscholar.org/CorpusId:284704735", "relevance": 1, "abstract": "Our work focuses on deep learning (DL) portfolio optimization, tackling challenges in long-only, multi-asset strategies across market cycles. We propose training models with limited regime data using pre-training techniques and leveraging transformer architectures for state variable inclusion. Evaluating our approach against traditional methods shows promising results, demonstrating our models'resilience in volatile markets. These findings emphasize the evolving landscape of DL-driven portfolio optimization, stressing the need for adaptive strategies to navigate dynamic market conditions and improve predictive accuracy.", "citations": 0}
{"title": "DeltaHedge: A Multi-Agent Framework for Portfolio Options Optimization", "year": 2025, "authors": "Feliks Banka, Jaros\u0142aw A. Chudziak", "url": "https://api.semanticscholar.org/CorpusId:280034573", "relevance": 1, "abstract": "In volatile financial markets, balancing risk and return remains a significant challenge. Traditional approaches often focus solely on equity allocation, overlooking the strategic advantages of options trading for dynamic risk hedging. This work presents DeltaHedge, a multi-agent framework that integrates options trading with AI-driven portfolio management. By combining advanced reinforcement learning techniques with an ensembled options-based hedging strategy, DeltaHedge enhances risk-adjusted returns and stabilizes portfolio performance across varying market conditions. Experimental results demonstrate that DeltaHedge outperforms traditional strategies and standalone models, underscoring its potential to transform practical portfolio management in complex financial environments. Building on these findings, this paper contributes to the fields of quantitative finance and AI-driven portfolio optimization by introducing a novel multi-agent system for integrating options trading strategies, addressing a gap in the existing literature.", "citations": 1}
{"title": "MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling", "year": 2025, "authors": "Fengchen Gu, Zhengyong Jiang, \u00c1ngel F. Garc\u00eda-Fern\u00e1ndez, Angelos Stefanidis, Jionglong Su, Huakang Li", "url": "https://api.semanticscholar.org/CorpusId:276813661", "relevance": 1, "abstract": "\n Portfolio management remains a crucial challenge in finance, with traditional methods often falling short in complex and volatile market environments. While deep reinforcement approaches have shown promise, they still face limitations in dynamic risk management, exploitation of temporal markets, and incorporation of complex trading strategies such as short-selling. These limitations can lead to suboptimal portfolio performance, increased vulnerability to market volatility, and missed opportunities in capturing potential returns from diverse market conditions. This paper introduces a Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling (MTS), offering a robust and adaptive strategy for sustainable investment performance. This framework utilizes a novel encoder-attention mechanism to address the limitations by incorporating temporal market characteristics, a parallel strategy for automated short-selling based on market trends, and risk management through innovative Incremental Conditional Value at Risk, enhancing adaptability and performance. Experimental validation on five diverse datasets from 2019 to 2023 demonstrates MTS\u2019s superiority over traditional algorithms and advanced machine learning techniques. MTS consistently achieves higher cumulative returns, Sharpe, Omega, and Sortino ratios, underscoring its effectiveness in balancing risk and return while adapting to market dynamics. MTS demonstrates an average relative increase of 30.67\n \n \n %\n \n \n in cumulative returns and 29.33\n \n \n %\n \n \n in Sharpe ratio compared to the next best-performing strategies across various datasets.\n", "citations": 3}
{"title": "Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow", "year": 2024, "authors": "Tian Guo, E. Hauptmann", "url": "https://www.semanticscholar.org/paper/f6c0a84ac1f1fe79cfde96f4e163d0d69f9c06cb", "relevance": 1, "abstract": "Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks.This paper explores fine-tuning LLMs for predicting stock returns with financial newsflow.Return prediction is fundamental for subsequent tasks like portfolio construction and optimization in quantitative investing. We formulate the model to include a text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways.The impact of these different representations on return forecasting remains an open question.Meanwhile, we compare two simple methods of integrating LLMs\u2019 token-level representations into the forecasting module.The experiments on real investment universes reveal that:(1) aggregated representations from LLMs\u2019 token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios;(2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners;(3) return predictions derived from LLMs\u2019 text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores.These findings shed light on developing suitable LLM fine-tuning methods for return prediction-based portfolio construction.", "citations": 13}
{"title": "LLMs for Time Series: an Application for Single Stocks and Statistical Arbitrage", "year": 2024, "authors": "S\u00e9bastien Valeyre, Sofiane Aboura", "url": "https://api.semanticscholar.org/CorpusId:274656301", "relevance": 1, "abstract": "Recently, LLMs (Large Language Models) have been adapted for time series prediction with significant success in pattern recognition. However, the common belief is that these models are not suitable for predicting financial market returns, which are known to be almost random. We aim to challenge this misconception through a counterexample. Specifically, we utilized the Chronos model from Ansari et al.(2024) and tested both pretrained configurations and fine-tuned supervised forecasts on the largest American single stocks using data from Guijarro-Ordonnez et al.(2022). We constructed a long/short portfolio, and the performance simulation indicates that LLMs can in reality handle time series that are nearly indistinguishable from noise, demonstrating an ability to identify inefficiencies amidst randomness and generate alpha. Finally, we compared these results with those of specialized models and smaller deep learning models, highlighting significant room for improvement in LLM performance to further enhance their predictive capabilities.", "citations": 2}
{"title": "Shai: A large language model for asset management", "year": 2023, "authors": "Zhongyang Guo, Guanran Jiang, Zhongdan Zhang, Peng Li, Zhefeng Wang, Yinchun Wang", "url": "https://api.semanticscholar.org/CorpusId:266521280", "relevance": 1, "abstract": "This paper introduces\"Shai\"a 10B level large language model specifically designed for the asset management industry, built upon an open-source foundational model. With continuous pre-training and fine-tuning using a targeted corpus, Shai demonstrates enhanced performance in tasks relevant to its domain, outperforming baseline models. Our research includes the development of an innovative evaluation framework, which integrates professional qualification exams, tailored tasks, open-ended question answering, and safety assessments, to comprehensively assess Shai's capabilities. Furthermore, we discuss the challenges and implications of utilizing large language models like GPT-4 for performance assessment in asset management, suggesting a combination of automated evaluation and human judgment. Shai's development, showcasing the potential and versatility of 10B-level large language models in the financial sector with significant performance and modest computational requirements, hopes to provide practical insights and methodologies to assist industry peers in their similar endeavors.", "citations": 5}
{"title": "Multiagent Reinforcement Learning: Methods, Trustworthiness, Applications in Intelligent Vehicles, and Challenges", "year": 2023, "authors": "Ziyuan Zhou, Guanjun Liu, Ying-Si Tang", "url": "https://api.semanticscholar.org/CorpusId:258741132", "relevance": 1, "abstract": "Multiagent Reinforcement Learning (MARL) plays a pivotal role in intelligent vehicle systems, offering solutions for complex decision-making, coordination, and adaptive behavior among autonomous agents. This review aims to highlight the importance of fostering trust in MARL and emphasize the significance of MARL in revolutionizing intelligent vehicle systems. First, this paper summarizes the fundamental methods of MARL. Second, it identifies the limitations of MARL in safety, robustness, generalization, and ethical constraints and outlines the corresponding research methods. Then we summarize their applications in intelligent vehicle systems. Considering human interaction is essential to practical applications of MARL in various domains, the paper also analyzes the challenges associated with MARL's applications in human-machine systems. These challenges, when overcome, could significantly enhance the real-world implementation of MARL-based intelligent vehicle systems.", "citations": 37}
{"title": "A Review on Machine Learning for Asset Management", "year": 2022, "authors": "Pedro M. Mirete-Ferrer, A. Garcia-Garcia, J. Baixauli-Soler, Maria A. Prats", "url": "https://api.semanticscholar.org/CorpusId:248198852", "relevance": 1, "abstract": "This paper provides a review on machine learning methods applied to the asset management discipline. Firstly, we describe the theoretical background of both machine learning and finance that will be needed to understand the reviewed methods. Next, the main datasets and sources of data are exposed to help researchers decide which are the best ones to suit their targets. After that, the existing methods are reviewed, highlighting their contribution and significance in the analyzed financial disciplines. Furthermore, we also describe the most common performance criteria that are applied to compare such methods quantitatively. Finally, we carry out a critical analysis to discuss the current state-of-the-art and lay down a set of future research directions.", "citations": 17}
{"title": "Benchmarking Large Language Model Volatility", "year": 2023, "authors": "Boyang Yu", "url": "https://www.semanticscholar.org/paper/2c0d8a3f0fd5f50dded522c8bbaf9b226890f6d9", "relevance": 1, "abstract": "The impact of non-deterministic outputs from Large Language Models (LLMs) is not well examined for financial text understanding tasks. Through a compelling case study on investing in the US equity market via news sentiment analysis, we uncover substantial variability in sentence-level sentiment classification results, underscoring the innate volatility of LLM outputs. These uncertainties cascade downstream, leading to more significant variations in portfolio construction and return. While tweaking the temperature parameter in the language model decoder presents a potential remedy, it comes at the expense of stifled creativity. Similarly, while ensembling multiple outputs mitigates the effect of volatile outputs, it demands a notable computational investment. This work furnishes practitioners with invaluable insights for adeptly navigating uncertainty in the integration of LLMs into financial decision-making, particularly in scenarios dictated by non-deterministic information.", "citations": 7}
{"title": "Artificial intelligence in financial market prediction: advancements in machine learning for stock price forecasting", "year": 2026, "authors": "Arafat Rohan, Md. Deluar Hossen, Md. Nuruzzaman Pranto, Balayet Hossain, Areyfin Mohammed Yoshi, Rakibul Islam", "url": "https://api.semanticscholar.org/CorpusId:284816233", "relevance": 1, "abstract": "This study reviews the advancements in AI-driven methods for predicting stock prices, tracing their evolution from traditional approaches to modern finance. The role of AI in the market extends beyond predictive systems to encompass the intersection of financial markets with emerging technologies, such as blockchain, and the potential influence of quantum computing on economic modeling. A decentralized finance system examines the application of Reinforcement Learning in financial market prediction, highlighting its potential for continuous learning from dynamic market conditions. The study discusses the development of hybrid prediction models, stock market machine learning systems, and AI-driven investment portfolio management. The potential of quantum computing enhances portfolio analysis, fraud detection, optimization, and asset valuation for complex market predictions, as well as the impact of blockchain technologies on transparency, security, and efficiency. Machine learning techniques can significantly automate data collection and purification. Financial decision-making and the application of time-series analysis techniques can be readily learned through deep reinforcement learning for stock price prediction. Deep Neural Networks and Strategic Asset Allocation can be managed by evaluating performance and portfolio using real-time market insights from AI models. Although there are numerous ethical, sentimental, regulatory, and data quality issues in market prediction, the future job market is heavily dependent on these criteria, particularly through effective risk management and fraud detection.", "citations": 0}
{"title": "A Novel approach to portfolio construction", "year": 2026, "authors": "T. D. Matteo, L. Riso, M. Zoia", "url": "https://api.semanticscholar.org/CorpusId:285275918", "relevance": 1, "abstract": "This paper proposes a machine learning-based framework for asset selection and portfolio construction, termed the Best-Path Algorithm Sparse Graphical Model (BPASGM). The method extends the Best-Path Algorithm (BPA) by mapping linear and non-linear dependencies among a large set of financial assets into a sparse graphical model satisfying a structural Markov property. Based on this representation, BPASGM performs a dependence-driven screening that removes positively or redundantly connected assets, isolating subsets that are conditionally independent or negatively correlated. This step is designed to enhance diversification and reduce estimation error in high-dimensional portfolio settings. Portfolio optimization is then conducted on the selected subset using standard mean-variance techniques. BPASGM does not aim to improve the theoretical mean-variance optimum under known population parameters, but rather to enhance realized performance in finite samples, where sample-based Markowitz portfolios are highly sensitive to estimation error. Monte Carlo simulations show that BPASGM-based portfolios achieve more stable risk-return profiles, lower realized volatility, and superior risk-adjusted performance compared to standard mean-variance portfolios. Empirical results for U.S. equities, global stock indices, and foreign exchange rates over 1990-2025 confirm these findings and demonstrate a substantial reduction in portfolio cardinality. Overall, BPASGM offers a statistically grounded and computationally efficient framework that integrates sparse graphical modeling with portfolio theory for dependence-aware asset selection.", "citations": 0}
{"title": "Agent-based Liquidity Risk Modelling for Financial Markets", "year": 2025, "authors": "Perukrishnen Vytelingum, R. Baggott, Namid R Stillman, Jianfei Zhang, Dingqiu Zhu, Tao Chen, Justin Lyon", "url": "https://api.semanticscholar.org/CorpusId:278782781", "relevance": 1, "abstract": "In this paper, we describe a novel agent-based approach for modelling the transaction cost of buying or selling an asset in financial markets, e.g., to liquidate a large position as a result of a margin call to meet financial obligations. The simple act of buying or selling in the market causes a price impact and there is a cost described as liquidity risk. For example, when selling a large order, there is market slippage -- each successive trade will execute at the same or worse price. When the market adjusts to the new information revealed by the execution of such a large order, we observe in the data a permanent price impact that can be attributed to the change in the fundamental value as market participants reassess the value of the asset. In our ABM model, we introduce a novel mechanism where traders assume orderflow is informed and each trade reveals some information about the value of the asset, and traders update their belief of the fundamental value for every trade. The result is emergent, realistic price impact without oversimplifying the problem as most stylised models do, but within a realistic framework that models the exchange with its protocols, its limit orderbook and its auction mechanism and that can calculate the transaction cost of any execution strategy without limitation. Our stochastic ABM model calculates the costs and uncertainties of buying and selling in a market by running Monte-Carlo simulations, for a better understanding of liquidity risk and can be used to optimise for optimal execution under liquidity risk. We demonstrate its practical application in the real world by calculating the liquidity risk for the Hang-Seng Futures Index.", "citations": 2}
{"title": "Deep Learning Enhanced Multivariate GARCH", "year": 2025, "authors": "Haoyuan Wang, Chen Liu, Minh-Ngoc Tran, Chaofan Wang", "url": "https://api.semanticscholar.org/CorpusId:279118521", "relevance": 1, "abstract": "This paper introduces a novel multivariate volatility modeling framework, named Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep learning into multivariate GARCH processes. By combining the flexibility of recurrent neural networks with the econometric structure of BEKK models, our approach is designed to better capture nonlinear, dynamic, and high-dimensional dependence structures in financial return data. The proposed model addresses key limitations of traditional multivariate GARCH-based methods, particularly in capturing persistent volatility clustering and asymmetric co-movement across assets. Leveraging the data-driven nature of LSTMs, the framework adapts effectively to time-varying market conditions, offering improved robustness and forecasting performance. Empirical results across multiple equity markets confirm that the LSTM-BEKK model achieves superior performance in terms of out-of-sample portfolio risk forecast, while maintaining the interpretability from the BEKK models. These findings highlight the potential of hybrid econometric-deep learning models in advancing financial risk management and multivariate volatility forecasting.", "citations": 1}
{"title": "Dynamic Hedging Strategies in Derivatives Markets with LLM-Driven Sentiment and News Analytics", "year": 2025, "authors": "Jie Yang, Yiqiu Tang, Yongjie Li, Lihua Zhang, Haoran Zhang", "url": "https://api.semanticscholar.org/CorpusId:277620976", "relevance": 1, "abstract": "Dynamic hedging strategies are essential for effective risk management in derivatives markets, where volatility and market sentiment can greatly impact performance. This paper introduces a novel framework that leverages large language models (LLMs) for sentiment analysis and news analytics to inform hedging decisions. By analyzing textual data from diverse sources like news articles, social media, and financial reports, our approach captures critical sentiment indicators that reflect current market conditions. The framework allows for real-time adjustments to hedging strategies, adapting positions based on continuous sentiment signals. Backtesting results on historical derivatives data reveal that our dynamic hedging strategies achieve superior risk-adjusted returns compared to conventional static approaches. The incorporation of LLM-driven sentiment analysis into hedging practices presents a significant advancement in decision-making processes within derivatives trading. This research showcases how sentiment-informed dynamic hedging can enhance portfolio management and effectively mitigate associated risks.", "citations": 0}
{"title": "MARS: A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Management", "year": 2025, "authors": "Jiayi Chen, Jing Li, G. Wang", "url": "https://api.semanticscholar.org/CorpusId:280422435", "relevance": 1, "abstract": "Reinforcement Learning (RL) has shown significant promise in automated portfolio management; however, effectively balancing risk and return remains a central challenge, as many models fail to adapt to dynamically changing market conditions. We propose Meta-controlled Agents for a Risk-aware System (MARS), a novel framework addressing this through a multi-agent, risk-aware approach. MARS replaces monolithic models with a Heterogeneous Agent Ensemble, where each agent's unique risk profile is enforced by a Safety-Critic network to span behaviors from capital preservation to aggressive growth. A high-level Meta-Adaptive Controller (MAC) dynamically orchestrates this ensemble, shifting reliance between conservative and aggressive agents to minimize drawdown during downturns while seizing opportunities in bull markets. This two-tiered structure leverages behavioral diversity rather than explicit feature engineering to ensure a disciplined portfolio robust across market regimes. Experiments on major international indexes confirm that our framework significantly reduces maximum drawdown and volatility while maintaining competitive returns.", "citations": 0}
{"title": "From Headlines to Holdings: Deep Learning for Smarter Portfolio Decisions", "year": 2025, "authors": "Yun Lin, Jiawei Lou, Jinghe Zhang", "url": "https://api.semanticscholar.org/CorpusId:281674709", "relevance": 1, "abstract": "Deep learning offers new tools for portfolio optimization. We present an end-to-end framework that directly learns portfolio weights by combining Long Short-Term Memory (LSTM) networks to model temporal patterns, Graph Attention Networks (GAT) to capture evolving inter-stock relationships, and sentiment analysis of financial news to reflect market psychology. Unlike prior approaches, our model unifies these elements in a single pipeline that produces daily allocations. It avoids the traditional two-step process of forecasting asset returns and then applying mean--variance optimization (MVO), a sequence that can introduce instability. We evaluate the framework on nine U.S. stocks spanning six sectors, chosen to balance sector diversity and news coverage. In this setting, the model delivers higher cumulative returns and Sharpe ratios than equal-weighted and CAPM-based MVO benchmarks. Although the stock universe is limited, the results underscore the value of integrating price, relational, and sentiment signals for portfolio management and suggest promising directions for scaling the approach to larger, more diverse asset sets.", "citations": 0}
{"title": "Comprehensive Review on Natural Language Generation for Automated Report Writing in Finance", "year": 2024, "authors": "Abbas Sani, Bachcha Lal Pal, A. Dhabariya, Faisal Rasheed, Asifa Shah, Usman Haruna, Babangida Salis Mu'az, Abdulgaffar Abubakar Yahya", "url": "https://api.semanticscholar.org/CorpusId:271894074", "relevance": 1, "abstract": "The financial industry is transforming with the advent of Natural Language Generation (NLG), a subset of Natural Language Processing (NLP), which automates data conversion into coherent and contextually relevant narratives. This paper presents a comprehensive review of NLG's application in financial report automation, tracing its evolution from template-based methods to advanced deep learning and knowledge graph techniques. We discuss the relevance of NLG in automating report generation, its role in enhancing data analysis and decision-making, and its potential to improve investor communications and compliance with regulations. The paper identifies research gaps, including the need for optimization, accuracy improvement, and the integration of machine learning models for better classification and prediction. A proposed methodology for structured report generation is outlined, leveraging deep learning architectures such as RNNs and LSTMs. Future work aims to address these gaps and further integrate NLG into financial reporting, promising to streamline processes, reduce costs, and provide more personalized and insightful financial narratives.", "citations": 2}
{"title": "Integrated Financial Analysis and Asset Recommendation", "year": 2024, "authors": "Prathmesh Sharma, Keval Savla, Akhil Sharma, Jignesh Sisodia, K. Devadkar", "url": "https://api.semanticscholar.org/CorpusId:269507506", "relevance": 1, "abstract": "In the ever-evolving financial landscape, data science, and machine learning have become instrumental in shaping investment strategies. This study introduces the \"Integrated Financial Analysis and Asset Recommendation\" (IFAAR) platform, a revolutionary tool designed to optimize investment decisions. This system will employ advanced techniques in stock recommendation, utilizing technical indicators and the Prophet library for precise time-series forecasting. Covering stocks, cryptocurrencies, mutual funds, and physical assets, the platform offers a diverse array of investment options. A key innovation lies in the integration of feature normalization methodologies, proportionate allocation, and elevating prediction accuracy. This multidisciplinary platform combines finance, data science, and machine learning to dynamically allocate assets, adapting to changing economic landscapes and optimizing the risk-return balance. \n\nThis system will empower users with tailored investment recommendations through a user-friendly interface. Predictions are grounded in a meticulous analysis of historical data patterns, sentiment analysis from news sources, the psychological behavior of investors, and the use of technical indicators like MACD, RSI, ARIMA, and LSTM.\n Contributing significantly to the financial industry, this research introduces a practical and valuable tool for investors of any expertise to navigate market complexities. IFAAR would quantitatively gauge the security stance of integrated packages, enhancing software security and mitigating potential risks", "citations": 1}
{"title": "Iterative Deep Learning Approach to Active Portfolio Management with Sentiment Factors", "year": 2024, "authors": "Javier Orlando Pantoja Robayo, Juli\u00e1n Alberto Alem\u00e1n Mu\u00f1oz, Diego F. Tellez-Falla", "url": "https://api.semanticscholar.org/CorpusId:272620129", "relevance": 1, "abstract": "We suggest using deep learning networks to create expert opinions as part of an iterative active portfolio management process. These opinions would be based on posts from the X platform and the fundamentals of stocks listed in the S&P 500 index. Expert views are integral to active portfolio management, as proposed by Black\u2013Litterman. The method we propose addresses the original subjectivity of the opinions by incorporating innovation and accuracy to generate views using analytical techniques. We utilize daily data from 2010 to 2022 for stocks from the S&P 500 and daily posts from Twitter API v2, collected under a research account license spanning the same period. We found that incorporating sentiment factors with machine learning techniques into the view generation process of the Black\u2013Litterman model improves optimal portfolio allocation. Empirically, our results notably outperform the S&P 500 market when considering the annualized alpha.", "citations": 1}
{"title": "Enhancing portfolio management using artificial intelligence: literature review", "year": 2024, "authors": "K. \u0160utien\u0117, Peter Schwendner, Ciprian Sipos, Luis Lorenzo, Miroslav Mirchev, Petre Lameski, Audrius Kaba\u0161inskas, Chemseddine Tidjani, Belma Ozturkkal, Jurgita \u010cernevi\u010dien\u0117", "url": "https://api.semanticscholar.org/CorpusId:269020037", "relevance": 1, "abstract": "Building an investment portfolio is a problem that numerous researchers have addressed for many years. The key goal has always been to balance risk and reward by optimally allocating assets such as stocks, bonds, and cash. In general, the portfolio management process is based on three steps: planning, execution, and feedback, each of which has its objectives and methods to be employed. Starting from Markowitz's mean-variance portfolio theory, different frameworks have been widely accepted, which considerably renewed how asset allocation is being solved. Recent advances in artificial intelligence provide methodological and technological capabilities to solve highly complex problems, and investment portfolio is no exception. For this reason, the paper reviews the current state-of-the-art approaches by answering the core question of how artificial intelligence is transforming portfolio management steps. Moreover, as the use of artificial intelligence in finance is challenged by transparency, fairness and explainability requirements, the case study of post-hoc explanations for asset allocation is demonstrated. Finally, we discuss recent regulatory developments in the European investment business and highlight specific aspects of this business where explainable artificial intelligence could advance transparency of the investment process.", "citations": 27}
{"title": "Portfolio Transformer for Attention-Based Asset Allocation", "year": 2022, "authors": "Damian Kisiel, D. Gorse", "url": "https://api.semanticscholar.org/CorpusId:249431558", "relevance": 1, "abstract": "Traditional approaches to financial asset allocation start with returns forecasting followed by an optimization stage that decides the optimal asset weights. Any errors made during the forecasting step reduce the accuracy of the asset weightings, and hence the profitability of the overall portfolio. The Portfolio Transformer (PT) network, introduced here, circumvents the need to predict asset returns and instead directly optimizes the Sharpe ratio, a risk-adjusted performance metric widely used in practice. The PT is a novel end-to-end portfolio optimization framework, inspired by the numerous successes of attention mechanisms in natural language processing. With its full encoder-decoder architecture, specialized time encoding layers, and gating components, the PT has a high capacity to learn long-term dependencies among portfolio assets and hence can adapt more quickly to changing market conditions such as the COVID-19 pandemic. To demonstrate its robustness, the PT is compared against other algorithms, including the current LSTM-based state of the art, on three different datasets, with results showing that it offers the best risk-adjusted performance.", "citations": 9}
{"title": "Fusion of Sentiment and Asset Price Predictions for Portfolio Optimization", "year": 2022, "authors": "Mufhumudzi Muthivhi, Terence L van Zyl", "url": "https://api.semanticscholar.org/CorpusId:247411162", "relevance": 1, "abstract": "The fusion of public sentiment data in the form of text with stock price prediction is a topic of increasing interest within the financial community. However, the research literature seldom explores the application of investor sentiment in the Portfolio Selection problem. This paper aims to unpack and develop an enhanced understanding of the sentiment-aware portfolio selection problem. To this end, the study uses a Semantic Attention model to predict sentiment towards an asset. We select the optimal portfolio through a sentiment-aware Long Short Term Memory (LSTM) recurrent neural network for price prediction and a mean-variance strategy. Our sentiment portfolio strategies achieved, on average, a significant increase in revenue above the non-sentiment aware models. However, the results show that our strategy does not outperform traditional portfolio allocation strategies from a stability perspective. We argue that an improved fusion of sentiment prediction with a combination of price prediction and portfolio optimization leads to an enhanced portfolio selection strategy.", "citations": 7}
{"title": "Transformers in Reinforcement Learning: A Survey", "year": 2023, "authors": "Pranav Agarwal, A. Rahman, P. St-Charles, Simon J. D. Prince, Samira Ebrahimi Kahou", "url": "https://api.semanticscholar.org/CorpusId:259837280", "relevance": 1, "abstract": "Transformers have significantly impacted domains like natural language processing, computer vision, and robotics, where they improve performance compared to other neural networks. This survey explores how transformers are used in reinforcement learning (RL), where they are seen as a promising solution for addressing challenges such as unstable training, credit assignment, lack of interpretability, and partial observability. We begin by providing a brief domain overview of RL, followed by a discussion on the challenges of classical RL algorithms. Next, we delve into the properties of the transformer and its variants and discuss the characteristics that make them well-suited to address the challenges inherent in RL. We examine the application of transformers to various aspects of RL, including representation learning, transition and reward function modeling, and policy optimization. We also discuss recent research that aims to enhance the interpretability and efficiency of transformers in RL, using visualization techniques and efficient training strategies. Often, the transformer architecture must be tailored to the specific needs of a given application. We present a broad overview of how transformers have been adapted for several applications, including robotics, medicine, language modeling, cloud computing, and combinatorial optimization. We conclude by discussing the limitations of using transformers in RL and assess their potential for catalyzing future breakthroughs in this field.", "citations": 26}
{"title": "Model-Free Reinforcement Learning for Asset Allocation", "year": 2022, "authors": "Adebayo Oshingbesan, Eniola Ajiboye, Peruth Kamashazi, Timothy Mbaka", "url": "https://api.semanticscholar.org/CorpusId:252407548", "relevance": 1, "abstract": "Asset allocation (or portfolio management) is the task of determining how to optimally allocate funds of a finite budget into a range of financial instruments/assets such as stocks. This study investigated the performance of reinforcement learning (RL) when applied to portfolio management using model-free deep RL agents. We trained several RL agents on real-world stock prices to learn how to perform asset allocation. We compared the performance of these RL agents against some baseline agents. We also compared the RL agents among themselves to understand which classes of agents performed better. From our analysis, RL agents can perform the task of portfolio management since they significantly outperformed two of the baseline agents (random allocation and uniform allocation). Four RL agents (A2C, SAC, PPO, and TRPO) outperformed the best baseline, MPT, overall. This shows the abilities of RL agents to uncover more profitable trading strategies. Furthermore, there were no significant performance differences between value-based and policy-based RL agents. Actor-critic agents performed better than other types of agents. Also, on-policy agents performed better than off-policy agents because they are better at policy evaluation and sample efficiency is not a significant problem in portfolio management. This study shows that RL agents can substantially improve asset allocation since they outperform strong baselines. On-policy, actor-critic RL agents showed the most promise based on our analysis.", "citations": 2}
{"title": "Reinforcement Learning Portfolio Manager Framework with Monte Carlo Simulation", "year": 2022, "authors": "Jungyu Ahn, S. Park, Jiwoo Kim, Ju-hong Lee", "url": "https://api.semanticscholar.org/CorpusId:250311510", "relevance": 1, "abstract": "Asset allocation using reinforcement learning has advantages such as flexibility in goal setting and utilization of various information. However, existing asset allocation methods do not consider the following viewpoints in solving the asset allocation problem. First, State design without considering portfolio management and financial market characteristics. Second, Model Overfitting. Third, Model training design without considering the statistical structure of financial time series data. To solve the problem of the existing asset allocation method using reinforcement learning, we propose a new reinforcement learning asset allocation method. First, the state of the portfolio managed by the model is considered as the state of the reinforcement learning agent. Second, Monte Carlo simulation data are used to increase training data complexity to prevent model overfitting. These data can have different patterns, which can increase the complexity of the data. Third, Monte Carlo simulation data are created considering various statistical structures of financial markets. We define the statistical structure of the financial market as the correlation matrix of the assets constituting the financial market. We show experimentally that our method outperforms the benchmark at several test intervals.", "citations": 1}
{"title": "Improving Generalization in Reinforcement Learning\u2013Based Trading by Using a Generative Adversarial Market Model", "year": 2021, "authors": "Chia-Hsuan Kuo, Chiao-Ting Chen, Sin-Jing Lin, Szu-Hao Huang", "url": "https://api.semanticscholar.org/CorpusId:233197159", "relevance": 1, "abstract": "With the increasing sophistication of artificial intelligence, reinforcement learning (RL) has been widely applied to portfolio management. However, shortcomings remain. Specifically, because the training environment of an RL-based portfolio optimization framework is usually constructed based on historical price data in the literature, the agent potentially 1) violates the definition of a Markov decision process (MDP), 2) ignores their own market impact, or 3) fails to account for causal relationships within interaction processes; these ultimately lead the agent to make poor generalizations. To surmount these problems\u2014specifically, to help the RL-based portfolio agent make better generalizations\u2014we introduce an interactive training environment that leverages a generative model, called the limit order book-generative adversarial model (LOB-GAN), to simulate a financial market. Specifically, the LOB-GAN models market ordering behavior, and LOB-GAN\u2019s generator is utilized as a market behavior simulator. A simulated financial market, called Virtual Market, is constructed by the market behavior simulator in conjunction with a realistic security matching system. Virtual Market is then leveraged as an interactive training environment for the RL-based portfolio agent. The experimental results demonstrate that our framework improves out-of-sample portfolio performance by 4%, which is superior to other generalization strategies.", "citations": 35}
{"title": "A Financial Brain Scan of the LLM", "year": 2025, "authors": "Hui Chen, Antoine Didisheim, Luciano Somoza, Hanqing Tian", "url": "https://api.semanticscholar.org/CorpusId:280984845", "relevance": 1, "abstract": "Emerging techniques in computer science make it possible to\"brain scan\"large language models (LLMs), identify the plain-English concepts that guide their reasoning, and steer them while holding other factors constant. We show that this approach can map LLM-generated economic forecasts to concepts such as sentiment, technical analysis, and timing, and compute their relative importance without reducing performance. We also show that models can be steered to be more or less risk-averse, optimistic, or pessimistic, which allows researchers to correct or simulate biases. The method is transparent, lightweight, and replicable for empirical research in the social sciences.", "citations": 0}
{"title": "QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models", "year": 2026, "authors": "Zhaolu Kang, Junhao Gong, Wenqing Hu, Shuo Yin, Kehan Jiang, Zhicheng Fang, Yingjie He, Chunlei Meng, Rong Fu, Dongyang Chen, Leqi Zheng, Eric Hanchen Jiang, Yunfei Feng, Yitong Leng, Junfan Zhu, Xiaoyou Chen, Xi Yang, Richeng Xuan", "url": "https://api.semanticscholar.org/CorpusId:284705005", "relevance": 1, "abstract": "Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs'quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.", "citations": 0}
{"title": "From market games to real-world markets", "year": 2000, "authors": "P. Jefferies, M. Hart, P. Hui, N. Johnson", "url": "https://api.semanticscholar.org/CorpusId:111385884", "relevance": 1, "abstract": "Abstract:This paper uses the development of multi-agent market models to present a unified approach to the joint questions of how financial market movements may be simulated, predicted, and hedged against. We first present the results of agent-based market simulations in which traders equipped with simple buy/sell strategies and limited information compete in speculatory trading. We examine the effect of different market clearing mechanisms and show that implementation of a simple Walrasian auction leads to unstable market dynamics. We then show that a more realistic out-of-equilibrium clearing process leads to dynamics that closely resemble real financial movements, with fat-tailed price increments, clustered volatility and high volume autocorrelation. We then show that replacing the `synthetic' price history used by these simulations with data taken from real financial time-series leads to the remarkable result that the agents can collectively learn to identify moments in the market where profit is attainable. Hence on real financial data, the system as a whole can perform better than random. We then employ the formalism of Bouchaud in conjunction with agent based models to show that in general risk cannot be eliminated from trading with these models. We also show that, in the presence of transaction costs, the risk of option writing is greatly increased. This risk, and the costs, can however be reduced through the use of a delta-hedging strategy with modified, time-dependent volatility structure.", "citations": 131}
{"title": "Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction", "year": 2023, "authors": "Yujie Ding, Shuai Jia, Tianyi Ma, Bingcheng Mao, Xiuze Zhou, Liuliu Li, Dongming Han", "url": "https://www.semanticscholar.org/paper/0fc94e0c7fea54407e9cf4e4fcbc5487be883b61", "relevance": 1, "abstract": "The remarkable achievements and rapid advancements of Large Language Models (LLMs) such as ChatGPT and GPT-4 have showcased their immense potential in quantitative investment. Traders can effectively leverage these LLMs to analyze financial news and predict stock returns accurately. However, integrating LLMs into existing quantitative models presents two primary challenges: the insufficient utilization of semantic information embedded within LLMs and the difficulties in aligning the latent information within LLMs with pre-existing quantitative stock features. We propose a novel framework consisting of two components to surmount these challenges. The first component, the Local-Global (LG) model, introduces three distinct strategies for modeling global information. These approaches are grounded respectively on stock features, the capabilities of LLMs, and a hybrid method combining the two paradigms. The second component, Self-Correlated Reinforcement Learning (SCRL), focuses on aligning the embeddings of financial news generated by LLMs with stock features within the same semantic space. By implementing our framework, we have demonstrated superior performance in Rank Information Coefficient and returns, particularly compared to models relying only on stock features in the China A-share market.", "citations": 17}
{"title": "Distributionally robust end-to-end portfolio construction", "year": 2022, "authors": "Giorgio Costa, G. Iyengar", "url": "https://api.semanticscholar.org/CorpusId:249605372", "relevance": 1, "abstract": "We propose an end-to-end distributionally robust system for portfolio construction that integrates the asset return prediction model with a distributionally robust portfolio optimization model. We also show how to learn the risk-tolerance parameter and the degree of robustness directly from data. End-to-end systems have an advantage in that information can be communicated between the prediction and decision layers during training, allowing the parameters to be trained for the final task rather than solely for predictive performance. However, existing end-to-end systems are not able to quantify and correct for the impact of model risk on the decision layer. Our proposed distributionally robust end-to-end portfolio selection system explicitly accounts for the impact of model risk. The decision layer chooses portfolios by solving a minimax problem where the distribution of the asset returns is assumed to belong to an ambiguity set centered around a nominal distribution. Using convex duality, we recast the minimax problem in a form that allows for efficient training of the end-to-end system.", "citations": 21}
{"title": "FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance", "year": 2020, "authors": "Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang, Bowen Xiao, Chris Wang", "url": "https://www.semanticscholar.org/paper/1fc643611860d9cb46df0251c35c2c55a941f3f2", "relevance": 1, "abstract": "As deep reinforcement learning (DRL) has been recognized as an effective approach in quantitative finance, getting hands-on experiences is attractive to beginners. However, to train a practical DRL trading agent that decides where to trade, at what price, and what quantity involves error-prone and arduous development and debugging. In this paper, we introduce a DRL library FinRL that facilitates beginners to expose themselves to quantitative finance and to develop their own stock trading strategies. Along with easily-reproducible tutorials, FinRL library allows users to streamline their own developments and to compare with existing schemes easily. Within FinRL, virtual environments are configured with stock market datasets, trading agents are trained with neural networks, and extensive backtesting is analyzed via trading performance. Moreover, it incorporates important trading constraints such as transaction cost, market liquidity and the investor's degree of risk-aversion. FinRL is featured with completeness, hands-on tutorial and reproducibility that favors beginners: (i) at multiple levels of time granularity, FinRL simulates trading environments across various stock markets, including NASDAQ-100, DJIA, SP (ii) organized in a layered architecture with modular structure, FinRL provides fine-tuned state-of-the-art DRL algorithms (DQN, DDPG, PPO, SAC, A2C, TD3, etc.), commonly-used reward functions and standard evaluation baselines to alleviate the debugging workloads and promote the reproducibility, and (iii) being highly extendable, FinRL reserves a complete set of user-import interfaces. Furthermore, we incorporated three application demonstrations, namely single stock trading, multiple stock trading, and portfolio allocation. The FinRL library will be available on Github at link this https URL.", "citations": 162}
{"title": "LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard", "year": 2025, "authors": "Varun Rao, Youran Sun, Mahendra Kumar, Tejas Mutneja, Agastya Mukherjee, Haizhao Yang", "url": "https://www.semanticscholar.org/paper/bc094b119fba308034931644532ad39c222715b8", "relevance": 1, "abstract": "This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLM Leaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.", "citations": 1}
{"title": "Robo-advisors and the financialization of lay investors", "year": 2020, "authors": "G. Tan", "url": "https://api.semanticscholar.org/CorpusId:221840317", "relevance": 1, "abstract": "\n The burgeoning financial technology scene in Singapore has seen the emergence of robo-advisors, which aim to disrupt traditional financial advisories by using algorithms to automate client advising and investment recommendations. Using an ecologies concept to explore how lay investors are articulated into global financial networks through robo advisors, this paper contributes to studies on the \u201cfinancialization of everyday life\u201d. It argues that investors are rendered passive by the disciplinary tools of algorithms, contemporary finance theories and elements of robo-advisor platforms that feed into these sociotechnological assemblages. The state's role in embedding citizen investors in these human-machine relationships is considered. The fragmented landscape of free, nonprofessional online financial advice and the opaque qualities of investing algorithms make investor subject formation incomplete and uncertain, especially when markets are highly volatile. This paper explores how both financial inclusion and exclusion operate simultaneously in robo-advisors and argues that robo-advisors may weaken efforts to promote financial literacy and education.\n", "citations": 38}
{"title": "Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization", "year": 2024, "authors": "Philip Ndikum, Serge Ndikum", "url": "https://api.semanticscholar.org/CorpusId:268378926", "relevance": 1, "abstract": "This research paper delves into the application of Deep Reinforcement Learning (DRL) in asset-class agnostic portfolio optimization, integrating industry-grade methodologies with quantitative finance. At the heart of this integration is our robust framework that not only merges advanced DRL algorithms with modern computational techniques but also emphasizes stringent statistical analysis, software engineering and regulatory compliance. To the best of our knowledge, this is the first study integrating financial Reinforcement Learning with sim-to-real methodologies from robotics and mathematical physics, thus enriching our frameworks and arguments with this unique perspective. Our research culminates with the introduction of AlphaOptimizerNet, a proprietary Reinforcement Learning agent (and corresponding library). Developed from a synthesis of state-of-the-art (SOTA) literature and our unique interdisciplinary methodology, AlphaOptimizerNet demonstrates encouraging risk-return optimization across various asset classes with realistic constraints. These preliminary results underscore the practical efficacy of our frameworks. As the finance sector increasingly gravitates towards advanced algorithmic solutions, our study bridges theoretical advancements with real-world applicability, offering a template for ensuring safety and robust standards in this technologically driven future.", "citations": 11}
{"title": "Deep Reinforcement Learning Model for Stock Portfolio Management Based on Data Fusion", "year": 2024, "authors": "Haifeng Li, Mo Hai", "url": "https://api.semanticscholar.org/CorpusId:268516922", "relevance": 1, "abstract": "Deep reinforcement learning (DRL) can be used to extract deep features that can be incorporated into reinforcement learning systems to enable improved decision-making; DRL can therefore also be used for managing stock portfolios. Traditional methods cannot fully exploit the advantages of DRL because they are generally based on real-time stock quotes, which do not have sufficient features for making comprehensive decisions. In this study, in addition to stock quotes, we introduced stock financial indices as additional stock features. Moreover, we used Markowitz mean-variance theory for determining stock correlation. A three-agent deep reinforcement learning model called Collaborative Multi-agent reinforcement learning-based stock Portfolio management System (CMPS) was designed and trained based on fused data. In CMPS, each agent was implemented with a deep Q-network to obtain the features of time-series stock data, and a self-attention network was used to combine the output of each agent. We added a risk-free asset strategy to CMPS to prevent risks and referred to this model as CMPS-Risk Free (CMPS-RF). We conducted experiments under different market conditions using the stock data of China Shanghai Stock Exchange 50 and compared our model with the state-of-the-art models. The results showed that CMPS could obtain better profits than the compared benchmark models, and CMPS-RF was able to accurately recognize the market risk and achieved the best Sharpe and Calmar ratios. The study findings are expected to aid in the development of an efficient investment-trading strategy.", "citations": 10}
{"title": "Adaptive Alpha Weighting with PPO: Enhancing Prompt-Based LLM-Generated Alphas in Quant Trading", "year": 2025, "authors": "Qizhao Chen, Hiroaki Kawashima", "url": "https://api.semanticscholar.org/CorpusId:281080601", "relevance": 1, "abstract": "This paper proposes a reinforcement learning framework that employs Proximal Policy Optimization (PPO) to dynamically optimize the weights of multiple large language model (LLM)-generated formulaic alphas for stock trading strategies. Formulaic alphas are mathematically defined trading signals derived from price, volume, sentiment, and other data. Although recent studies have shown that LLMs can generate diverse and effective alphas, a critical challenge lies in how to adaptively integrate them under varying market conditions. To address this gap, we leverage the deepseek-r1-distill-llama-70b model to generate fifty alphas for five major stocks: Apple, HSBC, Pepsi, Toyota, and Tencent, and then use PPO to adjust their weights in real time. Experimental results demonstrate that the PPO-optimized strategy achieves strong returns and high Sharpe ratios across most stocks, outperforming both an equal-weighted alpha portfolio and traditional benchmarks such as the Nikkei 225, S&P 500, and Hang Seng Index. The findings highlight the importance of reinforcement learning in the allocation of alpha weights and show the potential of combining LLM-generated signals with adaptive optimization for robust financial forecasting and trading.", "citations": 2}
{"title": "Kronos: A Foundation Model for the Language of Financial Markets", "year": 2025, "authors": "Yu Shi, Zongliang Fu, Shuo Chen, Bohan Zhao, Wei Xu, Changshui Zhang, Jian Li", "url": "https://api.semanticscholar.org/CorpusId:280527154", "relevance": 1, "abstract": "The success of large-scale pre-training paradigm, exemplified by Large Language Models (LLMs), has inspired the development of Time Series Foundation Models (TSFMs). However, their application to financial candlestick (K-line) data remains limited, often underperforming non-pre-trained architectures. Moreover, existing TSFMs often overlook crucial downstream tasks such as volatility prediction and synthetic data generation. To address these limitations, we propose Kronos, a unified, scalable pre-training framework tailored to financial K-line modeling. Kronos introduces a specialized tokenizer that discretizes continuous market information into token sequences, preserving both price dynamics and trade activity patterns. We pre-train Kronos using an autoregressive objective on a massive, multi-market corpus of over 12 billion K-line records from 45 global exchanges, enabling it to learn nuanced temporal and cross-asset representations. Kronos excels in a zero-shot setting across a diverse set of financial tasks. On benchmark datasets, Kronos boosts price series forecasting RankIC by 93% over the leading TSFM and 87% over the best non-pre-trained baseline. It also achieves a 9% lower MAE in volatility forecasting and a 22% improvement in generative fidelity for synthetic K-line sequences. These results establish Kronos as a robust, versatile foundation model for end-to-end financial time series analysis. Our pre-trained model is publicly available at https://github.com/shiyu-coder/Kronos.", "citations": 7}
{"title": "RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models", "year": 2025, "authors": "Xueyuan Lin, Cehao Yang, Ye Ma, Ming Li, Rongjunchen Zhang, Yang Ni, Xiaojun Wu, Chengjin Xu, Jian Guo, Hui Xiong", "url": "https://api.semanticscholar.org/CorpusId:282384513", "relevance": 1, "abstract": "Recently, large language models (LLMs) have demonstrated outstanding reasoning capabilities on mathematical and coding tasks. However, their application to financial tasks-especially the most fundamental task of stock movement prediction-remains underexplored. We study a three-class classification problem (up, hold, down) and, by analyzing existing reasoning responses, observe that: (1) LLMs follow analysts'opinions rather than exhibit a systematic, independent analytical logic (CoTs). (2) LLMs list summaries from different sources without weighing adversarial evidence, yet such counterevidence is crucial for reliable prediction. It shows that the model does not make good use of its reasoning ability to complete the task. To address this, we propose Reflective Evidence Tuning (RETuning), a cold-start method prior to reinforcement learning, to enhance prediction ability. While generating CoT, RETuning encourages dynamically constructing an analytical framework from diverse information sources, organizing and scoring evidence for price up or down based on that framework-rather than on contextual viewpoints-and finally reflecting to derive the prediction. This approach maximally aligns the model with its learned analytical framework, ensuring independent logical reasoning and reducing undue influence from context. We also build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks, with long contexts (32K tokens) and over 200K samples. In addition to price and news, it incorporates analysts'opinions, quantitative reports, fundamental data, macroeconomic indicators, and similar stocks. Experiments show that RETuning successfully unlocks the model's reasoning ability in the financial domain. Inference-time scaling still works even after 6 months or on out-of-distribution stocks, since the models gain valuable insights about stock movement prediction.", "citations": 0}
{"title": "Interpretable multimodal reasoning for robo-advisory: the FinErva framework", "year": 2026, "authors": "Jiarui Chi", "url": "https://api.semanticscholar.org/CorpusId:285019586", "relevance": 1, "abstract": "The rapid development of robo-advisory and quantitative investment has been accompanied by persistent concerns about limited personalization and the opacity of black-box models operating on multimodal financial information. This paper addresses these issues from a decision-support perspective by constructing FinErva, a multimodal chain-of-thought dataset tailored to financial applications. FinErva comprises 7,544 manually verified question\u2013answer pairs, divided into two economically relevant tasks: contract and disclosure understanding (FinErva-Pact) and candlestick-chart-based technical analysis (FinErva-Price). Building on this dataset, the paper propose a two-stage training framework: Supervised-CoT Learning followed by Self-CoT Refinement, and apply it to eight vision\u2013language models, each with fewer than 0.8 billion parameters. Empirical results show that those lightweight models approach the performance of finance professionals and clearly outperform non-expert investors. Overall, the findings indicate that appropriately designed multimodal chain of thought supervision enables interpretable modeling of key research tasks such as contract review and chart interpretation under realistic computational and deployment constraints, providing new data and methodology for the development of personalized, explainable, and operationally feasible AI systems in investment advisory and risk management.", "citations": 0}
{"title": "ChatGPT in Systematic Investing - Enhancing Risk-Adjusted Returns with LLMs", "year": 2025, "authors": "Nikolas Anic, Andrea Barbon, Ralf Seiz, Carlo Zarattini", "url": "https://api.semanticscholar.org/CorpusId:282591893", "relevance": 1, "abstract": "This paper investigates whether large language models (LLMs) can improve cross-sectional momentum strategies by extracting predictive signals from firm-specific news. We combine daily U.S. equity returns for S&P 500 constituents with high-frequency news data and use prompt-engineered queries to ChatGPT that inform the model when a stock is about to enter a momentum portfolio. The LLM evaluates whether recent news supports a continuation of past returns, producing scores that condition both stock selection and portfolio weights. An LLM-enhanced momentum strategy outperforms a standard long-only momentum benchmark, delivering higher Sharpe and Sortino ratios both in-sample and in a truly out-of-sample period after the model's pre-training cut-off. These gains are robust to transaction costs, prompt design, and portfolio constraints, and are strongest for concentrated, high-conviction portfolios. The results suggest that LLMs can serve as effective real-time interpreters of financial news, adding incremental value to established factor-based investment strategies.", "citations": 0}
{"title": "Enhancing Few-Shot Stock Trend Prediction with Large Language Models", "year": 2024, "authors": "Yiqi Deng, Xingwei He, Jiahao Hu, Siu-Ming Yiu", "url": "https://www.semanticscholar.org/paper/69ec9e81b1d4ced8ceb0214bdf33e38627aa5f5c", "relevance": 1, "abstract": "The goal of stock trend prediction is to forecast future market movements for informed investment decisions. Existing methods mostly focus on predicting stock trends with supervised models trained on extensive annotated data. However, human annotation can be resource-intensive and the annotated data are not readily available. Inspired by the impressive few-shot capability of Large Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome the scarcity of labeled data and make prediction more feasible to investors. Previous works typically merge multiple financial news for predicting stock trends, causing two significant problems when using LLMs: (1) Merged news contains noise, and (2) it may exceed LLMs' input limits, leading to performance degradation. To overcome these issues, we propose a two-step method 'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category, and predict stock trends for individual news instead of merged news. Then we aggregate these predictions using majority voting. The proposed method offers two advantages: (1) Classifying noisy news as irrelevant removes its impact on the final prediction. (2) Predicting for individual news mitigates LLMs' input length limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in CSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot counterparts by around 7%, 4%, and 4%. Furthermore, our proposed method performs on par with state-of-the-art supervised methods.", "citations": 5}
{"title": "DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection", "year": 2024, "authors": "Donghee Choi, Jinkyu Kim, Mogan Gim, Jinho Lee, Jaewoo Kang", "url": "https://api.semanticscholar.org/CorpusId:271270348", "relevance": 1, "abstract": "Utilizing market forecasts is pivotal in optimizing portfolio selection strategies. We introduce DeepClair, a novel framework for portfolio selection. DeepClair leverages a transformer-based time-series forecasting model to predict market trends, facilitating more informed and adaptable portfolio decisions. To integrate the forecasting model into a deep reinforcement learning-driven portfolio selection framework, we introduced a two-step strategy: first, pre-training the time-series model on market data, followed by fine-tuning the portfolio selection architecture using this model. Additionally, we investigated the optimization technique, Low-Rank Adaptation (LoRA), to enhance the pre-trained forecasting model for fine-tuning in investment scenarios. This work bridges market forecasting and portfolio selection, facilitating the advancement of investment strategies.", "citations": 5}
{"title": "A Deep Learning Framework for Medium-Term Covariance Forecasting in Multi-Asset Portfolios", "year": 2025, "authors": "Pedro Reis, Ana Paula Serra, Jo\u00e3o Gama", "url": "https://api.semanticscholar.org/CorpusId:276769266", "relevance": 1, "abstract": "Accurate covariance forecasting is central to portfolio allocation, risk management, and asset pricing, yet many existing methods struggle at medium-term horizons, where shifting market regimes and slower dynamics predominate. We propose a deep learning framework that combines three-dimensional convolutional neural networks, bidirectional long short-term memory layers, and multi-head attention to capture complex spatio-temporal dependencies. Using daily data on 14 exchange-traded funds from 2017 through 2023, we find that our model reduces Euclidean and Frobenius distance metrics by up to 20\\% relative to classical benchmarks (e.g., shrinkage and GARCH approaches) and remains robust across distinct market regimes. Our portfolio experiments demonstrate significant economic value through lower volatility and moderate turnover. These findings highlight the potential of advanced deep learning architectures to improve medium-term covariance forecasts, offering practical benefits for institutional investors and risk managers.", "citations": 2}
{"title": "FinTeamExperts: Role Specialized MOEs For Financial Analysis", "year": 2024, "authors": "Yue Yu, Prayag Tiwari", "url": "https://api.semanticscholar.org/CorpusId:273662304", "relevance": 1, "abstract": "Large Language Models (LLMs), such as ChatGPT, Phi3 and Llama-3, are leading a significant leap in AI, as they can generalize knowledge from their training to new tasks without fine-tuning. However, their application in the financial domain remains relatively limited. The financial field is inherently complex, requiring a deep understanding across various perspectives, from macro, micro economic trend to quantitative analysis. Motivated by this complexity, a mixture of expert LLMs tailored to specific financial domains could offer a more comprehensive understanding for intricate financial tasks. In this paper, we present the FinTeamExperts, a role-specialized LLM framework structured as a Mixture of Experts (MOEs) for financial analysis. The framework simulates a collaborative team setting by training each model to specialize in distinct roles: Macro Analysts, Micro analysts, and Quantitative Analysts. This role-specific specialization enhances the model's ability to integrate their domain-specific expertise. We achieve this by training three 8-billion parameter models on different corpus, each dedicated to excelling in specific finance-related roles. We then instruct-tune FinTeamExperts on downstream tasks to align with practical financial tasks. The experimental results show that FinTeamExperts outperform all models of the same size and larger on three out of four datasets. On the fourth dataset, which presents a more complex task, FinTeamExperts still surpass all models of the same size. This highlights the success of our role-based specialization approach and the continued training approach for FinTeamExperts.", "citations": 2}
{"title": "High-Dimensional Portfolio Selection with Cardinality Constraints", "year": 2022, "authors": "Jin-Hong Du, Yifeng Guo, Xueqin Wang", "url": "https://api.semanticscholar.org/CorpusId:252567955", "relevance": 1, "abstract": "Abstract The expanding number of assets offers more opportunities for investors but poses new challenges for modern portfolio management (PM). As a central plank of PM, portfolio selection by expected utility maximization (EUM) faces uncontrollable estimation and optimization errors in ultrahigh-dimensional scenarios. Past strategies for high-dimensional PM mainly concern only large-cap companies and select many stocks, making PM impractical. We propose a sample-average-approximation-based portfolio strategy to tackle the difficulties above with cardinality constraints. Our strategy bypasses the estimation of mean and covariance, the Chinese walls in high-dimensional scenarios. Empirical results on S&P 500 and Russell 2000 show that an appropriate number of carefully chosen assets leads to better out-of-sample mean-variance efficiency. On Russell 2000, our best portfolio profits as much as the equally weighted portfolio but reduces the maximum drawdown and the average number of assets by 10% and 90%, respectively. The flexibility and the stability of incorporating factor signals for augmenting out-of-sample performances are also demonstrated. Our strategy balances the tradeoff among the return, the risk, and the number of assets with cardinality constraints. Therefore, we provide a theoretically sound and computationally efficient strategy to make PM practical in the growing global financial market. Supplementary materials for this article are available online.", "citations": 14}
{"title": "Sparse Attention Combined with RAG Technology for Financial Data Analysis", "year": 2025, "authors": "Zhaoyan Zhang, Kaixian Xu, Yu Qiao, Alan Wilson", "url": "https://api.semanticscholar.org/CorpusId:277372776", "relevance": 1, "abstract": "In response to the challenges of multimodal data integration, real-time information retrieval, model hallucination, and lack of interpretability in financial stock analysis, this paper proposes an innovative financial analysis framework\u2014FSframe. It aims to address multiple challenges in stock analysis within the financial sector. The framework integrates various technological modules to provide comprehensive and efficient solutions for stock trend prediction and financial question answering tasks. First, FSframe optimizes large language models (LLMs), enhancing their adaptability to financial tasks, and incorporates prompt engineering to mitigate potential hallucination issues during the generation process, thereby improving the accuracy and reliability of the analysis. Secondly, the framework introduces Retrieval-Augmented Generation (RAG) technology, creating a dynamically updated financial knowledge base that enables the model to retrieve and integrate the latest market data, providing real-time external knowledge support for tasks. Furthermore, FSframe adopts a sparse attention mechanism, optimizing the processing efficiency of time-series data by filtering irrelevant information and focusing on key points, while also achieving efficient integration of time-series and textual data. Finally, through its modular design, FSframe organically combines the aforementioned advanced technologies, forming an innovative solution that blends multimodal data processing with real-time analysis, offering strong technical support for intelligent analysis in the financial sector. Validation on large-scale financial datasets (including historical stock prices, financial news, and market announcements) shows that FSframe significantly improves prediction accuracy and real-time responsiveness in stock trend forecasting and financial question answering tasks. Experimental results indicate that FSframe offers significant advantages in multimodal data integration, real-time performance, and interpretability, demonstrating excellent task adaptability and addressing the shortcomings of traditional methods. The FSframe framework not only provides an innovative solution for stock analysis in the financial sector but also opens new pathways for the development of intelligent financial technologies.", "citations": 1}
{"title": "Financial Instruction Following Evaluation (FIFE)", "year": 2025, "authors": "Glenn Scott Matlin, Siddharth, JM Anirudh, Aditya Shukla, Yahya Hassan, S. Chava", "url": "https://api.semanticscholar.org/CorpusId:283721484", "relevance": 1, "abstract": "Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.", "citations": 0}
{"title": "The Agentic Regulator: Risks for AI in Finance and a Proposed Agent-based Framework for Governance", "year": 2025, "authors": "Eren Kurshan, T. Balch, David Byrd", "url": "https://api.semanticscholar.org/CorpusId:283896735", "relevance": 1, "abstract": "Generative and agentic artificial intelligence is entering financial markets faster than existing governance can adapt. Current model-risk frameworks assume static, well-specified algorithms and one-time validations; large language models and multi-agent trading systems violate those assumptions by learning continuously, exchanging latent signals, and exhibiting emergent behavior. Drawing on complex adaptive systems theory, we model these technologies as decentralized ensembles whose risks propagate along multiple time-scales. We then propose a modular governance architecture. The framework decomposes oversight into four layers of\"regulatory blocks\": (i) self-regulation modules embedded beside each model, (ii) firm-level governance blocks that aggregate local telemetry and enforce policy, (iii) regulator-hosted agents that monitor sector-wide indicators for collusive or destabilizing patterns, and (iv) independent audit blocks that supply third-party assurance. Eight design strategies enable the blocks to evolve as fast as the models they police. A case study on emergent spoofing in multi-agent trading shows how the layered controls quarantine harmful behavior in real time while preserving innovation. The architecture remains compatible with today's model-risk rules yet closes critical observability and control gaps, providing a practical path toward resilient, adaptive AI governance in financial systems.", "citations": 0}
{"title": "Reinforcement Learning in Financial Decision Making: A Systematic Review of Performance, Challenges, and Implementation Strategies", "year": 2025, "authors": "Mohammad Rezoanul Hoque, M. Ferdaus, M. K. Hassan", "url": "https://api.semanticscholar.org/CorpusId:283737654", "relevance": 1, "abstract": "Reinforcement learning (RL) is an innovative approach to financial decision making, offering specialized solutions to complex investment problems where traditional methods fail. This review analyzes 167 articles from 2017--2025, focusing on market making, portfolio optimization, and algorithmic trading. It identifies key performance issues and challenges in RL for finance. Generally, RL offers advantages over traditional methods, particularly in market making. This study proposes a unified framework to address common concerns such as explainability, robustness, and deployment feasibility. Empirical evidence with synthetic data suggests that implementation quality and domain knowledge often outweigh algorithmic complexity. The study highlights the need for interpretable RL architectures for regulatory compliance, enhanced robustness in nonstationary environments, and standardized benchmarking protocols. Organizations should focus less on algorithm sophistication and more on market microstructure, regulatory constraints, and risk management in decision-making.", "citations": 0}
{"title": "Directly Learning Stock Trading Strategies Through Profit Guided Loss Functions", "year": 2025, "authors": "Devroop Kar, Zimeng Lyu, Sheeraja Rajakrishnan, Hao Zhang, Alex Ororbia, Travis J. Desell, Daniel Krutz", "url": "https://api.semanticscholar.org/CorpusId:280323100", "relevance": 1, "abstract": "Stock trading has always been a challenging task due to the highly volatile nature of the stock market. Making sound trading decisions to generate profit is particularly difficult under such conditions. To address this, we propose four novel loss functions to drive decision-making for a portfolio of stocks. These functions account for the potential profits or losses based with respect to buying or shorting respective stocks, enabling potentially any artificial neural network to directly learn an effective trading strategy. Despite the high volatility in stock market fluctuations over time, training time-series models such as transformers on these loss functions resulted in trading strategies that generated significant profits on a portfolio of 50 different S&P 500 company stocks as compared to a benchmark reinforcment learning techniques and a baseline buy and hold method. As an example, using 2021, 2022 and 2023 as three test periods, the Crossformer model adapted with our best loss function was most consistent, resulting in returns of 51.42%, 51.04% and 48.62% respectively. In comparison, the best performing state-of-the-art reinforcement learning methods, PPO and DDPG, only delivered maximum profits of around 41%, 2.81% and 41.58% for the same periods. The code is available at https://anonymous.4open.science/r/bandit-stock-trading-58C8/README.md.", "citations": 0}
{"title": "Decision by Supervised Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization", "year": 2025, "authors": "Juhyeon Kim, Sungyoon Choi, Youngbin Lee, Yejin Kim, Yongmin Choi, Yongjae Lee", "url": "https://api.semanticscholar.org/CorpusId:277104834", "relevance": 1, "abstract": "We propose Decision by Supervised Learning (DSL), a practical framework for robust portfolio optimization. DSL reframes portfolio construction as a supervised learning problem: models are trained to predict optimal portfolio weights, using cross-entropy loss and portfolios constructed by maximizing the Sharpe or Sortino ratio. To further enhance stability and reliability, DSL employs Deep Ensemble methods, substantially reducing variance in portfolio allocations. Through comprehensive backtesting across diverse market universes and neural architectures, shows superior performance compared to both traditional strategies and leading machine learning-based methods, including Prediction-Focused Learning and End-to-End Learning. We show that increasing the ensemble size leads to higher median returns and more stable risk-adjusted performance. The code is available at https://github.com/DSLwDE/DSLwDE.", "citations": 0}
{"title": "Improving Bayesian Optimization for Portfolio Management with an Adaptive Scheduling", "year": 2025, "authors": "Zinuo You, John Cartlidge, Karen Elliott, Menghan Ge, Daniel Gold", "url": "https://api.semanticscholar.org/CorpusId:277940301", "relevance": 1, "abstract": "Existing black-box portfolio management systems are prevalent in the financial industry due to commercial and safety constraints, though their performance can fluctuate dramatically with changing market regimes. Evaluating these non-transparent systems is computationally expensive, as fixed budgets limit the number of possible observations. Therefore, achieving stable and sample-efficient optimization for these systems has become a critical challenge. This work presents a novel Bayesian optimization framework (TPE-AS) that improves search stability and efficiency for black-box portfolio models under these limited observation budgets. Standard Bayesian optimization, which solely maximizes expected return, can yield erratic search trajectories and misalign the surrogate model with the true objective, thereby wasting the limited evaluation budget. To mitigate these issues, we propose a weighted Lagrangian estimator that leverages an adaptive schedule and importance sampling. This estimator dynamically balances exploration and exploitation by incorporating both the maximization of model performance and the minimization of the variance of model observations. It guides the search from broad, performance-seeking exploration towards stable and desirable regions as the optimization progresses. Extensive experiments and ablation studies, which establish our proposed method as the primary approach and other configurations as baselines, demonstrate its effectiveness across four backtest settings with three distinct black-box portfolio management models.", "citations": 0}
{"title": "Enhancing Black-Litterman Portfolio via Hybrid Forecasting Model Combining Multivariate Decomposition and Noise Reduction", "year": 2025, "authors": "Ziye Yang, Ke Lu, Yang Wang, Jerome Yen", "url": "https://api.semanticscholar.org/CorpusId:278905993", "relevance": 1, "abstract": "Modern portfolio construction demands robust methods for integrating data-driven insights into asset allocation. The Black-Litterman model offers a powerful Bayesian approach to adjust equilibrium returns using investor views to form a posterior expectation along with market priors. Mainstream research mainly generates subjective views through statistical models or machine learning methods, among which hybrid models combined with decomposition algorithms perform well. However, most hybrid models do not pay enough attention to noise, and time series decomposition methods based on single variables make it difficult to fully utilize information between multiple variables. Multivariate decomposition also has problems of low efficiency and poor component quality. In this study, we propose a novel hybrid forecasting model SSA-MAEMD-TCN to automate and improve the view generation process. The proposed model combines Singular Spectrum Analysis (SSA) for denoising, Multivariate Aligned Empirical Mode Decomposition (MA-EMD) for frequency-aligned decomposition, and Temporal Convolutional Networks (TCNs) for deep sequence learning to capture complex temporal patterns across multiple financial indicators. Empirical tests on the Nasdaq 100 Index stocks show a significant improvement in forecasting performance compared to baseline models based on MAEMD and MEMD. The optimized portfolio performs well, with annualized returns and Sharpe ratios far exceeding those of the traditional portfolio over a short holding period, even after accounting for transaction costs.", "citations": 0}
{"title": "RAG-IT: Retrieval-Augmented Instruction Tuning for Automated Financial Analysis -- A Case Study for the Semiconductor Sector", "year": 2024, "authors": "H. To, Tien-Cuong Bui, Van-Duc Le", "url": "https://www.semanticscholar.org/paper/a04c446a89af284eac7ca32f9652342a367421f4", "relevance": 1, "abstract": "Financial analysis relies heavily on the interpretation of earnings reports to assess company performance and guide decision-making. Traditional methods for generating such analyzes require significant financial expertise and are often time-consuming. With the rapid advancement of Large Language Models (LLMs), domain-specific adaptations have emerged for financial tasks such as sentiment analysis and entity recognition. This paper introduces RAG-IT (Retrieval-Augmented Instruction Tuning), a novel framework designed to automate the generation of earnings report analysis through an LLM fine-tuned specifically for the financial domain. Our approach integrates retrieval augmentation with instruction-based fine-tuning to enhance factual accuracy, contextual relevance, and domain adaptability. We construct a sector-specific financial instruction dataset derived from semiconductor industry documents to guide the LLM adaptation to specialized financial reasoning. Using NVIDIA, AMD, and Broadcom as representative companies, our case study demonstrates that RAG-IT substantially improves a general-purpose open-source LLM and achieves performance comparable to commercial systems like GPT-3.5 on financial report generation tasks. This research highlights the potential of retrieval-augmented instruction tuning to streamline and elevate financial analysis automation, advancing the broader field of intelligent financial reporting.", "citations": 2}
{"title": "Dynamic Pricing in Securities Lending Market: Application in Revenue Optimization for an Agent Lender Portfolio", "year": 2024, "authors": "Jing Xu, Yung-Cheng Hsu, William Biscarri", "url": "https://api.semanticscholar.org/CorpusId:271270178", "relevance": 1, "abstract": "Securities lending is an important part of the financial market structure, where agent lenders help long term institutional investors to lend out their securities to short sellers in exchange for a lending fee. Agent lenders within the market seek to optimize revenue by lending out securities at the highest rate possible. Typically, this rate is set by hard-coded business rules or standard supervised machine learning models. These approaches are often difficult to scale and are not adaptive to changing market conditions. Unlike a traditional stock exchange with a centralized limit order book, the securities lending market is organized similarly to an e-commerce marketplace, where agent lenders and borrowers can transact at any agreed price in a bilateral fashion. This similarity suggests that the use of typical methods for addressing dynamic pricing problems in e-commerce could be effective in the securities lending market. We show that existing contextual bandit frameworks can be successfully utilized in the securities lending market. Using offline evaluation on real historical data, we show that the contextual bandit approach can consistently outperform typical approaches by at least 15% in terms of total revenue generated.", "citations": 2}
{"title": "Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning", "year": 2024, "authors": "David Winkel, Niklas Strau\u00df, Matthias Schubert, Thomas Seidl", "url": "https://api.semanticscholar.org/CorpusId:264290245", "relevance": 1, "abstract": "Portfolio optimization tasks describe sequential decision problems in which the investor's wealth is distributed across a set of assets. Allocation constraints are used to enforce minimal or maximal investments into particular subsets of assets to control for objectives such as limiting the portfolio's exposure to a certain sector due to environmental concerns. Although methods for constrained Reinforcement Learning (CRL) can optimize policies while considering allocation constraints, it can be observed that these general methods yield suboptimal results. In this paper, we propose a novel approach to handle allocation constraints based on a decomposition of the constraint action space into a set of unconstrained allocation problems. In particular, we examine this approach for the case of two constraints. For example, an investor may wish to invest at least a certain percentage of the portfolio into green technologies while limiting the investment in the fossil energy sector. We show that the action space of the task is equivalent to the decomposed action space, and introduce a new reinforcement learning (RL) approach CAOSD, which is built on top of the decomposition. The experimental evaluation on real-world Nasdaq-100 data demonstrates that our approach consistently outperforms state-of-the-art CRL benchmarks for portfolio optimization.", "citations": 2}
{"title": "DSPO: An End-to-End Framework for Direct Sorted Portfolio Construction", "year": 2024, "authors": "Jianyuan Zhong, Zhijian Xu, Sai Wang, Xiangyu Wen, Jian Guo, Qiang Xu", "url": "https://api.semanticscholar.org/CorpusId:270062766", "relevance": 1, "abstract": "In quantitative investment, constructing characteristic-sorted portfolios is a crucial strategy for asset allocation. Traditional methods transform raw stock data of varying frequencies into predictive characteristic factors for asset sorting, often requiring extensive manual design and misalignment between prediction and optimization goals. To address these challenges, we introduce Direct Sorted Portfolio Optimization (DSPO), an innovative end-to-end framework that efficiently processes raw stock data to construct sorted portfolios directly. DSPO's neural network architecture seamlessly transitions stock data from input to output while effectively modeling the intra-dependency of time-steps and inter-dependency among all tradable stocks. Additionally, we incorporate a novel Monotonical Logistic Regression loss, which directly maximizes the likelihood of constructing optimal sorted portfolios. To the best of our knowledge, DSPO is the first method capable of handling market cross-sections with thousands of tradable stocks fully end-to-end from raw multi-frequency data. Empirical results demonstrate DSPO's effectiveness, yielding a RankIC of 10.12\\% and an accumulated return of 121.94\\% on the New York Stock Exchange in 2023-2024, and a RankIC of 9.11\\% with a return of 108.74\\% in other markets during 2021-2022.", "citations": 1}
{"title": "Investment Portfolio Management System Using Machine Learning", "year": 2024, "authors": "Payal Narale", "url": "https://api.semanticscholar.org/CorpusId:268867000", "relevance": 1, "abstract": "Abstract: Portfolio management is the concept of determining the proportions of various assets to be held in a portfolio in order to maximize return while minimizing risk exposure. Investment banking and financial management both depend heavily on portfolio optimization. Choosing the greatest feasible combinations of several portfolios to construct an optimal portfolio is an exponentially complex challenge in terms of computation. It's commonly believed that public opinion and financial markets are intertwined. Recently, a variety of machine learning algorithms have been employed to anticipate short-term financial markets with positive outcomes. On the other hand, historical returns don't seem to fit the normal distribution theory. But sentiment analysis performs better when combined with long short-term memory networks and historical data. In this project, we want to use AI/ML to predict portfolio risk and provide insights into how stocks will perform. We will train our model using datasets obtained from the Yahoo Financial API that include historical data from the top 100 companies (NIFTY 100) in the NSE and BSE from 2010 to 2021.", "citations": 0}
{"title": "Decision-Focused Forecasting: A Differentiable Multistage Optimisation Architecture", "year": 2024, "authors": "Egon Pervsak, Miguel F. Anjos", "url": "https://api.semanticscholar.org/CorpusId:278959132", "relevance": 1, "abstract": "Most decision-focused learning work has focused on single stage problems whereas many real-world decision problems are more appropriately modelled using multistage optimisation. In multistage problems contextual information is revealed over time, decisions have to be taken sequentially, and decisions now have an intertemporal effect on future decisions. Decision-focused forecasting is a recurrent differentiable optimisation architecture that expresses a fully differentiable multistage optimisation approach. This architecture enables us to account for the intertemporal decision effects of forecasts. We show what gradient adjustments are made to account for the state-path caused by forecasting. We apply the model to multistage problems in energy storage arbitrage and portfolio optimisation and report that our model outperforms existing approaches.", "citations": 0}
{"title": "Deep Portfolio Optimization via Distributional Prediction of Residual Factors", "year": 2020, "authors": "Kentaro Imajo, Kentaro Minami, Katsuya Ito, Kei Nakagawa", "url": "https://api.semanticscholar.org/CorpusId:229156665", "relevance": 1, "abstract": "Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems.", "citations": 31}
{"title": "A Comparison of Reinforcement Learning and Deep Trajectory Based Stochastic Control Agents for Stepwise Mean-Variance Hedging", "year": 2023, "authors": "Ali Fathi, B. Hientzsch", "url": "https://api.semanticscholar.org/CorpusId:256900822", "relevance": 1, "abstract": "We consider two data-driven approaches to hedging, Reinforcement Learning and Deep Trajectory-based Stochastic Optimal Control, under a stepwise mean-variance objective. We compare their performance for a European call option in the presence of transaction costs under discrete trading schedules. We do this for a setting where stock prices follow Black-Scholes-Merton dynamics and the\"book-keeping\"price for the option is given by the Black-Scholes-Merton model with the same parameters. This simulated data setting provides a\"sanitized\"lab environment with simple enough features where we can conduct a detailed study of strengths, features, issues, and limitations of these two approaches. However, the formulation is model free and could allow any other setting with available book-keeping prices. We consider this study as a first step to develop, test, and validate autonomous hedging agents, and we provide blueprints for such efforts that address various concerns and requirements.", "citations": 5}
{"title": "Categorical surrogation of agent\u2010based models: A comparative study of machine learning classifiers", "year": 2023, "authors": "B. Llacay, G. Peffer", "url": "https://api.semanticscholar.org/CorpusId:258893946", "relevance": 1, "abstract": "Agent\u2010based modelling has gained recognition in the last years because it provides a natural way to explore the behaviour of social systems. However, agent\u2010based models usually have a considerable number of parameters that make it computationally prohibitive to explore the complete space of parameter combinations. A promising approach to overcome the computational constraints of agent\u2010based models is the use of machine learning\u2010based surrogates or metamodels, which can be used as efficient proxies of the original agent\u2010based model. As the use of metamodels of agent\u2010based simulations is still an incipient area of research, there are no guidelines on which algorithms are the most suitable candidates. In order to contribute to filling this gap, we conduct here a systematic comparative analysis to evaluate different machine learning\u2010based approaches to agent\u2010based model surrogation. A key innovation of our work is the focus on classification methods for categorical metamodeling, which is highly relevant because agent\u2010based simulations are very often validated in a qualitative way. To analyse the performance of the classifiers we use three types of indicators\u2014measures of correctness, efficiency, and robustness\u2014and compare their results for different datasets and sample sizes using an agent\u2010based artificial market as a case study.", "citations": 4}
{"title": "The impact of active and passive investment on market efficiency: a simulation study", "year": 2023, "authors": "Patrick Jaquart, M. Motz, L. K\u00f6hler, Christof Weinhardt", "url": "https://api.semanticscholar.org/CorpusId:257579361", "relevance": 1, "abstract": "ABSTRACT We create a simulated financial market and examine the effect of different levels of active and passive investment on fundamental market efficiency. In our simulated market, active, passive, and random investors interact with each other through issuing orders. Active and passive investors select their portfolio weights by optimizing Markowitz-based utility functions. We find that higher fractions of active investment within a market lead to an increased fundamental market efficiency. The marginal increase in fundamental market efficiency per additional active investor is lower in markets with higher levels of active investment. Furthermore, we find that a large fraction of passive investors within a market may facilitate technical price bubbles, resulting in market failure. By examining the effect of specific parameters on market outcomes, we find that that lower transaction costs, lower individual forecasting errors of active investors, and less restrictive portfolio constraints tend to increase fundamental market efficiency in the market.", "citations": 4}
{"title": "PromptShots at the FinNLP-2022 ERAI Task: Pairwise Comparison and Unsupervised Ranking", "year": 2023, "authors": "Peratham Wiriyathammabhum", "url": "https://api.semanticscholar.org/CorpusId:255941990", "relevance": 1, "abstract": "This report describes our PromptShots submissions to a shared task on Evaluating the Rationales of Amateur Investors (ERAI). We participated in both pairwise comparison and unsupervised ranking tasks. For pairwise comparison, we employed instruction-based models based on T5-small and OpenAI InstructGPT language models. Surprisingly, we observed OpenAI InstructGPT language model few-shot trained on Chinese data works best in our submissions, ranking 3rd on the maximal loss (ML) pairwise accuracy. This model works better than training on the Google translated English data by a large margin, where the English few-shot trained InstructGPT model even performs worse than an instruction-based T5-small model finetuned on the English data. However, all instruction-based submissions do not perform well on the maximal potential profit (MPP) pairwise accuracy where there are more data and learning signals. The Chinese few-shot trained InstructGPT model still performs best in our setting. For unsupervised ranking, we utilized many language models, including many financial-specific ones, and Bayesian lexicons unsupervised-learned on both Chinese and English words using a method-of-moments estimator. All our submissions rank best in the MPP ranking, from 1st to 3rd. However, they all do not perform well for ML scoring. Therefore, both MPP and ML scores need different treatments since we treated MPP and ML using the same formula. Our only difference is the treatment of market sentiment lexicons.", "citations": 4}
{"title": "A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading", "year": 2023, "authors": "R. Amirzadeh, D. Thiruvady, A. Nazari, M. Ee", "url": "https://api.semanticscholar.org/CorpusId:264145771", "relevance": 1, "abstract": "Despite advances in artificial intelligence-enhanced trading methods, developing a profitable automated trading system remains challenging in the rapidly evolving cryptocurrency market. This research focuses on developing a reinforcement learning (RL) framework to tackle the complexities of trading five prominent altcoins: Binance Coin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present the CausalReinforceNet~(CRN) framework, which integrates both Bayesian and dynamic Bayesian network techniques to empower the RL agent in trade decision-making. We develop two agents using the framework based on distinct RL algorithms to analyse performance compared to the Buy-and-Hold benchmark strategy and a baseline RL model. The results indicate that our framework surpasses both models in profitability, highlighting CRN's consistent superiority, although the level of effectiveness varies across different cryptocurrencies.", "citations": 3}
{"title": "Decision Support Systems in Stock Investment Problems", "year": 2023, "authors": "Tolga T\u00fckel, Utku K\u00f6se, G\u00f6zde \u00d6zkan T\u00fckel", "url": "https://api.semanticscholar.org/CorpusId:265013372", "relevance": 1, "abstract": "This study compiles decision support systems that aim to optimize financial decision processes by examining the literature studies targeting stock investments. The review encompasses a range of methodologies and applications, from traditional approaches such as Markowitz\u2019s Modern Portfolio Theory, Black-Litterman, and Single Index models to artificial intelligence-based techniques. In detail, the contributions of Decision Support Systems to stock portfolio construction and portfolio optimization processes along with comparative analyses between these systems are scrutinized. The review also aims to enable researchers and practitioners to be engaged in portfolio optimization with a framework for future investigations in areas such as historical data analysis, future price movement prediction, assessment of risk factors, and determination of optimal portfolio distribution. Furthermore, it seeks to enhance the understanding of decision support systems employed in portfolio optimization, facilitating a more comprehensive grasp of their utility within stock investments.", "citations": 3}
{"title": "Leveraging Deep Learning and Online Source Sentiment for Financial Portfolio Management", "year": 2023, "authors": "Paraskevi Nousi, L. Avramelou, Georgios Rodinos, Maria Tzelepi, Theodoros Manousis, K. Tsampazis, K. Stefanidis, Dimitris Spanos, E. Kirtas, P. Tosidis, Avraam Tsantekidis, Nikolaos Passalis, A. Tefas", "url": "https://api.semanticscholar.org/CorpusId:263311035", "relevance": 1, "abstract": "Financial portfolio management describes the task of distributing funds and conducting trading operations on a set of financial assets, such as stocks, index funds, foreign exchange or cryptocurrencies, aiming to maximize the profit while minimizing the loss incurred by said operations. Deep Learning (DL) methods have been consistently excelling at various tasks and automated financial trading is one of the most complex one of those. This paper aims to provide insight into various DL methods for financial trading, under both the supervised and reinforcement learning schemes. At the same time, taking into consideration sentiment information regarding the traded assets, we discuss and demonstrate their usefulness through corresponding research studies. Finally, we discuss commonly found problems in training such financial agents and equip the reader with the necessary knowledge to avoid these problems and apply the discussed methods in practice.", "citations": 2}
{"title": "Navigating Uncertainty in ESG Investing", "year": 2023, "authors": "Jiayue Zhang, Ken Seng Tan, T. Wirjanto, Lysa Porth", "url": "https://api.semanticscholar.org/CorpusId:263608703", "relevance": 1, "abstract": "The widespread confusion among investors regarding Environmental, Social, and Governance (ESG) rankings assigned by rating agencies has underscored a critical issue in sustainable investing. To address this uncertainty, our research has devised methods that not only recognize this ambiguity but also offer tailored investment strategies for different investor profiles. By developing ESG ensemble strategies and integrating ESG scores into a Reinforcement Learning (RL) model, we aim to optimize portfolios that cater to both financial returns and ESG-focused outcomes. Additionally, by proposing the Double-Mean-Variance model, we classify three types of investors based on their risk preferences. We also introduce ESG-adjusted Capital Asset Pricing Models (CAPMs) to assess the performance of these optimized portfolios. Ultimately, our comprehensive approach provides investors with tools to navigate the inherent ambiguities of ESG ratings, facilitating more informed investment decisions.", "citations": 0}
{"title": "Order book regulatory impact on stock market quality: a multi-agent reinforcement learning perspective", "year": 2023, "authors": "J. Lussange, B. Gutkin", "url": "https://api.semanticscholar.org/CorpusId:256662508", "relevance": 1, "abstract": "Recent technological developments have changed the fundamental ways stock markets function, bringing regulatory instances to assess the benefits of these developments. In parallel, the ongoing machine learning revolution and its multiple applications to trading can now be used to design a next generation of financial models, and thereby explore the systemic complexity of financial stock markets in new ways. We here follow on a previous groundwork, where we designed and calibrated a novel agent-based model stock market simulator, where each agent autonomously learns to trade by reinforcement learning. In this Paper, we now study the predictions of this model from a regulator's perspective. In particular, we focus on how the market quality is impacted by smaller order book tick sizes, increasingly larger metaorders, and higher trading frequencies, respectively. Under our model assumptions, we find that the market quality benefits from the latter, but not from the other two trends.", "citations": 0}
{"title": "Semantic Similarity Covariance Matrix Shrinkage", "year": 2023, "authors": "Guillaume Becquin, Saher Esmeir", "url": "https://api.semanticscholar.org/CorpusId:266176964", "relevance": 1, "abstract": "An accurate estimation of the covariance matrix is a critical component of many applications in finance, including portfolio optimization. The sample covariance suffers from the curse of dimensionality when the number of observations is in the same order or lower than the number of variables. This tends to be the case in portfolio optimization, where a portfolio manager can choose between thousands of stocks using historical daily returns to guide their investment decisions. To address this issue, past works proposed linear covariance shrinkage to regularize the estimated matrix. While effective, the proposed methods relied solely on historical price data and thus ignored company fundamental data. In this work, we propose to utilise semantic similarity derived from textual descriptions or knowledge graphs to improve the covariance estimation. Rather than using the semantic similarity directly as a biased estimator to the covariance, we employ it as a shrinkage target. The resulting covariance estimators leverage both semantic similarity and recent price history, and can be readily adapted to a broad range of financial securities. The effectiveness of the approach is demonstrated for a period including diverse market conditions and compared with the covariance shrinkage prior art.", "citations": 0}
{"title": "Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?", "year": 2023, "authors": "Haohan Zhang, Fengrui Hua, Chengjin Xu, Jian Guo, Hao Kong, Ruiting Zuo", "url": "https://www.semanticscholar.org/paper/2b47921d12e3d1c6fc4738ad9019029c1bf0fb76", "relevance": 1, "abstract": "The rapid advancement of Large Language Models (LLMs) has spurred discussions about their potential to enhance quantitative trading strategies. LLMs excel in analyzing sentiments about listed companies from financial news, providing critical insights for trading decisions. However, the performance of LLMs in this task varies substantially due to their inherent characteristics. This paper introduces a standardized experimental procedure for comprehensive evaluations. We detail the methodology using three distinct LLMs, each embodying a unique approach to performance enhancement, applied specifically to the task of sentiment factor extraction from large volumes of Chinese news summaries. Subsequently, we develop quantitative trading strategies using these sentiment factors and conduct back-tests in realistic scenarios. Our results will offer perspectives about the performances of Large Language Models applied to extracting sentiments from Chinese news texts.", "citations": 22}
{"title": "Precise Stock Price Prediction for Optimized Portfolio Design Using an LSTM Model", "year": 2021, "authors": "Jaydip Sen, Sidra Mehtab, Abhishek Dutta, Saikat Mondal", "url": "https://api.semanticscholar.org/CorpusId:247192728", "relevance": 1, "abstract": "Accurate prediction of future prices of stocks is a difficult task to perform. Even more challenging is to design an optimized portfolio of stocks with the identification of proper weights of allocation to achieve the optimized values of return and risk. We present optimized portfolios based on the seven sectors of the Indian economy. The past prices of the stocks are extracted from the web from January 1,2016, to December 31, 2020. Optimum portfolios are designed on the selected seven sectors. An LSTM regression model is also designed for predicting future stock prices. Five months after the construction of the portfolios, i.e., on June 1, 2021, the actual and predicted returns and risks of each portfolio are computed. The predicted and the actual returns indicate the very high accuracy of the LS TM model.", "citations": 15}
{"title": "A Novel Modeling Technique for the Forecasting of Multiple\u2010Asset Trading Volumes: Innovative Initial\u2010Value\u2010Problem Differential Equation Algorithms for Reinforcement Machine Learning", "year": 2022, "authors": "M. A. Janabi", "url": "https://api.semanticscholar.org/CorpusId:247534552", "relevance": 1, "abstract": "Liquidity risk arises from the inability to unwind or hedge trading positions at the prevailing market prices. The risk of liquidity is a wide and complex topic as it depends on several factors and causes. While much has been written on the subject, there exists no clear\u2010cut mathematical description of the phenomena and typical market risk modeling methods fail to identify the effect of illiquidity risk. In this paper, we do not propose a definitive one either, but we attempt to derive novel mathematical algorithms for the dynamic modeling of trading volumes during the closeout period from the perspective of multiple\u2010asset portfolio(s), as well as for financial entities with different subsidiary firms and multiple agents. The robust modeling techniques are based on the application of initial\u2010value\u2010problem differential equations technique for portfolio selection and risk management purposes. This paper provides some crucial parameters for the assessment of the trading volumes of multiple\u2010asset portfolio(s) during the closeout period, where the mathematical proofs for each theorem and corollary are provided. Based on the new developed econophysics theory, this paper presents for the first time a closed\u2010form solution for key parameters for the estimation of trading volumes and liquidity risk, such as the unwinding constant, half\u2010life, and mean lifetime and discusses how these novel parameters can be estimated and incorporated into the proposed techniques. The developed modeling algorithms are appealing in terms of theory and are promising for practical econophysics applications, particularly in developing dynamic and robust portfolio management algorithms in light of the 2007\u20132009 global financial crunch. In addition, they can be applied to artificial intelligence and machine learning for the policymaking process, reinforcement machine learning techniques for the Internet of Things (IoT) data analytics, expert systems in finance, FinTech, and within big data ecosystems.", "citations": 4}
{"title": "LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction", "year": 2024, "authors": "Meiyun Wang, Kiyoshi Izumi, Hiroki Sakaji", "url": "https://www.semanticscholar.org/paper/7185f24f33de547954baa0c71cafaf41786e81ba", "relevance": 1, "abstract": "Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting tasks. In this study, we introduce a novel framework called LLMFactor, which employs Sequential Knowledge-Guided Prompting (SKGP) to identify factors that influence stock movements using LLMs. Unlike previous methods that relied on keyphrases or sentiment analysis, this approach focuses on extracting factors more directly related to stock market dynamics, providing clear explanations for complex temporal changes. Our framework directs the LLMs to create background knowledge through a fill-in-the-blank strategy and then discerns potential factors affecting stock prices from related news. Guided by background knowledge and identified factors, we leverage historical stock prices in textual format to predict stock movement. An extensive evaluation of the LLMFactor framework across four benchmark datasets from both the U.S. and Chinese stock markets demonstrates its superiority over existing state-of-the-art methods and its effectiveness in financial time-series forecasting.", "citations": 41}
{"title": "Risk-aware multi-armed bandit problem with application to portfolio selection", "year": 2017, "authors": "Xiaoguang Huo, Feng Fu", "url": "https://api.semanticscholar.org/CorpusId:2107106", "relevance": 1, "abstract": "Sequential portfolio selection has attracted increasing interest in the machine learning and quantitative finance communities in recent years. As a mathematical framework for reinforcement learning policies, the stochastic multi-armed bandit problem addresses the primary difficulty in sequential decision-making under uncertainty, namely the exploration versus exploitation dilemma, and therefore provides a natural connection to portfolio selection. In this paper, we incorporate risk awareness into the classic multi-armed bandit setting and introduce an algorithm to construct portfolio. Through filtering assets based on the topological structure of the financial market and combining the optimal multi-armed bandit policy with the minimization of a coherent risk measure, we achieve a balance between risk and return.", "citations": 75}
{"title": "Hybrid quantum\u2013classical optimization with cardinality constraints and applications to finance", "year": 2020, "authors": "Samuel Fern'andez-Lorenzo, D. Porras, J. Garc'ia-Ripoll", "url": "https://api.semanticscholar.org/CorpusId:221341047", "relevance": 1, "abstract": "In this work we develop tools to address combinatorial optimization problems with a cardinality constraint, in which only a subset of variables end up having nonzero values. Firstly, we introduce a new heuristic pruning method that iteratively discards variables through a hybrid quantum\u2013classical optimization step. Secondly, we analyse the use of soft constraints in the form of \u2018chemical potentials\u2019 to control the number of non-zero variables. We illustrate the power of both techniques using the problem of index tracking, which aims to mimicking the performance of a financial index with a balanced subset of assets. We also compare the performance of different state-of-the-art quantum variational optimization algorithms in our pruning method.", "citations": 21}
{"title": "mt5se: An Open Source Framework for Building Autonomous Trading Robots", "year": 2021, "authors": "Paulo Andr\u00e9 Lima de Castro", "url": "https://api.semanticscholar.org/CorpusId:250113355", "relevance": 1, "abstract": "Autonomous trading robots have been studied in artificial intelligence area for quite some time. Many AI techniques have been tested for building autonomous agents able to trade financial assets. These initiatives include traditional neural networks, fuzzy logic, reinforcement learning but also more recent approaches like deep neural networks and deep reinforcement learning. Many developers claim to be successful in creating robots with great performance when simulating execution with historical price series, so called backtesting. However, when these robots are used in real markets frequently they present poor performance in terms of risks and return. In this paper, we propose an open source framework (mt5se) that helps the development, backtesting, live testing and real operation of autonomous traders. We built and tested several traders using mt5se. The results indicate that it may help the development of better traders. Furthermore, we discuss the simple architecture that is used in many studies and propose an alternative multiagent architecture. Such architecture separates two main concerns for portfolio manager (PM) : price prediction and capital allocation. More than achieve a high accuracy, a PM should increase profits when it is right and reduce loss when it is wrong. Furthermore, price prediction is highly dependent of asset's nature and history, while capital allocation is dependent only on analyst's prediction performance and assets' correlation. Finally, we discuss some promising technologies in the area.", "citations": 0}
{"title": "Stock market microstructure inference via multi-agent reinforcement learning", "year": 2019, "authors": "J. Lussange, I. Lazarevich, S. Bourgeois-Gironde, Stefano Palminteri, B. Gutkin", "url": "https://api.semanticscholar.org/CorpusId:204008131", "relevance": 1, "abstract": "Quantitative finance has had a long tradition of a bottom-up approach to complex systems inference via multi-agent systems (MAS). These statistical tools are based on modelling agents trading via a centralised order book, in order to emulate complex and diverse market phenomena. These past financial models have all relied on so-called zero-intelligence agents, so that the crucial issues of agent information and learning, central to price formation and hence to all market activity, could not be properly assessed. In order to address this, we designed a next-generation MAS stock market simulator, in which each agent learns to trade autonomously via model-free reinforcement learning. We calibrate the model to real market data from the London Stock Exchange over the years $2007$ to $2018$, and show that it can faithfully reproduce key market microstructure metrics, such as various price autocorrelation scalars over multiple time intervals. Agent learning thus enables model emulation of the microstructure with greater realism.", "citations": 2}
{"title": "Confidence and the Stock Market: An Agent-Based Approach", "year": 2014, "authors": "M. A. Bertella, F. R. Pires, Ling Feng, H. Stanley", "url": "https://api.semanticscholar.org/CorpusId:2663986", "relevance": 1, "abstract": "Using a behavioral finance approach we study the impact of behavioral bias. We construct an artificial market consisting of fundamentalists and chartists to model the decision-making process of various agents. The agents differ in their strategies for evaluating stock prices, and exhibit differing memory lengths and confidence levels. When we increase the heterogeneity of the strategies used by the agents, in particular the memory lengths, we observe excess volatility and kurtosis, in agreement with real market fluctuations\u2014indicating that agents in real-world financial markets exhibit widely differing memory lengths. We incorporate the behavioral traits of adaptive confidence and observe a positive correlation between average confidence and return rate, indicating that market sentiment is an important driver in price fluctuations. The introduction of market confidence increases price volatility, reflecting the negative effect of irrationality in market behavior.", "citations": 91}
{"title": "A Mean Field Game Of Portfolio Trading And Its Consequences On Perceived Correlations", "year": 2019, "authors": "Charles-Albert Lehalle, Charafeddine Mouzouni", "url": "https://api.semanticscholar.org/CorpusId:159168976", "relevance": 1, "abstract": "This paper goes beyond the optimal trading Mean Field Game model introduced by Pierre Cardaliaguet and Charles-Albert Lehalle in [Cardaliaguet, P. and Lehalle, C.-A., Mean field game of controls and an application to trade crowding, Mathematics and Financial Economics (2018)]. It starts by extending it to portfolios of correlated instruments. This leads to several original contributions: first that hedging strategies naturally stem from optimal liquidation schemes on portfolios. Second we show the influence of trading flows on naive estimates of intraday volatility and correlations. Focussing on this important relation, we exhibit a closed form formula expressing standard estimates of correlations as a function of the underlying correlations and the initial imbalance of large orders, via the optimal flows of our mean field game between traders. To support our theoretical findings, we use a real dataset of 176 US stocks from January to December 2014 sampled every 5 minutes to analyze the influence of the daily flows on the observed correlations. Finally, we propose a toy model based approach to calibrate our MFG model on data.", "citations": 27}
{"title": "A Framework for Online Investment Algorithms", "year": 2020, "authors": "A. Paskaramoorthy, Terence L van Zyl, Tim Gebbie", "url": "https://api.semanticscholar.org/CorpusId:214714406", "relevance": 1, "abstract": "The artificial segmentation of an investment management process into a workflow with silos of offline human operators can restrict silos from collectively and adaptively pursuing a unified optimal investment goal. To meet the investor's objectives, an online algorithm can provide an explicit incremental approach that makes sequential updates as data arrives at the process level. This is in stark contrast to offline (or batch) processes that are focused on making component level decisions prior to process level integration. Here we present and report results for an integrated, and online framework for algorithmic portfolio management. This article provides a workflow that can in-turn be embedded into a process level learning framework. The workflow can be enhanced to refine signal generation and asset-class evolution and definitions. Our results confirm that we can use our framework in conjunction with resampling methods to outperform naive market capitalisation benchmarks while making clear the extent of back-test over-fitting. We consider such an online update framework to be a crucial step towards developing intelligent portfolio selection algorithms that integrate financial theory, investor views, and data analysis with process-level learning.", "citations": 10}
{"title": "Pagan: Portfolio Analysis with Generative Adversarial Networks", "year": 2019, "authors": "G. Mariani, Yada Zhu, Jianbo Li, F. Scheidegger, R. Istrate, C. Bekas, A. Malossi", "url": "https://api.semanticscholar.org/CorpusId:202734171", "relevance": 1, "abstract": "Since decades, the data science community tries to propose prediction models of financial time series. Yet, driven by the rapid development of information technology and machine intelligence, the velocity of today's information leads to high market efficiency. Sound financial theories demonstrate that in an efficient marketplace all information available today, including expectations on future events, are represented in today prices whereas future price trend is driven by the uncertainty. This jeopardizes the efforts put in designing prediction models. To deal with the unpredictability of financial systems, today's portfolio management is largely based on the Markowitz framework which puts more emphasis in the analysis of the market uncertainty and less in the price prediction. The limitation of the Markowitz framework stands in taking very strong ideal assumptions about future returns probability distribution. \nTo address this situation we propose PAGAN, a pioneering methodology based on deep generative models. The goal is modeling the market uncertainty that ultimately is the main factor driving future trends. The generative model learns the joint probability distribution of price trends for a set of financial assets to match the probability distribution of the real market. Once the model is trained, a portfolio is optimized by deciding the best diversification to minimize the risk and maximize the expected returns observed over the execution of several simulations. Applying the model for analyzing possible futures, is as simple as executing a Monte Carlo simulation, a technique very familiar to finance experts. The experimental results on different portfolios representing different geopolitical areas and industrial segments constructed using real-world public data sets demonstrate promising results.", "citations": 23}
{"title": "Dynamic dependence networks: Financial time series forecasting and portfolio decisions", "year": 2016, "authors": "Z. Zhao, Mengning Xie, M. West", "url": "https://api.semanticscholar.org/CorpusId:31565086", "relevance": 1, "abstract": "We discuss Bayesian forecasting of increasingly high-dimensional time series, a key area of application of stochastic dynamic models in the financial industry and allied areas of business. Novel state-space models characterizing sparse patterns of dependence among multiple time series extend existing multivariate volatility models to enable scaling to higher numbers of individual time series. The theory of these dynamic dependence network models shows how the individual series can be decoupled for sequential analysis and then recoupled for applied forecasting and decision analysis. Decoupling allows fast, efficient analysis of each of the series in individual univariate models that are linked - for later recoupling - through a theoretical multivariate volatility structure defined by a sparse underlying graphical model. Computational advances are especially significant in connection with model uncertainty about the sparsity patterns among series that define this graphical model; Bayesian model averaging using discounting of historical information builds substantially on this computational advance. An extensive, detailed case study showcases the use of these models and the improvements in forecasting and financial portfolio investment decisions that are achievable. Using a long series of daily international currencies, stock indices and commodity prices, the case study includes evaluations of multi-day forecasts and Bayesian portfolio analysis with a variety of practical utility functions, as well as comparisons against commodity trading advisor benchmarks. Copyright \u00a9 2016 John Wiley & Sons, Ltd.", "citations": 59}
{"title": "Graphical models for financial time series and portfolio selection", "year": 2020, "authors": "Ni Zhan, Yijia Sun, Aman Jakhar, Hening Liu", "url": "https://api.semanticscholar.org/CorpusId:231692964", "relevance": 1, "abstract": "We examine a variety of graphical models to construct optimal portfolios. Graphical models such as PCA-KMeans, autoencoders, dynamic clustering, and structural learning can capture the time varying patterns in the covariance matrix and allow the creation of an optimal and robust portfolio. We compared the resulting portfolios from the different models with baseline methods. In many cases our graphical strategies generated steadily increasing returns with low risk and outgrew the S&P 500 index. This work suggests that graphical models can effectively learn the temporal dependencies in time series data and are proved useful in asset management.", "citations": 2}
{"title": "FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model", "year": 2024, "authors": "Xiangyu Li, Xinjie Shen, Yawen Zeng, Xiaofen Xing, Jin Xu", "url": "https://www.semanticscholar.org/paper/186fbd0bfe897dd156389d3fea6642fb4b058de2", "relevance": 1, "abstract": "The task of stock earnings forecasting has received considerable attention due to the demand investors in real-world scenarios. However, compared with financial institutions, it is not easy for ordinary investors to mine factors and analyze news. On the other hand, although large language models in the financial field can serve users in the form of dialogue robots, it still requires users to have financial knowledge to ask reasonable questions. To serve the user experience, we aim to build an automatic system, FinReport, for ordinary investors to collect information, analyze it, and generate reports after summarizing. Specifically, our FinReport is based on financial news announcements and a multi-factor model to ensure the professionalism of the report. The FinReport consists of three modules: news factorization module, return forecasting module, risk assessment module. The news factorization module involves understanding news information and combining it with stock factors, the return forecasting module aim to analysis the impact of news on market sentiment, and the risk assessment module is adopted to control investment risk. Extensive experiments on real-world datasets have well verified the effectiveness and explainability of our proposed FinReport. Our codes and datasets are available at https://github.com/frinkleko/FinReport.", "citations": 19}
{"title": "TradeMaster: A Holistic Quantitative Trading Platform Empowered by Reinforcement Learning", "year": 2023, "authors": "Shuo Sun, Molei Qin, Wentao Zhang, Haochong Xia, Chuqiao Zong, Jie Ying, Yonggang Xie, Lingxuan Zhao, Xinrun Wang, Bo An", "url": "https://www.semanticscholar.org/paper/7e85a70f45911343ec9112a4df69bb7b0880a539", "relevance": 1, "abstract": "", "citations": 20}
{"title": "BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs", "year": 2025, "authors": "Guilong Lu, Xuntao Guo, Rongjunchen Zhang, Wenqiao Zhu, Ji Liu", "url": "https://www.semanticscholar.org/paper/9de263bfddf6888f928bc66837f1dd788289de13", "relevance": 1, "abstract": "Large language models excel in general tasks, yet assessing their reliability in logic-heavy, precision-critical domains like finance, law, and healthcare remains challenging. To address this, we introduce BizFinBench, the first benchmark specifically designed to evaluate LLMs in real-world financial applications. BizFinBench consists of 6,781 well-annotated queries in Chinese, spanning five dimensions: numerical calculation, reasoning, information extraction, prediction recognition, and knowledge-based question answering, grouped into nine fine-grained categories. The benchmark includes both objective and subjective metrics. We also introduce IteraJudge, a novel LLM evaluation method that reduces bias when LLMs serve as evaluators in objective metrics. We benchmark 25 models, including both proprietary and open-source systems. Extensive experiments show that no model dominates across all tasks. Our evaluation reveals distinct capability patterns: (1) In Numerical Calculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while smaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning, proprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with open-source models trailing by up to 19.49 points; (3) In Information Extraction, the performance spread is the largest, with DeepSeek-R1 scoring 71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition, performance variance is minimal, with top models scoring between 39.16 and 50.00. We find that while current LLMs handle routine finance queries competently, they struggle with complex scenarios requiring cross-concept reasoning. BizFinBench offers a rigorous, business-aligned benchmark for future research. The code and dataset are available at https://github.com/HiThink-Research/BizFinBench.", "citations": 14}
{"title": "FinTSB: A Comprehensive and Practical Benchmark for Financial Time Series Forecasting", "year": 2025, "authors": "Yifan Hu, Yuante Li, Peiyuan Liu, Yuxia Zhu, Naiqi Li, Tao Dai, Shu-Tao Xia, Dawei Cheng, Changjun Jiang", "url": "https://www.semanticscholar.org/paper/036e3421a65d0ecb903cfff2daf329005f1a37f8", "relevance": 1, "abstract": "Financial time series (FinTS) record the behavior of human-brain-augmented decision-making, capturing valuable historical information that can be leveraged for profitable investment strategies. Not surprisingly, this area has attracted considerable attention from researchers, who have proposed a wide range of methods based on various backbones. However, the evaluation of the area often exhibits three systemic limitations: 1. Failure to account for the full spectrum of stock movement patterns observed in dynamic financial markets. (Diversity Gap), 2. The absence of unified assessment protocols undermines the validity of cross-study performance comparisons. (Standardization Deficit), and 3. Neglect of critical market structure factors, resulting in inflated performance metrics that lack practical applicability. (Real-World Mismatch). Addressing these limitations, we propose FinTSB, a comprehensive and practical benchmark for financial time series forecasting (FinTSF). To increase the variety, we categorize movement patterns into four specific parts, tokenize and pre-process the data, and assess the data quality based on some sequence characteristics. To eliminate biases due to different evaluation settings, we standardize the metrics across three dimensions and build a user-friendly, lightweight pipeline incorporating methods from various backbones. To accurately simulate real-world trading scenarios and facilitate practical implementation, we extensively model various regulatory constraints, including transaction fees, among others. Finally, we conduct extensive experiments on FinTSB, highlighting key insights to guide model selection under varying market conditions. Overall, FinTSB provides researchers with a novel and comprehensive platform for improving and evaluating FinTSF methods. The code is available at https://github.com/TongjiFinLab/FinTSBenchmark.", "citations": 14}
{"title": "An Agent-based Model of Contagion in Financial Networks", "year": 2017, "authors": "L. Pinheiro, F. Coelho", "url": "https://api.semanticscholar.org/CorpusId:168912466", "relevance": 1, "abstract": "This work develops an agent-based model for the study of how the leverage through the use of repurchase agreements can function as a mechanism for the propagation and amplification of financial shocks in a financial system. Based on the analysis of financial intermediaries in the repo and interbank lending markets during the 2007-08 financial crisis we develop a model that can be used to simulate the dynamics of financial contagion.", "citations": 0}
{"title": "Evaluating LLMs in Finance Requires Explicit Bias Consideration", "year": 2026, "authors": "Yaxuan Kong, Hoyoung Lee, Yoontae Hwang, Alejandro Lopez-Lira, Bradford Levy, Dhagash Mehta, Qingsong Wen, Chanyeol Choi, Yongjae Lee, Stefan Zohren", "url": "https://www.semanticscholar.org/paper/1744469bb8a5a2c5b462cc5d1f33ce621ab35424", "relevance": 1, "abstract": "Large Language Models (LLMs) are increasingly integrated into financial workflows, but evaluation practice has not kept up. Finance-specific biases can inflate performance, contaminate backtests, and make reported results useless for any deployment claim. We identify five recurring biases in financial LLM applications. They include look-ahead bias, survivorship bias, narrative bias, objective bias, and cost bias. These biases break financial tasks in distinct ways and they often compound to create an illusion of validity. We reviewed 164 papers from 2023 to 2025 and found that no single bias is discussed in more than 28 percent of studies. This position paper argues that bias in financial LLM systems requires explicit attention and that structural validity should be enforced before any result is used to support a deployment claim. We propose a Structural Validity Framework and an evaluation checklist with minimal requirements for bias diagnosis and future system design. The material is available at https://github.com/Eleanorkong/Awesome-Financial-LLM-Bias-Mitigation.", "citations": 0}
{"title": "A General Framework on Enhancing Portfolio Management with Reinforcement Learning", "year": 2019, "authors": "Yinheng Li, Junhao Wang, Yijie Cao", "url": "https://api.semanticscholar.org/CorpusId:208309865", "relevance": 1, "abstract": "Portfolio management is the art and science in fiance that concerns continuous reallocation of funds and assets across financial instruments to meet the desired returns to risk profile. Deep reinforcement learning (RL) has gained increasing interest in portfolio management, where RL agents are trained base on financial data to optimize the asset reallocation process. Though there are prior efforts in trying to combine RL and portfolio management, previous works did not consider practical aspects such as transaction costs or short selling restrictions, limiting their applicability. To address these limitations, we propose a general RL framework for asset management that enables continuous asset weights, short selling and making decisions with relevant features. We compare the performance of three different RL algorithms: Policy Gradient with Actor-Critic (PGAC), Proximal Policy Optimization (PPO), and Evolution Strategies (ES) and demonstrate their advantages in a simulated environment with transaction costs. Our work aims to provide more options for utilizing RL frameworks in real-life asset management scenarios and can benefit further research in financial applications.", "citations": 6}
{"title": "MMRepAgent: Explainable stock earnings forecasting via multimodal report agent framework", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://www.semanticscholar.org/paper/f7f5dcdc055f3caf71d30491c38b940c72cc80de", "relevance": 1, "abstract": "", "citations": 0}
{"title": "Portfolio Performance Based on LLM News Scores and Related Economical Analysis", "year": 2024, "authors": "Ruoxue Wu", "url": "https://www.semanticscholar.org/paper/8ac5c9808d72aca46d2e66d701a58a27403ec151", "relevance": 1, "abstract": "", "citations": 8}
{"title": "Time Series Momentum", "year": 2012, "authors": "Tobias. Moskowitz, Yao Hua Ooi, L. Pedersen", "url": "https://www.semanticscholar.org/paper/797398408f967a6e6bc4570db7df7daeccd6fa61", "relevance": 1, "abstract": "We document significant \u2018\u2018time series momentum\u2019\u2019 in equity index, currency, commodity, and bond futures for each of the 58 liquid instruments we consider. We find persistence in returns for one to 12 months that partially reverses over longer horizons, consistent with sentiment theories of initial under-reaction and delayed over-reaction. A diversified portfolio of time series momentum strategies across all asset classes delivers substantial abnormal returns with little exposure to standard asset pricing factors and performs best during extreme markets. Examining the trading activities of speculators and hedgers, we find that speculators profit from time series momentum at the expense of hedgers.", "citations": 1393}
{"title": "Adaptive Configuration Oracle for Online Portfolio Selection Methods", "year": 2019, "authors": "Favour Nyikosa, Michael A. Osborne, S. Roberts", "url": "https://api.semanticscholar.org/CorpusId:201330078", "relevance": 1, "abstract": "Financial markets are complex environments that produce enormous amounts of noisy and non-stationary data. One fundamental problem is online portfolio selection, the goal of which is to exploit this data to sequentially select portfolios of assets to achieve positive investment outcomes while managing risks. Various algorithms have been proposed for solving this problem in fields such as finance, statistics and machine learning, among others. Most of the methods have parameters that are estimated from backtests for good performance. Since these algorithms operate on non-stationary data that reflects the complexity of financial markets, we posit that adaptively tuning these parameters in an intelligent manner is a remedy for dealing with this complexity. In this paper, we model the mapping between the parameter space and the space of performance metrics using a Gaussian process prior. We then propose an oracle based on adaptive Bayesian optimization for automatically and adaptively configuring online portfolio selection methods. We test the efficacy of our solution on algorithms operating on equity and index data from various markets.", "citations": 1}
{"title": "Extended formulations in mixed integer conic quadratic programming", "year": 2015, "authors": "J. Vielma, Iain Dunning, Joey Huchette, Miles Lubin", "url": "https://api.semanticscholar.org/CorpusId:1924437", "relevance": 1, "abstract": "In this paper we consider the use of extended formulations in LP-based algorithms for mixed integer conic quadratic programming (MICQP). Extended formulations have been used by Vielma et al. (INFORMS J Comput 20: 438\u2013450, 2008) and Hijazi et al. (Comput Optim Appl 52: 537\u2013558, 2012) to construct algorithms for MICQP that can provide a significant computational advantage. The first approach is based on an extended or lifted polyhedral relaxation of the Lorentz cone by Ben-Tal and Nemirovski (Math Oper Res 26(2): 193\u2013205 2001) that is extremely economical, but whose approximation quality cannot be iteratively improved. The second is based on a lifted polyhedral relaxation of the euclidean ball that can be constructed using techniques introduced by Tawarmalani and Sahinidis (Math Programm 103(2): 225\u2013249, 2005). This relaxation is less economical, but its approximation quality can be iteratively improved. Unfortunately, while the approach of Vielma, Ahmed and Nemhauser is applicable for general MICQP problems, the approach of Hijazi, Bonami and Ouorou can only be used for MICQP problems with convex quadratic constraints. In this paper we show how a homogenization procedure can be combined with the technique by Tawarmalani and Sahinidis to adapt the extended formulation used by Hijazi, Bonami and Ouorou to a class of conic mixed integer programming problems that include general MICQP problems. We then compare the effectiveness of this new extended formulation against traditional and extended formulation-based algorithms for MICQP. We find that this new formulation can be used to improve various LP-based algorithms. In particular, the formulation provides an easy-to-implement procedure that, in our benchmarks, significantly improved the performance of commercial MICQP solvers.", "citations": 44}
{"title": "Quantum Finance and Fuzzy Reinforcement Learning-Based Multi-agent Trading System", "year": 2024, "authors": "Chi Cheng, Bingshen Chen, Ziting Xiao, Raymond S. T. Lee", "url": "https://www.semanticscholar.org/paper/00a1c0fe8f91e17f3cfd7c8453c473215731537f", "relevance": 1, "abstract": "", "citations": 6}
{"title": "MarketGPT: Developing a Pre-trained transformer (GPT) for Modeling Financial Time Series", "year": 2024, "authors": "Aaron Wheeler, Jeffrey D. Varner", "url": "https://www.semanticscholar.org/paper/33c35eaa465f49b5bcba049f1d01b29ca6685841", "relevance": 1, "abstract": "This work presents a generative pre-trained transformer (GPT) designed for modeling financial time series. The GPT functions as an order generation engine within a discrete event simulator, enabling realistic replication of limit order book dynamics. Our model leverages recent advancements in large language models to produce long sequences of order messages in a steaming manner. Our results demonstrate that the model successfully reproduces key features of order flow data, even when the initial order flow prompt is no longer present within the model's context window. Moreover, evaluations reveal that the model captures several statistical properties, or 'stylized facts', characteristic of real financial markets and broader macro-scale data distributions. Collectively, this work marks a significant step toward creating high-fidelity, interactive market simulations.", "citations": 6}
{"title": "From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models", "year": 2025, "authors": "Zi-Zhou Kuang, Feiyu Zhu, Maowei Jiang, Yanzhao Lai, Zelin Wang, Zhitong Wang, Meikang Qiu, Jiajia Huang, Min Peng, Qianqian Xie, Sophia Ananiadou", "url": "https://www.semanticscholar.org/paper/ba13b3744678596741204a69dd337360d52cd85d", "relevance": 1, "abstract": "Large Language Models (LLMs) have shown promise for financial applications, yet their suitability for this high-stakes domain remains largely unproven due to inadequacies in existing benchmarks. Existing benchmarks solely rely on score-level evaluation, summarizing performance with a single score that obscures the nuanced understanding of what models truly know and their precise limitations. They also rely on datasets that cover only a narrow subset of financial concepts, while overlooking other essentials for real-world applications. To address these gaps, we introduce FinCDM, the first cognitive diagnosis evaluation framework tailored for financial LLMs, enabling the evaluation of LLMs at the knowledge-skill level, identifying what financial skills and knowledge they have or lack based on their response patterns across skill-tagged tasks, rather than a single aggregated number. We construct CPA-KQA, the first cognitively informed financial evaluation dataset derived from the Certified Public Accountant (CPA) examination, with comprehensive coverage of real-world accounting and financial skills. It is rigorously annotated by domain experts, who author, validate, and annotate questions with high inter-annotator agreement and fine-grained knowledge labels. Our extensive experiments on 30 proprietary, open-source, and domain-specific LLMs show that FinCDM reveals hidden knowledge gaps, identifies under-tested areas such as tax and regulatory reasoning overlooked by traditional benchmarks, and uncovers behavioral clusters among models. FinCDM introduces a new paradigm for financial LLM evaluation by enabling interpretable, skill-aware diagnosis that supports more trustworthy and targeted model development, and all datasets and evaluation scripts will be publicly released to support further research.", "citations": 3}
{"title": "Option-Driven Sentiment in FinRL: a PPO Approach to Trading", "year": 2025, "authors": "Shenjian Li, Mingxuan Yu, Freddie Dossor", "url": "https://www.semanticscholar.org/paper/a394dd37ec90d2b36bce43cb5d45311c0df1fc79", "relevance": 1, "abstract": "This paper addresses Task 1 of the FinRL Contest 2025 by applying a sentiment-enhanced stock trading agent based on Proximal Policy Optimization (PPO) augmented with market sentiment indicators, such as Put-Call Ratio, as key input, which is an option-based market sentiment indicator. The agent was tested on NASDAQ-100 constituents from 2019 to 2023 by using the trained dataset from 2013 to 2018. We found the PPO model outperforms both the baseline index and CVaR-PPO (CPPO) in cumulative return, Sharpe ratio, and Sortino ratio. Notably, the Sharpe ratio improved from 0.69 to 1.08. The results suggest that incorporating market sentiment indicators into PPO can significantly enhance risk-adjusted performance.", "citations": 3}
{"title": "From Technical Indicators to Trading Decisions: A Deep Learning Model Combining CNN and LSTM", "year": 2024, "authors": "Sahib Mohamed Rida, Elkina Hamza, Zaki A. Taher", "url": "https://www.semanticscholar.org/paper/a7d0b5047c1d7cf13e1c91fa0f76544735a4d46f", "relevance": 1, "abstract": "\u2014Stock market prediction is a highly attractive and popular field within finance, driven by the potential for significant profits that come with substantial risks due to data non-linearity and complex economic principles. Extracting features from trading data is crucial in this domain, and numerous strategies have been developed. Among these, deep learning has achieved impressive results in financial applications because of its robust data processing capabilities. In our study, we propose a hybrid deep learning model, the CNN-LSTM, which combines the 2D Convolutional Neural Network (CNN) for image processing with the Long Short-Term Memory (LSTM) network for managing image sequences and classification. We transformed the top 15 of 21 technical indicators from financial time series into 15x15 images for 21 different day periods. Each image is then categorized as Sell, Hold, or Buy based on the trading data. Our model demonstrates superior performance in stock predictions over other deep learning models.", "citations": 5}
{"title": "QuantBench: benchmarking AI methods for quantitative investment from a full pipeline perspective", "year": 2025, "authors": "Sai Wang, Hao Kong, Jiadong Guo, Fengrui Hua, Yiyan Qi, Wanyun Zhou, Jiahao Zheng, Xinyu Wang, Lionel M. Ni, Jian Guo", "url": "https://www.semanticscholar.org/paper/872f371bc0b3ced545877679379d276466533183", "relevance": 1, "abstract": "The field of artificial intelligence (AI) in quantitative investment has seen significant advancements, yet it lacks a standardized benchmark aligned with industry practices. This gap hinders research progress and limits the practical application of academic innovations. We present QuantBench, an industrial-grade benchmark platform designed to address this critical need. QuantBench offers three key strengths: (1) standardization that aligns with quantitative investment industry practices; (2) flexibility to integrate various AI algorithms; (3) full-pipeline coverage of the entire quantitative investment process. Our empirical studies using QuantBench reveal some critical research directions, including the need for continual learning to address distribution shifts, improved methods for modeling relational financial data, and more robust approaches to mitigate overfitting in low signal-to-noise environments. By providing a common ground for evaluation and fostering collaboration between researchers and practitioners, QuantBench aims to accelerate progress in AI for quantitative investment, similar to the impact of benchmark platforms in computer vision and natural language processing. The code is open-sourced on GitHub at https://github.com/SaizhuoWang/quantbench.", "citations": 2}
{"title": "Deep Finance: Cutting-Edge Deep Learning Applications in Market Prediction, Risk Analytics, and Algorithmic Trading", "year": 2025, "authors": "Murali Krishna Pasupuleti", "url": "https://www.semanticscholar.org/paper/9d69dbfe6c8e53d6abe83805293d0c91d8067a8d", "relevance": 1, "abstract": "Abstract:\nThis research paper delves into the transformative role of deep learning in revolutionizing financial market analysis, with a focus on predictive modeling, risk management, and algorithmic trading. Leveraging architectures such as recurrent neural networks (RNNs), long short-term memory (LSTM) networks, convolutional neural networks (CNNs), and transformer models, the study explores how deep learning techniques enhance the accuracy and adaptability of financial forecasting across diverse asset classes. It further examines the integration of deep reinforcement learning and generative models in building autonomous trading agents capable of learning optimal strategies in dynamic and uncertain environments. The paper also evaluates advanced deep learning-driven risk analytics, including volatility forecasting, credit scoring, and stress testing, demonstrating their value in proactive decision-making and systemic risk assessment. Through empirical validation using real-world financial datasets, this study offers actionable insights into building robust, data-driven frameworks that align with the demands of modern, high-frequency, and AI-powered financial systems.\nKeywords:\nDeep learning, Financial markets, Predictive modeling, Risk analytics, Algorithmic trading, LSTM, RNN, Transformer models, Reinforcement learning, Autonomous trading systems, Market forecasting, Financial risk management, Neural networks, High-frequency trading, AI in finance", "citations": 1}
{"title": "Analysis Influence Working Capital Investment On Company Value and Investment Decisions Long Term : An Empirical Study of the Sector Manufacturing 2014 \u2013 2023 in Indonesia", "year": 2025, "authors": "Rena Khaesarani, R. Rokhim", "url": "https://www.semanticscholar.org/paper/6156aa8a49bd1df9d4a7b55a072affbd860219d6", "relevance": 1, "abstract": "This research aims to investigate the impact of working capital investment on firm value and long-term investment decisions in the manufacturing sector in Indonesia. The study utilizes annual panel data from 100 to 150 manufacturing firms listed on the Indonesia Stock Exchange (IDX) during the period 2014-2023. Findings indicate that efficient working capital investment has a positive influence on firm value and long-term investment decisions. This study utilizes the Trade-Off, Agency, and Resource-Based View theories as a framework. The results provide valuable implications for finance managers in the manufacturing sector to optimize working capital management to enhance firm profitability and long-term growth.", "citations": 1}
{"title": "Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)", "year": 2025, "authors": "Paolo Pedinotti, Peter Baumann, Nathan Jessurun, Leslie Barrett, Enrico Santus", "url": "https://www.semanticscholar.org/paper/42d925a8797703b96c867849c13ad78b97e21ee1", "relevance": 1, "abstract": "Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling new tasks and driving a proliferation of datasets and diversification of data sources. Yet, this transformation has outpaced traditional surveys. In this paper, we present MetaGraph, a generalizable methodology for extracting knowledge graphs from scientific literature and analyzing them to obtain a structured, queryable view of research trends. We define an ontology for financial NLP research and apply an LLM-based extraction pipeline to 681 papers (2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals three key phases: early LLM adoption and task/dataset innovation; critical reflection on LLM limitations; and growing integration of peripheral techniques into modular systems. This structured view offers both practitioners and researchers a clear understanding of how financial NLP has evolved - highlighting emerging trends, shifting priorities, and methodological shifts-while also demonstrating a reusable approach for mapping scientific progress in other domains.", "citations": 0}
{"title": "Comparison of Linear Regression and LSTM (Long Short-Term Memory) in Cryptocurrency Prediction", "year": 2024, "authors": "Marisa Istaltofa, Sarwido Sarwido, Adi Sucipto", "url": "https://www.semanticscholar.org/paper/d9f53feedeba5a045d97e769c206624dccfbae7e", "relevance": 1, "abstract": "Abstract \u00a0 \nCryptocurrency, particularly Bitcoin, has become a major topic in the financial and digital trading sectors due to its ability to facilitate direct transactions without intermediaries and the transparency offered by blockchain technology. However, the high volatility of Bitcoin prices necessitates accurate prediction methods to support better investment decisions. This research aims to compare the accuracy of Linear Regression and Long Short-Term Memory (LSTM) methods in predicting Bitcoin prices using historical data from Yahoo Finance. The research process begins with the collection of historical Bitcoin price data from September 17, 2014, to July 15, 2024, followed by data processing that includes cleaning and splitting the dataset into training and test data. Linear Regression and LSTM models are applied to the training data and tested to evaluate their performance in price prediction. The research findings show that the LSTM model significantly outperforms the Linear Regression model in terms of prediction accuracy. The LSTM model records much lower Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), as well as perfect R\u00b2 scores on both datasets, demonstrating its high precision in prediction. In contrast, the Linear Regression model shows higher errors and lower explanatory power of data variability. These findings indicate that LSTM is more effective in capturing temporal patterns and Bitcoin price fluctuations, offering better accuracy and potentially being more suitable for future cryptocurrency price analysis, providing better guidance for investors in this highly dynamic market.", "citations": 4}
{"title": "Influence of YouTube Finance Influencers and Traders\u2019 Tips on Investment Decisions of Working Professionals: The Mediating Role of Trust and Perceived Advice Quality in Stock Market Participation", "year": 2025, "authors": "Shubham Mishra", "url": "https://www.semanticscholar.org/paper/a5bee23c376e6b23ed0b4ee6262d610dfce753bb", "relevance": 1, "abstract": "This study investigates the burgeoning influence of YouTube-based financial\u00a0 influencers (\u201cfinfluencers\u201d) on the investment behaviors of working professionals.\u00a0 As digital platforms democratize financial advice, understanding the cognitive\u00a0 and psychological drivers of investment becomes paramount. Grounded in Source\u00a0 Credibility Theory (SCT), this research examines how influencer content drives\u00a0 stock market participation through two critical mediators: Trust and Perceived\u00a0 Advice Quality. A quantitative study was conducted using a hypothetical sample\u00a0 of 400 working professionals across urban centers. The findings indicate that\u00a0 while direct \u201ctrading tips\u201d stimulate immediate investment intent, long-term and\u00a0 sustained stock market participation are heavily dependent on the established\u00a0 trust between the viewer and the influencer. Furthermore, perceived advice\u00a0 quality acts as a secondary mediator, ensuring that professionals feel competent in\u00a0 their decision-making. The results underscore a significant shift from traditional\u00a0 institutional advisory to social-media-driven peer advisory. This paper contributes\u00a0 to behavioral finance literature by identifying the \u201cTrust-Quality\u201d bridge in digital\u00a0 ecosystems and suggests that regulatory bodies should focus on the quality metrics\u00a0 of digital financial content to protect retail investors.\u00a0", "citations": 0}
{"title": "Optimal consumption, portfolio, and long\u2010term\u2010care health insurance in a dynamic framework", "year": 2025, "authors": "Lucia Leporatti, Rosella Levaggi, F. Menoncin, Raffaele Miniaci", "url": "https://www.semanticscholar.org/paper/1384cc2d52607189bd285b0d71ede1fa23991b24", "relevance": 1, "abstract": "We study the optimal dynamic strategy of representative agents who can invest in the financial market and sign an insurance contract to optimise the utility of intertemporal consumption and face the risk of long\u2010term\u2010care (LTC) expenses. The time horizon of the agent coincides with the stochastic death time, and the health expenditure risk takes the form of a jump Poisson process. The agent may hedge against this health risk by signing an insurance contract, on which we assume there exists a mark\u2010up. We find a closed\u2010form solution for the optimal consumption, the optimal portfolio, and the optimal insurance hedge. We show that the decision to purchase LTC insurance is more complex than what emerges from most insurance models. The proportion of LTC expenditure insured decreases with age. Our model predicts substitution between private coverage and savings as a means to finance LTC expenditure. In response to a health shock requiring an increase in LTC expenditure, the individuals sell their assets to keep up the level of consumption (the so\u2010called \u201cconsumption smoothing\u201d effect). Richer individuals dissave more than poorer ones. An increase in the interest rate has the same qualitative impact. The reduction in the mark\u2010up, either due to increasing competitiveness or through public subsidies, is likely to increase the welfare of well\u2010off/fit individuals, while an increase in the interest rate may reduce coverage in a very substantial way, an aspect that has been overlooked by the literature so far.", "citations": 0}
{"title": "Are Autonomous Agents the Inevitable Future of Decentralized Finance? A Review and Forward Outlook", "year": 2025, "authors": "Sonya Nadira Gularso, Richard Wiputra", "url": "https://www.semanticscholar.org/paper/b4d9f1263cf72f59b76178e651a714c98241a295", "relevance": 1, "abstract": "", "citations": 0}
{"title": "PyFi: Toward Pyramid-like Financial Image Understanding for VLMs via Adversarial Agents", "year": 2025, "authors": "Yuqun Zhang, Yuxuan Zhao, Sijia Chen", "url": "https://www.semanticscholar.org/paper/21c8f3c47dcf6d0fbe010fe44283654791c9da79", "relevance": 1, "abstract": "This paper proposes PyFi, a novel framework for pyramid-like financial image understanding that enables vision language models (VLMs) to reason through question chains in a progressive, simple-to-complex manner. At the core of PyFi is PyFi-600K, a dataset comprising 600K financial question-answer pairs organized into a reasoning pyramid: questions at the base require only basic perception, while those toward the apex demand increasing levels of capability in financial visual understanding and expertise. This data is scalable because it is synthesized without human annotations, using PyFi-adv, a multi-agent adversarial mechanism under the Monte Carlo Tree Search (MCTS) paradigm, in which, for each image, a challenger agent competes with a solver agent by generating question chains that progressively probe deeper capability levels in financial visual reasoning. Leveraging this dataset, we present fine-grained, hierarchical, and comprehensive evaluations of advanced VLMs in the financial domain. Moreover, fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B on the pyramid-structured question chains enables these models to answer complex financial questions by decomposing them into sub-questions with gradually increasing reasoning demands, yielding average accuracy improvements of 19.52% and 8.06%, respectively, on the dataset. All resources of code, dataset and models are available at: https://github.com/AgenticFinLab/PyFi .", "citations": 0}
{"title": "Pricing analysis of wind power derivatives for renewable energy risk management", "year": 2021, "authors": "Takashi Kanamura, Lasse Homann, Marcel Prokopczuk", "url": "https://www.semanticscholar.org/paper/a72ebf7258c530eb0a7ac56be930e8a40723ec57", "relevance": 1, "abstract": "", "citations": 21}
{"title": "Examining the predictive power of moving averages in the stock market", "year": 2023, "authors": "Arjun Chaddha, S. Yadav", "url": "https://www.semanticscholar.org/paper/477ab97ce809fcadb5742252bb8485ff0af5c0dd", "relevance": 1, "abstract": "Moving averages are common technical analysis tools which investors use to generate buy and sell calls in the stock market. The purpose of this research paper is to analyse whether common moving average techniques can reliably predict stock market behaviour. Using hypothesis testing, this paper tests whether the percentage return yielded by using moving average combinations to trade stocks in the S&P 500 index was significantly higher than a) the percentage return yielded by randomly buying and selling the stocks and b) the market percentage return. The tests were conducted for the S&P 500 stocks in four different time frames to understand the performance of moving averages during different stock market trends (uptrend, sideways trend, downtrend). Moreover, the performance of three different buying and selling techniques which use moving averages were compared. The results of the paper indicate that an investor should not use moving averages to trade stocks owing to their limited predictive power. There were only a few moving average combinations which were significantly better than randomly buying and selling. Even those few combinations could not yield higher percentage returns than the market percentage return.", "citations": 3}
{"title": "Incorporating Black-Litterman views in portfolio construction when stock returns are a mixture of normals", "year": 2017, "authors": "Burak Kocuk, G'erard Cornu'ejols", "url": "https://api.semanticscholar.org/CorpusId:13992934", "relevance": 1, "abstract": "Abstract In this paper, we consider the basic problem of portfolio construction in financial engineering, and analyze how market-based and analytical approaches can be combined to obtain efficient portfolios. As a first step in our analysis, we model the asset returns as a random variable distributed according to a mixture of normal random variables. We then discuss how to construct portfolios that minimize the Conditional Value-at-Risk (CVaR) under this probabilistic model via a convex program. We also construct a second-order cone representable approximation of the CVaR under the mixture model, and demonstrate its theoretical and empirical accuracy. Furthermore, we incorporate the market equilibrium information into this procedure through the well-known Black-Litterman approach via an inverse optimization framework by utilizing the proposed approximation. Our computational experiments on a real dataset show that this approach with an emphasis on the market equilibrium typically yields less risky portfolios than a purely market-based portfolio while producing similar returns on average.", "citations": 24}
{"title": "Democratization of Retail Trading: Can Reddit's WallStreetBets Outperform Investment Bank Analysts?", "year": 2022, "authors": "Tolga Buz, Gerard de Melo", "url": "https://www.semanticscholar.org/paper/2fbacb8be6e16a519edc4cfbf66b7cd4e73bf398", "relevance": 1, "abstract": "The recent hype around Reddit\u2019s WallStreetBets (WSB) community has inspired research on its impact on our economy and society. Still, one important question remains: Can WSB\u2019s community of anonymous contributors actually provide valuable investment advice and possibly even outperform top \ufb01nancial institutions? We present a data-driven empirical study of investment recommendations of WSB in comparison to recommendations made by leading investment banks, based on more than 1.6 million WSB posts published since 2018. To this end, we extract and evaluate investment recommendations from WSB\u2019s raw text for all S&P 500 stocks and compare their performance to more than 16,000 analyst recommendations from the largest investment banks. While not all WSB recommendations prove pro\ufb01table, our results show that they achieve average returns that compete with the best banks and outperform them in certain cases. Furthermore, the WSB community has been better than almost all investment banks at detecting top-performing stocks. We conclude that WSB may indeed constitute a freely accessible, valuable source of investment advice.", "citations": 3}
{"title": "Multi-agent modeling and simulation of a stock market", "year": 2018, "authors": "Mohamed Amine Souissi, K. Bensaid, R. Ellaia", "url": "https://api.semanticscholar.org/CorpusId:158609754", "relevance": 1, "abstract": "The stock market represents complex systems where multiple agents interact. The complexity of the environment in the financial markets in general has encouraged the use of modeling by multi-agent platforms and particularly in the case of the stock market.In this paper, an agent-based simulation model is proposed to study the behavior of the volume of market transactions. The model is based on the case of a single asset and three types of investor agents. Each investor can be a zero intelligent trader, fundamentalist trader or traders using historical information in the decision making process. The goal of the study is to simulate the behavior of a stock market according to the different considered endogenous and exogenous variables.", "citations": 11}
{"title": "FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance", "year": 2021, "authors": "Xiao-Yang Liu, Jingyang Rui, Jiechao Gao, Liuqing Yang, Hongyang Yang, Zhaoran Wang, Chris Wang, Jian Guo", "url": "https://www.semanticscholar.org/paper/bc2f8313d0cd6efbd317a9f7e4ad8e20ade30367", "relevance": 1, "abstract": "Deep reinforcement learning (DRL) has shown huge potentials in building financial market simulators recently. However, due to the highly complex and dynamic nature of real-world markets, raw historical financial data often involve large noise and may not reflect the future of markets, degrading the fidelity of DRL-based market simulators. Moreover, the accuracy of DRL-based market simulators heavily relies on numerous and diverse DRL agents, which increases demand for a universe of market environments and imposes a challenge on simulation speed. In this paper, we present a FinRL-Meta framework that builds a universe of market environments for data-driven financial reinforcement learning. First, FinRL-Meta separates financial data processing from the design pipeline of DRL-based strategy and provides open-source data engineering tools for financial big data. Second, FinRL-Meta provides hundreds of market environments for various trading tasks. Third, FinRL-Meta enables multiprocessing simulation and training by exploiting thousands of GPU cores. Our codes are available online at https://github.com/AI4Finance-Foundation/FinRL-Meta.", "citations": 13}
{"title": "LP Algorithms for Portfolio Optimization: The PortfolioOptim Package", "year": 2018, "authors": "A. Palczewski", "url": "https://api.semanticscholar.org/CorpusId:64553405", "relevance": 1, "abstract": "The paper describes two algorithms for financial portfolio optimization with the following risk measures: CVaR, MAD, LSAD and dispersion CVaR. These algorithms can be applied to discrete distributions of asset returns since then the optimization problems can be reduced to linear programs. The first algorithm solves a simple recourse problem as described by Haneveld using Benders decomposition method. The second algorithm finds an optimal portfolio with the smallest distance to a given benchmark portfolio and is an adaptation of the least norm solution (called also normal solution) of linear programs due to Zhao and Li. The algorithms are implemented in R in the package PortfolioOptim.", "citations": 6}
{"title": "Financial Portfolio Optimization: Computationally guided agents to investigate, analyse and invest!?", "year": 2013, "authors": "Ankit Dangi", "url": "https://api.semanticscholar.org/CorpusId:9568395", "relevance": 1, "abstract": "Financial portfolio optimization is a widely studied problem in mathematics, statistics, financial and computational literature. It adheres to determining an optimal combination of weights associated with financial assets held in a portfolio. In practice, it faces challenges by virtue of varying math. formulations, parameters, business constraints and complex financial instruments. Empirical nature of data is no longer one-sided; thereby reflecting upside and downside trends with repeated yet unidentifiable cyclic behaviours potentially caused due to high frequency volatile movements in asset trades. Portfolio optimization under such circumstances is theoretically and computationally challenging. This work presents a novel mechanism to reach an optimal solution by encoding a variety of optimal solutions in a solution bank to guide the search process for the global investment objective formulation. It conceptualizes the role of individual solver agents that contribute optimal solutions to a bank of solutions, a super-agent solver that learns from the solution bank, and, thus reflects a knowledge-based computationally guided agents approach to investigate, analyse and reach to optimal solution for informed investment decisions. Conceptual understanding of classes of solver agents that represent varying problem formulations and, mathematically oriented deterministic solvers along with stochastic-search driven evolutionary and swarm-intelligence based techniques for optimal weights are discussed. Algorithmic implementation is presented by an enhanced neighbourhood generation mechanism in Simulated Annealing algorithm. A framework for inclusion of heuristic knowledge and human expertise from financial literature related to investment decision making process is reflected via introduction of controlled perturbation strategies using a decision matrix for neighbourhood generation.", "citations": 9}
{"title": "Momentum Effects in Country Equity Indices", "year": 2010, "authors": "C. Muller, M. Ward", "url": "https://www.semanticscholar.org/paper/7e2458e449b80513bf3fa2339923db075b8e4e7a", "relevance": 1, "abstract": "Abstract This paper examines the 70 country indices which comprise the MSCI world index as a representative set of global equity investment opportunities, and examines momentum and mean-reversion effects in these. We show that persistent and significant effects do exist, particularly with regard to short-term momentum. A strategy of holding for one month, a portfolio of the four best performing MSCI country indices over the previous 11 months, was found to persistently out-perform an equal weighted benchmark by around 10% per annum over the 39 year period from 1970 to 2009.", "citations": 9}
